[{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 // ==UserScript== // @name 下载微博相册图片为ZIP文件 // @namespace http://tampermonkey.net/ // @version 0.1 // @description 下载微博相册上的所有图片并将它们打包为ZIP文件 // @author You // @match https://weibo.com/u/*?tabtype=album // @grant GM_addStyle // ==/UserScript== (function() { \u0026#39;use strict\u0026#39;; // 获取微博用户的 ID 作为下载文件名 const match = window.location.href.match(/https:\\/\\/weibo\\.com\\/u\\/(\\d+)\\?/); if (!match) { console.error(\u0026#34;无法获取微博用户 ID\u0026#34;); return; } const userId = match[1]; const downloadFileName = `weibo_album_${userId}.zip`; // 插入按钮到页面顶部并居中 const button = document.createElement(\u0026#34;button\u0026#34;); button.innerText = \u0026#34;下载图片为ZIP\u0026#34;; button.style.position = \u0026#34;fixed\u0026#34;; button.style.top = \u0026#34;50%\u0026#34;; // 垂直居中 button.style.left = \u0026#34;50%\u0026#34;; // 水平居中 button.style.transform = \u0026#34;translate(-50%, -50%)\u0026#34;; // 使按钮完全居中 button.style.zIndex = \u0026#34;9999\u0026#34;; // 确保按钮位于页面顶部 button.style.padding = \u0026#34;10px 20px\u0026#34;; button.style.backgroundColor = \u0026#34;#007bff\u0026#34;; button.style.color = \u0026#34;#fff\u0026#34;; button.style.border = \u0026#34;none\u0026#34;; button.style.borderRadius = \u0026#34;5px\u0026#34;; button.style.cursor = \u0026#34;pointer\u0026#34;; button.style.fontSize = \u0026#34;16px\u0026#34;; // 增加字体大小 button.style.boxShadow = \u0026#34;0 2px 10px rgba(0, 0, 0, 0.3)\u0026#34;; // 添加阴影 document.body.appendChild(button); // 按钮点击事件 button.addEventListener(\u0026#34;click\u0026#34;, () =\u0026gt; { downloadAllImagesAsZip(); }); // 加载 JSZip 库 const loadJSZip = () =\u0026gt; { return new Promise((resolve, reject) =\u0026gt; { const script = document.createElement(\u0026#34;script\u0026#34;); script.src = \u0026#34;https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js\u0026#34;; script.onload = resolve; script.onerror = reject; document.head.appendChild(script); }); }; // 下载所有图片并打包为ZIP const downloadAllImagesAsZip = async () =\u0026gt; { console.log(\u0026#34;开始加载 JSZip...\u0026#34;); await loadJSZip(); // 加载 JSZip console.log(\u0026#34;JSZip 加载完成。\u0026#34;); const zip = new JSZip(); // 使用 new JSZip() 实例化 const images = document.getElementsByClassName(\u0026#34;woo-picture-img\u0026#34;); console.log(`共找到 ${images.length} 张图片。`); if (images.length === 0) { alert(\u0026#34;没有找到任何图片！\u0026#34;); // 如果没有图片，提示用户 return; // 终止函数，不执行下载逻辑 } // 下载所有图片并存储到内存中 const imageBlobs = await Promise.all( Array.from(images).map((img, index) =\u0026gt; { if (img.tagName === \u0026#34;IMG\u0026#34; \u0026amp;\u0026amp; img.src) { console.log(`开始下载图片 ${index + 1}: ${img.src}`); return fetch(img.src) .then((response) =\u0026gt; { if (!response.ok) { throw new Error(`HTTP 状态码: ${response.status}`); } return response.blob(); }) .then((blob) =\u0026gt; { console.log(`图片 ${index + 1} 下载完成。`); return { blob, index, src: img.src }; }) .catch((error) =\u0026gt; { console.error(`无法下载图片 ${index + 1}: ${img.src}`, error); return null; // 返回 null 表示下载失败 }); } else { console.warn(`图片元素无效: ${img}`); return null; } }) ); console.log(\u0026#34;所有图片下载完成，开始添加到 ZIP 包。\u0026#34;); // 将图片添加到 ZIP 包 imageBlobs.forEach((image) =\u0026gt; { if (image) { const ext = image.src.split(\u0026#34;.\u0026#34;).pop().split(\u0026#34;?\u0026#34;)[0] || \u0026#34;jpg\u0026#34;; // 提取扩展名 zip.file(`image-${image.index + 1}.${ext}`, image.blob); // 添加到 ZIP console.log(`图片 ${image.index + 1} 已添加到 ZIP 包。`); } }); // 生成 ZIP 并下载 console.log(\u0026#34;开始生成 ZIP 文件。\u0026#34;); zip.generateAsync({ type: \u0026#34;blob\u0026#34; }).then((content) =\u0026gt; { console.log(\u0026#34;ZIP 文件生成完成，开始下载。\u0026#34;); const a = document.createElement(\u0026#34;a\u0026#34;); a.href = URL.createObjectURL(content); a.download = downloadFileName; // 使用用户 ID 作为下载文件名 document.body.appendChild(a); a.click(); document.body.removeChild(a); console.log(\u0026#34;ZIP 文件下载完成。\u0026#34;); }); }; })(); 效果嘛。\n大概会遇到CORS错误。\n解决办法嘛 -\u0026gt; Modheader 修改一下ResponseHeader。\nAccess-Control-Allow-Origin 直接填成 *\n完事。\n下载内容。\n","date":"2025-01-23T08:00:00Z","image":"https://liguobao.github.io/p/one-line-download-weibo-img/logo_hu_ccab1450c202af7f.png","permalink":"https://liguobao.github.io/p/one-line-download-weibo-img/","title":"一行代码下载微博相册"},{"content":"mini-dashboard 是 meilisearch 的一个小型查询看板，\n提供了比较集群的查询页面，对于我的需求来说刚好够用。\n不过官方的镜像构建只是个node Debug版本，\n所以我自己构建了一个静态站点镜像。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 FROM node:20-alpine AS build-env WORKDIR /home/node/app RUN chown -R node:node /home/node/app USER node COPY package*.json ./ COPY --chown=node:node . . RUN yarn install ENV NODE_ENV=production # if you want to use your own meilisearch server, you can set the following env # ENV REACT_APP_MEILI_SERVER_ADDRESS=http://meilisearch:7700 # ENV REACT_APP_MEILI_API_KEY=masterKey RUN yarn build FROM nginx COPY --from=build-env /home/node/app/build/ /usr/share/nginx/html/ Docker with Nginx nginx is also available in the Docker image.\nYou can use it to serve the mini-dashboard.\n1 2 docker build --build-arg REACT_APP_MEILI_SERVER_ADDRESS=http://meilisearch:7700 -t meilisearch-mini-dashboard-nginx . -f Dockerfile.nginx docker run -p 8080:80 meilisearch-mini-dashboard-nginx You can then access the mini-dashboard at http://localhost:8080.\n大概如此。\n当然，最简单的还是直接把用docker-compose\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 version: \u0026#34;3.8\u0026#34; services: meilisearch-node1: image: getmeili/meilisearch:v1.12 restart: always container_name: meilisearch-node1 ports: - \u0026#34;7700:7700\u0026#34; environment: MEILI_MASTER_KEY: \u0026#34;iinti_2025_gogogo_123\u0026#34; MEILI_ENV: \u0026#34;production\u0026#34; MEILI_DB_PATH: \u0026#34;/meili_data\u0026#34; MEILI_NO_ANALYTICS: \u0026#34;true\u0026#34; volumes: - /mnt/nvme/Meilisearch/meili_data/node1:/meili_data networks: - meili-network meilisearch-dashboard: restart: always image: mini-dashboard-nginx container_name: meilisearch-dashboard ports: - \u0026#34;7707:80\u0026#34; networks: - meili-network networks: meili-network: driver: bridge ","date":"2025-01-16T08:00:00Z","image":"https://liguobao.github.io/p/meili-dashboard/logo_hu_77dac2114095c1e3.png","permalink":"https://liguobao.github.io/p/meili-dashboard/","title":"构建 meilisearch mini-dashboard 静态站点镜像"},{"content":"Windows 整盘备份迁移简易教程 死党前阵子一直在抱怨电脑磁盘空间不够用了，\n查了下他的笔记本型号，问了下小米客服确认，这个型号只有一个M.2插槽，没有预留扩展位。\n不过SSD并没有焊死在主板上，拆装起来还是比较方便的。\n查了一下拆机教程，背板螺丝拆下来之后就能换硬盘了。\n准备工具 4T M.2 SSD 维修螺丝刀套装 SSD 硬盘盒 软件：分区助手 操作流程 把新硬盘装到SSD 硬盘盒 使用“分区助手” 克隆整个磁盘分区到新硬盘 拆笔记本后盖，替换原硬盘 开机确认系统正常启动运行 克隆整个磁盘分区 这个没什么太多需要讲的，打开分区助手，\n选择磁盘克隆，选择源盘和目标盘，然后开始克隆。\n看磁盘速度，都是SSD的情况，我这边一个多小时就跑完了。\n教程可以参考：\n无需重装，轻松将系统迁移到固态硬盘! 如何快速将系统迁移到新硬盘？3种数据迁移方法！ 操作流程大同小异，不再赘述。\n迁移完成之后，可以打开文件夹，简单看一下数据是不是正常的。\n拆装硬盘 这个很简单，基本就是拧螺丝，拆下来，换上去。\n我扔了一个操作视频给死党，他自己都搞掂了。\n是的。本次操作全程他自己完成，我只能远程指导。\n第一个“问题”：No bootable device 换好硬盘之后开机，直接显示 “No bootable device”。\n迷糊，难道硬盘没插紧？\n让老友再次检查了，确认硬盘确实接紧了。\n让他换回老硬盘试试开机，一切正常。\n再次换回新硬盘，还是显示 “No bootable device”。\n奈何他手上没有PE U盘，夜里太晚了先不折腾了，白天搞个PE盘在试试。\n白天想了下，这个问题应该是引导问题，新硬盘没有引导信息。\n搞到了新PE盘之后，远程指导他进入PE系统，确认了新硬盘是正常识别的了，\n容量和分区看起来和老硬盘是一致的。\n先直接用PE自带的工具做了一次引导修复。\n再次重启，依旧还是一样的错误。\n第二个“问题”：主引导记录不太对？ 再次进入PE系统，使用 diskgenius 手动修复了一下主引导记录。\n启动之后，还是一样的错误。\n神奇了，还差个什么玩意呢。\n突然想起了老早之前的操作，迁移了磁盘之后，是不是给这玩意磁盘转成GPT 格式。\n再次进入 PE 系统，使用 diskgenius 将新硬盘转换为 GPT 格式。\n重启，正常启动。\n总结 搞系统迁移，还是要备好PE工具在手。 硬盘迁移之后，要注意磁盘格式问题。 参考资料 如何使用老毛桃winpe进行磁盘分区引导修复? MBR(主引导记录)介绍及修复 ","date":"2024-12-27T08:00:00Z","permalink":"https://liguobao.github.io/p/windows-c-disk-move/","title":"Windows 整盘备份迁移简易教程"},{"content":"最近在折腾GitLab迁移，由于原GitLab版本实在是太低了，\n同时使用的是被魔改过的，完全不太可能从老版本跨几个大版本升级到最新版本，\n所以最后决定写Python脚本调用Gitlab API导出用户和分组以及项目，\n接着通过Gitlab API添加到新的Gitlab中，然后把源码仓库整个文件夹拷贝到新服务器，\n使用Python执行shell命令，把所有的git 裸仓库 提交到新的Gitlab中。\n导出用户、分组、项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 import requests import json from loguru import logger from datetime import datetime # GitLab 域名 gitlab_domain = \u0026#34;gitlab.com\u0026#34; # GitLab 配置 GITLAB_URL = f\u0026#39;https://{domain}\u0026#39; # 你的 GitLab 实例的 URL API_TOKEN = \u0026#39;xxx\u0026#39; # 你的 GitLab 访问令牌 # 老版本的Auth Token在 Header HEADERS = {\u0026#39;PRIVATE-TOKEN\u0026#39;: f\u0026#39;{API_TOKEN}\u0026#39;} # 获取所有项目的函数 def get_all_projects(): url = f\u0026#34;{GITLAB_URL}/api/v4/projects\u0026#34; params = { \u0026#34;page\u0026#34;: 1, # 默认第一页 \u0026#34;per_page\u0026#34;: 100 # 每页最多返回100个项目 } projects = [] while True: response = requests.get(url, headers=HEADERS, params=params) if response.status_code != 200: logger.error(f\u0026#34;Error: Unable to fetch data. Status code {response.status_code}\u0026#34;) break data = response.json() if not data: logger.info(\u0026#34;No more projects to fetch.\u0026#34;) break projects.extend(data) params[\u0026#34;page\u0026#34;] += 1 # 获取下一页 logger.info(f\u0026#34;Fetched {len(data)} projects from page {params[\u0026#39;page\u0026#39;] - 1}.\u0026#34;) return projects # 提取所需的项目数据 def extract_project_info(projects, rep_base): user_project_list = [ { \u0026#39;name\u0026#39;: p[\u0026#34;name\u0026#34;], \u0026#39;path_with_namespace\u0026#39;: p[\u0026#34;path_with_namespace\u0026#34;], \u0026#39;default_branch\u0026#39;: p[\u0026#34;default_branch\u0026#34;], \u0026#39;visibility\u0026#39;: p[\u0026#34;visibility\u0026#34;], \u0026#39;ssh_url_to_repo\u0026#39;: p[\u0026#34;ssh_url_to_repo\u0026#34;], \u0026#39;absolute_path\u0026#39;: rep_base + p[\u0026#34;ssh_url_to_repo\u0026#34;].replace(f\u0026#39;git@{gitlab_domain}:\u0026#39;, \u0026#34;\u0026#34;), \u0026#39;new_ssh_url_to_repo\u0026#39;: p[\u0026#34;ssh_url_to_repo\u0026#34;].replace(f\u0026#34;git@{gitlab_domain}:\u0026#34;, \u0026#34;git@127.0.0.1:\u0026#34;), } for p in projects ] return user_project_list # 保存数据到文件 def save_to_file(data, filename=\u0026#34;old_all_projects.json\u0026#34;): with open(filename, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: json.dump(data, f, indent=4, ensure_ascii=False) logger.info(f\u0026#34;Projects data has been saved to \u0026#39;{filename}\u0026#39;.\u0026#34;) # 主函数 def main(): rep_base = \u0026#34;/var/opt/gitlab/git-data/back_repositories/repositories/\u0026#34; # 你自己的仓库路径 logger.info(\u0026#34;Starting the project extraction process.\u0026#34;) try: # 获取所有项目 projects = get_all_projects() if not projects: logger.warning(\u0026#34;No projects found or there was an issue fetching data.\u0026#34;) return # 提取项目信息 user_project_list = extract_project_info(projects, rep_base) # 保存项目列表到文件 save_to_file(user_project_list) logger.info(\u0026#34;Process completed successfully.\u0026#34;) except Exception as e: logger.error(f\u0026#34;An error occurred: {e}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 创建用户、分组、项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 import requests import json import random import string from loguru import logger # 新 GitLab 实例的 URL 和个人访问令牌 NEW_GITLAB_URL = \u0026#39;https://new-gitlab.com\u0026#39; # 新的 GitLab 实例 URL API_TOKEN = \u0026#39;xxxx\u0026#39; # 新的 GitLab 管理员访问令牌 # 新版本的鉴权Header 用的 Authorization HEADERS = { \u0026#39;Authorization\u0026#39;: f\u0026#39;Bearer {API_TOKEN}\u0026#39; } # 随机生成密码 def generate_random_password(length=12): characters = string.ascii_letters + string.digits + string.punctuation return \u0026#39;\u0026#39;.join(random.choice(characters) for i in range(length)) # 从 JSON 文件中读取备份数据 def load_backup_data(): with open(\u0026#34;dump_gitlab_data.json\u0026#34;, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: return json.load(f) # 创建用户 def create_user(username, email, password): url = f\u0026#34;{NEW_GITLAB_URL}/api/v4/users\u0026#34; data = { \u0026#34;username\u0026#34;: username, \u0026#34;name\u0026#34;: username, \u0026#34;email\u0026#34;: email, \u0026#34;password\u0026#34;: password, \u0026#34;skip_confirmation\u0026#34;: True, \u0026#34;force_random_password\u0026#34;: True # 强制用户首次登录时修改密码 } try: response = requests.post(url, headers=HEADERS, data=data) response.raise_for_status() logger.info(f\u0026#34;User {username} created successfully.\u0026#34;) return response.json() # 返回包含用户信息的 JSON except requests.RequestException as e: logger.error(f\u0026#34;Error creating user {username}: {e}\u0026#34;) return None # 创建项目 def create_project(group_id, project_name): url = f\u0026#34;{NEW_GITLAB_URL}/api/v4/projects\u0026#34; data = { \u0026#34;name\u0026#34;: project_name, \u0026#34;namespace_id\u0026#34;: group_id, # 将项目放入指定的组 \u0026#34;visibility\u0026#34;: \u0026#34;private\u0026#34;, \u0026#34;initialize_with_readme\u0026#34;: False # 默认创建空项目 } try: response = requests.post(url, headers=HEADERS, data=data) response.raise_for_status() logger.info(f\u0026#34;Project {project_name} created successfully in group {group_id}.\u0026#34;) return response.json() # 返回创建的项目数据 except requests.RequestException as e: logger.error(f\u0026#34;Error creating project {project_name} in group {group_id}: {e}\u0026#34;) return None # 创建分组 def create_group(group_name): url = f\u0026#34;{NEW_GITLAB_URL}/api/v4/groups\u0026#34; data = { \u0026#34;name\u0026#34;: group_name, \u0026#34;path\u0026#34;: group_name.lower().replace(\u0026#34; \u0026#34;, \u0026#34;_\u0026#34;) # 自动生成路径 } try: response = requests.post(url, headers=HEADERS, data=data) response.raise_for_status() logger.info(f\u0026#34;Group {group_name} created successfully.\u0026#34;) return response.json() # 返回包含分组信息的 JSON except requests.RequestException as e: logger.error(f\u0026#34;Error creating group {group_name}: {e}\u0026#34;) return None # 添加用户到分组并设置权限为 master def add_user_to_group(group_id, user_id, access_level=40): url = f\u0026#34;{NEW_GITLAB_URL}/api/v4/groups/{group_id}/members\u0026#34; data = { \u0026#34;user_id\u0026#34;: user_id, \u0026#34;access_level\u0026#34;: access_level # 权限设置为 master (40) } try: response = requests.post(url, headers=HEADERS, data=data) response.raise_for_status() logger.info(f\u0026#34;User {user_id} added to group {group_id} with master access.\u0026#34;) except requests.RequestException as e: logger.error(f\u0026#34;Error adding user {user_id} to group {group_id}: {e}\u0026#34;) # 导入用户、分组和项目 def import_data(): logger.add(\u0026#34;import_gitlab_entities.log\u0026#34;, rotation=\u0026#34;500 MB\u0026#34;, compression=\u0026#34;zip\u0026#34;) # 读取备份数据 backup_data = load_backup_data() # 存储用户名、邮箱、密码 user_passwords = [] # 创建用户 for user in backup_data[\u0026#34;users\u0026#34;]: username = user[\u0026#34;username\u0026#34;] email = user[\u0026#34;email\u0026#34;] password = generate_random_password() user_data = create_user(username, email, password) if user_data: user_id = user_data[\u0026#34;id\u0026#34;] user_passwords.append({\u0026#34;username\u0026#34;: username, \u0026#34;email\u0026#34;: email, \u0026#34;password\u0026#34;: password}) # 创建用户的项目 for project in user[\u0026#34;projects\u0026#34;]: project_name = project[\u0026#34;name\u0026#34;] # 查找项目所属的分组 group_name = project[\u0026#34;namespace\u0026#34;][\u0026#34;name\u0026#34;] # 创建项目时需要使用分组ID，首先获取分组的 ID group_id = None for group in backup_data[\u0026#34;groups\u0026#34;]: if group[\u0026#34;name\u0026#34;] == group_name: group_id = create_group(group_name)[\u0026#34;id\u0026#34;] break if group_id: create_project(group_id, project_name) # 创建项目后，将用户添加到分组中 add_user_to_group(group_id, user_id) # 创建分组和项目 for group in backup_data[\u0026#34;groups\u0026#34;]: group_name = group[\u0026#34;name\u0026#34;] group_data = create_group(group_name) if group_data: group_id = group_data[\u0026#34;id\u0026#34;] # 创建分组中的项目 for project in group[\u0026#34;projects\u0026#34;]: project_name = project[\u0026#34;name\u0026#34;] create_project(group_id, project_name) # 添加对应的用户到分组，并设置为 master 权限 for group_user in group[\u0026#34;users\u0026#34;]: add_user_to_group(group_id, group_user[\u0026#34;user_id\u0026#34;]) # 将用户名、邮箱、密码保存到 JSON 文件 with open(\u0026#34;user_passwords.json\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: json.dump(user_passwords, f, ensure_ascii=False, indent=4) logger.info(\u0026#34;User passwords have been exported to user_passwords.json\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: import_data() 提交Git 裸仓库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 import os import subprocess import json from loguru import logger # 读取配置的 JSON 文件 def load_config(file_path): with open(file_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: return json.load(f) # 将操作结果写入到 JSON 文件 def write_result_to_json(results, output_file): with open(output_file, \u0026#39;w+\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: json.dump(results, f, indent=4, ensure_ascii=False) # 推送裸仓库到新远端 def push_bare_repo_to_remote(project, results): absolute_path = project[\u0026#34;absolute_path\u0026#34;] new_ssh_url_to_repo = project[\u0026#34;new_ssh_url_to_repo\u0026#34;] # 检查仓库路径是否合法 if not os.path.isdir(absolute_path) or not os.path.exists(os.path.join(absolute_path, \u0026#34;HEAD\u0026#34;)): logger.error(f\u0026#34;Invalid bare repository path: {absolute_path}\u0026#34;) results.append({ \u0026#34;project\u0026#34;: project, \u0026#34;status\u0026#34;: \u0026#34;failed\u0026#34;, \u0026#34;message\u0026#34;: f\u0026#34;Invalid bare repository path: {absolute_path}\u0026#34; }) return try: # 进入原始仓库目录 logger.info(f\u0026#34;Accessing local bare repository: {absolute_path}\u0026#34;) os.chdir(absolute_path) # 确保是裸仓库 subprocess.run([\u0026#34;git\u0026#34;, \u0026#34;rev-parse\u0026#34;, \u0026#34;--is-bare-repository\u0026#34;], check=True) # 设置新的远端地址 logger.info(f\u0026#34;Setting new remote URL: {new_ssh_url_to_repo}\u0026#34;) subprocess.run([\u0026#34;git\u0026#34;, \u0026#34;remote\u0026#34;, \u0026#34;add\u0026#34;, \u0026#34;new-origin\u0026#34;, new_ssh_url_to_repo], check=True) # 推送所有分支到新远端 logger.info(\u0026#34;Pushing all branches to the new remote repository\u0026#34;) subprocess.run([\u0026#34;git\u0026#34;, \u0026#34;push\u0026#34;, \u0026#34;new-origin\u0026#34;, \u0026#34;--all\u0026#34;,\u0026#34;-f\u0026#34;], check=True) # 推送所有标签到新远端 logger.info(\u0026#34;Pushing all tags to the new remote repository\u0026#34;) subprocess.run([\u0026#34;git\u0026#34;, \u0026#34;push\u0026#34;, \u0026#34;new-origin\u0026#34;, \u0026#34;--tags\u0026#34;], check=True) results.append({ \u0026#34;project\u0026#34;: project, \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;message\u0026#34;: f\u0026#34;Successfully pushed to {new_ssh_url_to_repo}\u0026#34; }) except subprocess.CalledProcessError as e: logger.error(f\u0026#34;Error during git operations: {e}\u0026#34;) results.append({ \u0026#34;project\u0026#34;: project, \u0026#34;status\u0026#34;: \u0026#34;failed\u0026#34;, \u0026#34;message\u0026#34;: f\u0026#34;Error during git operations: {str(e)}\u0026#34; }) except Exception as e: logger.exception(\u0026#34;Unexpected error occurred\u0026#34;) results.append({ \u0026#34;project\u0026#34;: project, \u0026#34;status\u0026#34;: \u0026#34;failed\u0026#34;, \u0026#34;message\u0026#34;: f\u0026#34;Unexpected error: {str(e)}\u0026#34; }) finally: # 移除新远端配置以保持原始仓库清洁 try: subprocess.run([\u0026#34;git\u0026#34;, \u0026#34;remote\u0026#34;, \u0026#34;remove\u0026#34;, \u0026#34;new-origin\u0026#34;], check=True) except subprocess.CalledProcessError: logger.warning(\u0026#34;Failed to remove new-origin remote, please check manually.\u0026#34;) # 主函数 def main(): config_file = \u0026#39;old_all_projects.json\u0026#39; output_file = \u0026#39;old_all_projects_result_2024.json\u0026#39; projects = load_config(config_file) logger.add(\u0026#34;all_projects_operation_log_2024.log\u0026#34;, rotation=\u0026#34;500 MB\u0026#34;, level=\u0026#34;INFO\u0026#34;, compression=\u0026#34;zip\u0026#34;) results = [] for project in projects: logger.info(f\u0026#34;Processing project: {project[\u0026#39;name\u0026#39;]}\u0026#34;) push_bare_repo_to_remote(project, results) write_result_to_json(results, output_file) logger.info(f\u0026#34;Operation results saved to {output_file}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() ","date":"2024-11-25T08:00:00Z","permalink":"https://liguobao.github.io/p/gitlab-migration-low-version/","title":"Gitlab 低版本迁移简易教程"},{"content":"以下内容转载自知乎，不代表个人观点。\n已剪辑自:\nhttps://henchat.net/%e5%9c%a8%e6%9c%89%e7%83%ad%e6%ad%a6%e5%99%a8%e5%8e%8b%e5%88%b6%e6%9a%b4%e6%b0%91%e7%9a%84%e7%8e%b0%e4%bb%a3%e5%9b%bd%e5%ae%b6%e7%bb%93%e6%9d%9f%e5%a5%b4%e9%9a%b6%e5%88%b6/\n以下内容转载自知乎，不代表个人观点。\n现代奴隶制会亡于原子化的叛乱。\n所谓原子化叛乱，就是没有路线，没有纲领，没有组织，没有诉求，完全是一个个原子化的个体，随机的展开报复社会的行动。他们随性而起，没有规律地进攻任何被他们视作敌人的对象，包括不限于仇人，看不顺眼的路人，妇女儿童，甚至是自己。他们如同一个个堂吉诃德，一个人就是一支叛军，用自己随意想到的方式来反抗社会的秩序，也完全不在意这种反抗会自己带来怎样的结果，一切以给社会造成最大程度的破坏为目标。\n现代奴隶主的热武器是专门为镇压大规模集团化叛乱而设计的，因此集体叛乱的难度比冷兵器时代提高了太多，但个体叛乱的难度却并没有提高很多。原子化叛乱的镇压成本远高于同等规模集体叛乱。一万个普通人集合起来，组成一支反政府军，占领固定的据点，进攻固定的战略要地，无论如何也打不过拥有机枪，坦克，无人机的职业军队。但如果一万个人分散在一万个地方，在一万个随机的时间，随机的地点，朝随机的人群发起随机的攻击，热武器镇压的效率就将大大下降，由此造成的破坏也远超过一万人组成的集团军。比如内蒙古那个杀了一家五口的人，在如此严密的社会监控下也花了十天时间才找到，这种人一旦多起来，带来的治安成本是无法承受的。这就是为什么现代统治者害怕治安战更甚于正面战争。\n当然奴隶主也会未雨绸缪，最好的办法就是使用现代信息手段，将每个人的行踪监视起来，提前瓦解一切潜在的叛乱。这时就体现出个体化叛乱的另一个优势，就是他根本没有组织也没有征兆。现代信息技术可以扼杀大多数密谋组织的叛乱，但难以察觉随性而起的报复社会行为。一个人揣着一把枪走在大街上，满街的摄像头也看不出他脑子里在想什么。你把枪禁了，他就用刀；你把刀禁了，他就开着车上街创人；你把汽车也禁了，他就捡起路边的石头砸人；你把石头也全部清理干净，他就赤手空拳的搞事，比如韩国那个梨泰院事件，就是有人在楼梯口推搡造成人群踩踏，你怎么预防？这个过程中，叛乱者永远处于先手，统治者永远在被动防御，这不是你装几处监控，加几处安检就能杜绝的。\n其实不止热武器，思想镇压的武器也会失效。面对一个接一个随机出现的叛乱者，你无法在道义上攻击他们，在思想上抹黑他们，因为他们既没有道义也没有思想，他们不为任何人谋福利，也不寻求解放任何人，他们不惮于杀害弱小和无辜的人，他们不受任何道德上的，纲领上的，正义上的约束，因此任你再怎么站在道德高地上审视他们，他们也视你的审判如无物。你也无法分化打压他们，他们本身就是一个个原子化的个体，你还能怎么分化？总不能把一个活人分化成无数个细胞吧。你也无法拉一派打一派，他们想起一出是一出，自己都不知道自己是哪派，你环顾四周，个个看起来都是老实人，你手握利剑，既不知道该惩罚谁，也不知道该保护谁，这就是所谓“拔剑四顾心茫然”。\n君以此兴，必以此亡。当奴隶主试图把奴隶集中起来压榨时，最终便会亡于集体化的叛乱；当奴隶主试图把奴隶分割成原子化的个体时，最终便会亡于原子化的叛乱。原子化的叛乱者们就如同病毒细菌，他们随着社会病态的恶化而滋生，传播，扩大，而机枪大炮是杀不死细菌的。\n新时代的叛乱，核心在于“乱”而不在于“叛”。新时代的叛乱者，并不需要将刀刺向统治者或是隶属于统治者的任何暴力机关，他们只需要将刀刺向身边够得着的人，不管是有仇的人还是没仇的人，认识的人还是不认识的人，身强力壮的人还是老弱病残的人，实在没人了就刺向自己，这种行为本身就是对奴隶制统治根基的动摇。奴隶制和任何契约社会一样，也是建立在群体的共同信念的基础上的，任何形式的混乱都会导致这种信念的崩塌。每多一个报复社会的人，混乱度就增加一分，奴隶社会也就向着原始丛林社会更靠近一步。而当越来越多的人开始具有随机的攻击性，越来越多的个体如同布朗运动般横冲直撞，统治者最终会发现，自己的社会规则再也无法驾驭这个不断增熵的世界，奴隶制也就走到了尽头。\n","date":"2024-11-14T23:09:00Z","permalink":"https://liguobao.github.io/p/how-to-end-sl-avery-in-a-modern-country-where-there-are/","title":"在有热武器可以压制暴民的现代国家，结束奴隶制需要有什么条件？"},{"content":"在 Linux 或 macOS 系统中，\n你可以使用 du 命令来获取当前文件夹中每个一级子目录的大小。可以使用以下命令：\n1 du -h --max-depth=1 -h 选项表示以人类可读的格式显示大小（例如 KB、MB 或 GB）。 --max-depth=1 表示只查看当前目录下的一级子目录的大小。 如果你希望仅查看当前目录的总大小，可以使用：\n1 du -sh . -s 选项表示显示总计而不是逐个列出每个目录。 上述命令可以帮助你快速了解当前文件夹中每个子目录的大小。\n","date":"2024-08-07T08:00:00Z","permalink":"https://liguobao.github.io/p/linux-du/","title":"Linux du 命令"},{"content":"npm.taobao.org https 证书过期 这玩意过期也不是一两天了，所有用了依赖这个镜像源的都会直接报错。 前阵子因为查构建失败问题，折腾了好几个小时才意识到是证书过期了。 一开始以为是自己的网络问题，后来发现是源的问题。 虽然这个域名已经被cname到 registry.npmmirror.com，然而在npm的时候，并不会自动跳转到这个新的域名。\nSo，依旧构建失败。\n解决方案 1 2 npm config set registry registry.npmmirror.com npm config set registry registry.npmjs.org 如果项目根目录有 .npmrc 文件，记得要改下这个文件。\n1 registry=https://registry.npmmirror.com 切记 不要过度依赖某厂商的服务，尤其是国内的。 有时候，不如直接用官方源。 ","date":"2024-08-06T08:00:00Z","image":"https://liguobao.github.io/p/npm-taobao-org-exp/npm_hu_2d1df1aaa48eef37.png","permalink":"https://liguobao.github.io/p/npm-taobao-org-exp/","title":"npm.taobao.org 淘宝镜像源证书过期解决方案"},{"content":"社区整体策略 回答为主 以运营团队为核心，产研驱动。\n创作者为中心，创作为王。\n知乎为深度内容社区。\n产研驱动有什么 居委会、答主为业主 推荐算法升级 冷启动优化 算法目的调整 社区治理（引战、对立、内容管控；大概2%评论直接被清理。） 生态结构、鼓励专业垂直 以前，流量为王，PV、UV 为核心指标。\n当前，深度内容、互动为重要指标。\n热榜体验优化 降低引战、对立 内容运营策略调整 产品体验：取消折叠、新增精选 问题页排序：低质打压、TPR优化 True Positive Rate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 TPR排序，全称为\u0026#34;True Positive Rate\u0026#34;排序，是一种在数据科学和机器学习领域常用的性能评估方式，尤其在处理分类任务时。\u0026#34;True Positive Rate\u0026#34;（真正例率），也被称为敏感度（Sensitivity）或召回率（Recall），是用于衡量模型正确识别正类的能力。 在分类任务中，将数据集分为正类（我们感充趣的类）和负类。对于一个给定的分类模型： - 真正例（True Positive, TP）的数量是模型正确预测为正类的样本数量。 - 假正例（False Positive, FP）的数量是模型错误预测为正类的样本数量（实际上是负类）。 - 真负例（True Negative, TN）的数量是模型正确预测为负类的样本数量。 - 假负例（False Negative, FN）的数量是模型错误预测为负类的样本数量（实际上是正类）。 True Positive Rate（TPR）的计算方法如下： \\[ TPR = \\frac{TP}{TP + FN} \\] 这个比例反映了所有实际正类样本中，被模型正确识别出来的比例。TPR越高，表示模型对正类的识别能力越强。 TPR排序实际上是根据不同配置、阈值或模型下的TPR值来进行排序，从而评估和选择最优的模型或设置。在某些应用场景，如疾病筛查或欺诈检测中，高TPR尤为重要，因为我们希望尽可能多地识别出所有可能的正类（如病例或欺诈行为），即使这意味着会有更多的假正例（FP）。 综上，TPR排序是一种以模型或方法的真正例率作为标准进行比较和排序的方法，广泛应用于模型选择和性能比较中。 用户沟通机制 反馈 AI内容的态度 观点提取、相似度、质量、可信度 抄袭识别与打击 反爬虫（SEO屏蔽了？） AIGC、Spam 识别 -\u0026gt; 限制分发、对于恶意账号处置\nAI自己的“AI直答”呢？引用了谁的内容做了什么回答？给了\nFor 作者体验 好问题 提问被弱化了 重复问题呢？刷问题的呢？（我能看到部分用户几千个提问和编辑问题）。这块的反作弊呢？ 消息提醒优化 专栏 升级、曝光、增加流通、支持付费 知乎日报呢？ SEO很高，内容质量很高（什么时候能重新开放？） 知乎直答-AI搜索 ? ","date":"2024-07-28T08:00:00Z","permalink":"https://liguobao.github.io/p/zhihu-salon-0728/","title":"知乎盐沙龙-20240728"},{"content":"Visual Studio 2022 配置 Git Bash\n不需要赘言 how-can-i-use-a-git-bash-terminal-profile-in-visual-studio-2019\nShell Location:C:\\Program Files\\Git\\bin\\sh.exe\n路径\nC:\\Program Files\\Git\\bin\\sh.exe\n如果你的安装目录不在这里，自行调整哈。\n参数\n\u0026ndash;login -i -l\n最终效果。\n","date":"2024-07-27T08:00:00Z","image":"https://liguobao.github.io/p/vs-git-bash/bash_hu_8d2d5eb1b72de8ee.jpg","permalink":"https://liguobao.github.io/p/vs-git-bash/","title":"Visual Studio 添加Git Bash 到终端"},{"content":"需求 之前在C++实现过一个获取硬件信息的接口，\n用的是 hwinfo,\n大概返回了下面的硬件信息。\n1 { \u0026#34;cpuModel\u0026#34;: \u0026#34;12th Gen Intel(R) Core(TM) i7-12700K\u0026#34;, \u0026#34;gpuName\u0026#34;: \u0026#34;Microsoft Remote Display Adapter | NVIDIA GeForce RTX 3070\u0026#34;, \u0026#34;ramVendor\u0026#34;: \u0026#34;A-DATA Technology\u0026#34;, \u0026#34;ramSerialNumber\u0026#34;: \u0026#34;CC500\u0026#34;, \u0026#34;ramTotalSizeBytes\u0026#34;: 34359740000, \u0026#34;ramFreeSizeBytes\u0026#34;: -1, \u0026#34;mainBoardVendor\u0026#34;: \u0026#34;Rev 1.xx\u0026#34;, \u0026#34;mainBoardName\u0026#34;: \u0026#34;PRIME Z690-P D4\u0026#34;, \u0026#34;mainBoardSerialNumber\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;disks\u0026#34;: [ { \u0026#34;model\u0026#34;: \u0026#34;ST12000VN0008-2YS101\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34; ZRT0DJ\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;12000132426240\u0026#34;, \u0026#34;freeSize\u0026#34;: \u0026#34;-1\u0026#34; }, { \u0026#34;model\u0026#34;: \u0026#34;Samsung SSD 980 1TB\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34;0025.\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;1000202273280\u0026#34;, \u0026#34;freeSize\u0026#34;: \u0026#34;-1\u0026#34; }, { \u0026#34;model\u0026#34;: \u0026#34;WDC WD10EZEX-00BBHA0\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34; WD-WATM2266\u0026#34;, \u0026#34;size\u0026#34;: \u0026#34;1000202273280\u0026#34;, \u0026#34;freeSize\u0026#34;: \u0026#34;-1\u0026#34; } ], \u0026#34;osOperatingSystem\u0026#34;: \u0026#34;19044\u0026#34;, \u0026#34;osShortName\u0026#34;: \u0026#34;Windows\u0026#34;, \u0026#34;osArchitecture\u0026#34;: \u0026#34;32 bit\u0026#34;, \u0026#34;diskTotalSize\u0026#34;: 14000536972800, \u0026#34;logicDiskTotalFreeSpace\u0026#34;: 0 } 代码没撒看的，基本都是调库，hwinfo 的样例写得还不错~\n不过前几天发现这玩意偶尔会崩掉，\n错误是0000005，应该是内存访问错误，\n道理来是个空引用触发的。\n老早之前还给这个库修个字符串编码的Bug，\n在后面老哥应该还升级过几个版本，\n我自己太忙了也就没空再折腾了。\n想了下，\n算了，先用Python实现一个吧。\n问问GPT？ Q： 1、我想在Python3 中实现电脑硬件信息读取，返回上面的JSON，请问如何处理。 2、帮我兼容一下，如果不在Windows平台的话，尽可能给足够的信息回去，没有的信息给默认值即可。 3、对应的库版本是哪些？给我个requirements\nA：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 import psutil import cpuinfo import GPUtil import platform import json def get_cpu_info(): try: cpu = cpuinfo.get_cpu_info() return cpu[\u0026#39;brand_raw\u0026#39;] except Exception as e: return f\u0026#34;Unknown CPU ({e})\u0026#34; def get_gpu_info(): try: gpus = GPUtil.getGPUs() return \u0026#34; | \u0026#34;.join([gpu.name for gpu in gpus]) except Exception as e: return f\u0026#34;Unknown GPU ({e})\u0026#34; def get_ram_info(): try: if platform.system() == \u0026#34;Windows\u0026#34;: import wmi c = wmi.WMI() for memory in c.Win32_PhysicalMemory(): ram_vendor = memory.Manufacturer ram_serial_number = memory.SerialNumber ram_total_size = int(memory.Capacity) ram_free_size = psutil.virtual_memory().available return ram_vendor, ram_serial_number, ram_total_size, ram_free_size else: vm = psutil.virtual_memory() return \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Serial\u0026#34;, vm.total, vm.available except Exception as e: return \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Serial\u0026#34;, -1, -1 def get_mainboard_info(): try: if platform.system() == \u0026#34;Windows\u0026#34;: import wmi c = wmi.WMI() for board in c.Win32_BaseBoard(): mainboard_vendor = board.Manufacturer mainboard_name = board.Product mainboard_serial = board.SerialNumber return mainboard_vendor, mainboard_name, mainboard_serial else: return \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Board\u0026#34;, \u0026#34;Unknown Serial\u0026#34; except Exception as e: return \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Board\u0026#34;, f\u0026#34;Unknown Serial ({e})\u0026#34; def get_disk_info(): try: if platform.system() == \u0026#34;Windows\u0026#34;: import wmi c = wmi.WMI() disks = [] for disk in c.Win32_DiskDrive(): model = disk.Model serial_number = disk.SerialNumber.strip() size = int(disk.Size) disks.append({ \u0026#34;model\u0026#34;: model, \u0026#34;serialNumber\u0026#34;: serial_number, \u0026#34;size\u0026#34;: size, \u0026#34;freeSize\u0026#34;: -1 }) return disks else: disks = [] for disk in psutil.disk_partitions(): usage = psutil.disk_usage(disk.mountpoint) disks.append({ \u0026#34;model\u0026#34;: \u0026#34;Unknown Model\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34;Unknown Serial\u0026#34;, \u0026#34;size\u0026#34;: usage.total, \u0026#34;freeSize\u0026#34;: usage.free }) return disks except Exception as e: return [{\u0026#34;model\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;size\u0026#34;: -1, \u0026#34;freeSize\u0026#34;: -1}] def get_os_info(): try: os_version = platform.version() os_short_name = platform.system() os_arch = platform.architecture()[0] return os_version, os_short_name, os_arch except Exception as e: return \u0026#34;Unknown\u0026#34;, \u0026#34;Unknown\u0026#34;, \u0026#34;Unknown\u0026#34; def get_total_disk_size_and_free_space(): try: total_size = 0 total_free_space = 0 for partition in psutil.disk_partitions(): try: usage = psutil.disk_usage(partition.mountpoint) total_size += usage.total total_free_space += usage.free except PermissionError: continue # 避免某些磁盘没有权限访问导致的错误 return total_size, total_free_space except Exception as e: return -1, -1 def get_hardware_info(): cpu_model = get_cpu_info() gpu_name = get_gpu_info() ram_vendor, ram_serial_number, ram_total_size, ram_free_size = get_ram_info() mainboard_vendor, mainboard_name, mainboard_serial_number = get_mainboard_info() disks = get_disk_info() os_version, os_short_name, os_arch = get_os_info() total_disk_size, total_free_space = get_total_disk_size_and_free_space() return { \u0026#34;cpuModel\u0026#34;: cpu_model, \u0026#34;gpuName\u0026#34;: gpu_name, \u0026#34;ramVendor\u0026#34;: ram_vendor, \u0026#34;ramSerialNumber\u0026#34;: ram_serial_number, \u0026#34;ramTotalSizeBytes\u0026#34;: ram_total_size, \u0026#34;ramFreeSizeBytes\u0026#34;: ram_free_size, \u0026#34;mainBoardVendor\u0026#34;: mainboard_vendor, \u0026#34;mainBoardName\u0026#34;: mainboard_name, \u0026#34;mainBoardSerialNumber\u0026#34;: mainboard_serial_number, \u0026#34;disks\u0026#34;: disks, \u0026#34;osOperatingSystem\u0026#34;: os_version, \u0026#34;osShortName\u0026#34;: os_short_name, \u0026#34;osArchitecture\u0026#34;: os_arch, \u0026#34;diskTotalSize\u0026#34;: total_disk_size, \u0026#34;logicDiskTotalFreeSpace\u0026#34;: total_free_space } if __name__ == \u0026#34;__main__\u0026#34;: hardware_info = get_hardware_info() print(json.dumps(hardware_info, indent=2)) 优化 get_hardware_info 这个函数执行比较慢，能优化一下吗？ 部分信息获取之后应该是可以缓存起来的 我使用的lorugu 库，请帮我加一些日志，确认一下调用耗时 我的日志使用标准输出即可，不用写文件；lru_cache 可以设置过期时间吗? get_cpu_info太慢了 2024-07-05 16:24:16.370 | INFO | main:get_cpu_info:54 - get_cpu_info() took 1.1144 seconds\ncpu = cpuinfo.get_cpu_info() 为嘛它这么慢，有其他的实现吗？\n最终代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 import psutil import GPUtil import platform import json import time import subprocess from functools import wraps from loguru import logger from datetime import datetime, timedelta # 配置 loguru 将日志输出到标准输出 logger.remove() logger.add(lambda msg: print(msg, end=\u0026#39;\u0026#39;)) # 自定义缓存装饰器 def timed_lru_cache(seconds: int, maxsize: int = 128): def wrapper(func): cache = {} cache_expiration = {} @wraps(func) def inner(*args): now = datetime.now() # 清除过期缓存 for key in list(cache_expiration): if cache_expiration[key] \u0026lt; now: cache.pop(key, None) cache_expiration.pop(key, None) if args in cache: return cache[args] result = func(*args) cache[args] = result cache_expiration[args] = now + timedelta(seconds=seconds) if len(cache) \u0026gt; maxsize: oldest = min(cache_expiration, key=cache_expiration.get) cache.pop(oldest, None) cache_expiration.pop(oldest, None) return result return inner return wrapper @timed_lru_cache(60) def get_cpu_info(): start_time = time.time() try: if platform.system() == \u0026#34;Windows\u0026#34;: result = subprocess.run([\u0026#39;wmic\u0026#39;, \u0026#39;cpu\u0026#39;, \u0026#39;get\u0026#39;, \u0026#39;Name\u0026#39;], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True) cpu_model = result.stdout.split(\u0026#39;\\n\u0026#39;)[1].strip() elif platform.system() == \u0026#34;Linux\u0026#34;: result = subprocess.run([\u0026#39;lscpu\u0026#39;], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True) for line in result.stdout.split(\u0026#39;\\n\u0026#39;): if \u0026#39;Model name\u0026#39; in line: cpu_model = line.split(\u0026#39;:\u0026#39;)[1].strip() break elif platform.system() == \u0026#34;Darwin\u0026#34;: result = subprocess.run([\u0026#39;sysctl\u0026#39;, \u0026#39;-n\u0026#39;, \u0026#39;machdep.cpu.brand_string\u0026#39;], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True) cpu_model = result.stdout.strip() else: cpu_model = \u0026#34;Unsupported platform\u0026#34; except Exception as e: cpu_model = f\u0026#34;Unknown CPU ({e})\u0026#34; end_time = time.time() logger.info(f\u0026#34;get_cpu_info() took {end_time - start_time:.3f} seconds\u0026#34;) return cpu_model @timed_lru_cache(60) def get_gpu_info(): start_time = time.time() try: gpus = GPUtil.getGPUs() gpu_name = \u0026#34; | \u0026#34;.join([gpu.name for gpu in gpus]) except Exception as e: gpu_name = f\u0026#34;Unknown GPU ({e})\u0026#34; end_time = time.time() logger.info(f\u0026#34;get_gpu_info() took {end_time - start_time:.3f} seconds\u0026#34;) return gpu_name @timed_lru_cache(60) def get_ram_info(): start_time = time.time() try: if platform.system() == \u0026#34;Windows\u0026#34;: import wmi c = wmi.WMI() for memory in c.Win32_PhysicalMemory(): ram_vendor = memory.Manufacturer ram_serial_number = memory.SerialNumber ram_total_size = int(memory.Capacity) ram_free_size = psutil.virtual_memory().available break else: vm = psutil.virtual_memory() ram_vendor, ram_serial_number, ram_total_size, ram_free_size = \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Serial\u0026#34;, vm.total, vm.available except Exception as e: ram_vendor, ram_serial_number, ram_total_size, ram_free_size = \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Serial\u0026#34;, -1, -1 end_time = time.time() logger.info(f\u0026#34;get_ram_info() took {end_time - start_time:.3f} seconds\u0026#34;) return ram_vendor, ram_serial_number, ram_total_size, ram_free_size @timed_lru_cache(60) def get_mainboard_info(): start_time = time.time() try: if platform.system() == \u0026#34;Windows\u0026#34;: import wmi c = wmi.WMI() for board in c.Win32_BaseBoard(): mainboard_vendor = board.Manufacturer mainboard_name = board.Product mainboard_serial = board.SerialNumber break else: mainboard_vendor, mainboard_name, mainboard_serial = \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Board\u0026#34;, \u0026#34;Unknown Serial\u0026#34; except Exception as e: mainboard_vendor, mainboard_name, mainboard_serial = \u0026#34;Unknown Vendor\u0026#34;, \u0026#34;Unknown Board\u0026#34;, f\u0026#34;Unknown Serial ({e})\u0026#34; end_time = time.time() logger.info(f\u0026#34;get_mainboard_info() took {end_time - start_time:.3f} seconds\u0026#34;) return mainboard_vendor, mainboard_name, mainboard_serial @timed_lru_cache(60) def get_disk_info(): start_time = time.time() try: if platform.system() == \u0026#34;Windows\u0026#34;: import wmi c = wmi.WMI() disks = [] for disk in c.Win32_DiskDrive(): model = disk.Model serial_number = disk.SerialNumber.strip() size = int(disk.Size) disks.append({ \u0026#34;model\u0026#34;: model, \u0026#34;serialNumber\u0026#34;: serial_number, \u0026#34;size\u0026#34;: size, \u0026#34;freeSize\u0026#34;: -1 }) else: disks = [] for disk in psutil.disk_partitions(): usage = psutil.disk_usage(disk.mountpoint) disks.append({ \u0026#34;model\u0026#34;: \u0026#34;Unknown Model\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34;Unknown Serial\u0026#34;, \u0026#34;size\u0026#34;: usage.total, \u0026#34;freeSize\u0026#34;: usage.free }) except Exception as e: disks = [{\u0026#34;model\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;serialNumber\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;size\u0026#34;: -1, \u0026#34;freeSize\u0026#34;: -1}] end_time = time.time() logger.info(f\u0026#34;get_disk_info() took {end_time - start_time:.3f} seconds\u0026#34;) return disks @timed_lru_cache(60) def get_os_info(): start_time = time.time() try: os_version = platform.version() os_short_name = platform.system() os_arch = platform.architecture()[0] except Exception as e: os_version, os_short_name, os_arch = \u0026#34;Unknown\u0026#34;, \u0026#34;Unknown\u0026#34;, \u0026#34;Unknown\u0026#34; end_time = time.time() logger.info(f\u0026#34;get_os_info() took {end_time - start_time:.3f} seconds\u0026#34;) return os_version, os_short_name, os_arch @timed_lru_cache(60) def get_total_disk_size_and_free_space(): start_time = time.time() try: total_size = 0 total_free_space = 0 for partition in psutil.disk_partitions(): try: usage = psutil.disk_usage(partition.mountpoint) total_size += usage.total total_free_space += usage.free except PermissionError: continue # 避免某些磁盘没有权限访问导致的错误 except Exception as e: total_size, total_free_space = -1, -1 end_time = time.time() logger.info(f\u0026#34;get_total_disk_size_and_free_space() took {end_time - start_time:.3f} seconds\u0026#34;) return total_size, total_free_space def get_hardware_info(): start_time = time.time() cpu_model = get_cpu_info() gpu_name = get_gpu_info() ram_vendor, ram_serial_number, ram_total_size, ram_free_size = get_ram_info() mainboard_vendor, mainboard_name, mainboard_serial_number = get_mainboard_info() disks = get_disk_info() os_version, os_short_name, os_arch = get_os_info() total_disk_size, total_free_space = get_total_disk_size_and_free_space() end_time = time.time() logger.info(f\u0026#34;get_hardware_info() took {end_time - start_time:.3f} seconds\u0026#34;) return { \u0026#34;cpuModel\u0026#34;: cpu_model, \u0026#34;gpuName\u0026#34;: gpu_name, \u0026#34;ramVendor\u0026#34;: ram_vendor, \u0026#34;ramSerialNumber\u0026#34;: ram_serial_number, \u0026#34;ramTotalSizeBytes\u0026#34;: ram_total_size, \u0026#34;ramFreeSizeBytes\u0026#34;: ram_free_size, \u0026#34;mainBoardVendor\u0026#34;: mainboard_vendor, \u0026#34;mainBoardName\u0026#34;: mainboard_name, \u0026#34;mainBoardSerialNumber\u0026#34;: mainboard_serial_number, \u0026#34;disks\u0026#34;: disks, \u0026#34;osOperatingSystem\u0026#34;: os_version, \u0026#34;osShortName\u0026#34;: os_short_name, \u0026#34;osArchitecture\u0026#34;: os_arch, \u0026#34;diskTotalSize\u0026#34;: total_disk_size, \u0026#34;logicDiskTotalFreeSpace\u0026#34;: total_free_space } if __name__ == \u0026#34;__main__\u0026#34;: hardware_info = get_hardware_info() print(json.dumps(hardware_info, indent=2)) requirements.txt 1 2 3 4 5 psutil==5.9.5 gputil==1.4.0 WMI==1.5.1; sys_platform == \u0026#39;win32\u0026#39; pywin32==306; sys_platform == \u0026#39;win32\u0026#39; loguru==0.5.3 总结 我一句代码都没写。jpg 确实GPT过于强大。jpg GPT确实需要调教。jpg ","date":"2024-07-08T08:00:00Z","image":"https://liguobao.github.io/p/how-to-get-hwinfo-by-python/logo_hu_71686341b1fc3fa2.png","permalink":"https://liguobao.github.io/p/how-to-get-hwinfo-by-python/","title":"通过Python获取计算机的硬件信息，包括CPU、GPU、内存、主板、硬盘、操作系统等。"},{"content":"前言 也不要问为什么要搞这个了，\n你都看到这个文章的话，\n还有兴趣看下去的话，\n那就是你也有这个需求了。\n什么是 Magisk Introduction Magisk is a suite of open source software for customizing Android,\nsupporting devices higher than Android 6.0.\nSome highlight features:\nMagiskSU: Provide root access for applications Magisk Modules: Modify read-only partitions by installing modules MagiskBoot: The most complete tool for unpacking and repacking Android boot images Zygisk: Run code in every Android applications\u0026rsquo; processes Powered by Magisk\n操作步骤预览 解BL锁 安装 Magisk App 下载对应系统版本的ROM包提取boot.img 使用 Magisk 修改boot.img 刷入修改后的boot.img 安装 Magisk 模块 享受”自由新世界“ 解BL锁 蛇有蛇路，shu有shu路，自己看着办了。 小米设备可以参考 Xiaomi 解BL锁 一加设备可以参考 OnePlus 阿木大侠 其他设备请自行搜索 2024年，最好解锁的设备，是 OnePlus 了。\n其他的，都是弟弟。\n（ 本来考虑要不买台小米14的，因为BL锁劝退了十年米粉）\n安装 Magisk App 下载 Magisk/releases 下载后，自行安装到手机上。\n1 2 adb install Magisk-v26.4.apk 提取boot.img 下载对应系统版本的ROM包提取boot.img 如果是卡刷包，可以直接解压，找到boot.img\n如果是线刷包，解压之后得到的是 playload.bin，需要使用工具解压。\nWindows上可以使用FastbootEnhance工具，Mac/Linux上可以使用payload_dumper工具。\n基本大同小异。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 使用 Magisk 生成修补后的boot.img - Magisk App -\u0026gt; Install -\u0026gt; Install -\u0026gt; Select and Patch a File -\u0026gt; 选择boot.img - 等待生成修补后的boot.img，自动保存到 /sdcard/Download/magisk_patched-xxx.img ## 刷入修改后的boot.img - 手机进入Fastboot模式，连接电脑 ```sh # 检查设备是否连接成功 fastboot devices; # 刷入修改后的boot.img fastboot flash boot /sdcard/Download/magisk_patched-xxx.img 刷入完成后，重启手机。\nMagisk 激活 重启手机之后，重新打开Magisk App，第一次应该会提示需要启动修复。\n正常情况下，修复完成后会重启手机，再次开机后就完事了。\n安装 Magisk 模块 下载面具模块，在本地安装即可。 大体流程基本如此。\n常用命令列表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 进入Fastboot模式 adb reboot bootloader # 检查fastboot设备是否连接成功 fastboot devices #解锁 fastboot oem unlock # 其他设备解BL锁 fastboot flashing unlock # 刷入boot.img fastboot flash boot ./Download/magisk_patched-xxx.img # 重启 fastboot reboot LineageOS Build Archive 下载 LineageOS 老版本 lineageos 最新版本 LineageOS 设置网络探测地址 更换 captive 连接验证服务器\n1 2 3 4 5 6 7 8 adb shell settings delete global captive_portal_https_url adb shell settings delete global captive_portal_http_url adb shell settings put global captive_portal_https_url https://connect.rom.miui.com/generate_204 adb shell settings put global captive_portal_http_url http://connect.rom.miui.com/generate_204 ","date":"2024-07-05T08:00:00Z","image":"https://liguobao.github.io/p/android-magisk-install/logo_hu_a0a3b448a4bc4104.png","permalink":"https://liguobao.github.io/p/android-magisk-install/","title":"用 Magisk 开始你的安卓折腾之路"},{"content":"前言 大概在去年还是前年的时候，因为手机换成了iOS，没有小爱同学了之后，\n只能使用米家App来控制米家设备实在蛋疼，\n于是那阵子就折腾过 HomeAssistant 方案， 于是写过这样的文章。\n知乎专栏：Home Assistant 智能家居系统搭建指南（米家+Siri）\n这个方案配合HomePod音响，基本满足了我的需求了。\n后面家里基本是就是各种设备都有一点，HomePod基本就是全屋中控的存在了。\nHome Assistant 在家里的主机24小时跑着，基本也没出什么岔子，也就很久继续折腾了。\n又一个“新需求” 年初有个大佬找过我，咨询能不能基于现在的米家或者其他硬件设备，自己做公寓的智能家居方案。\n基于上面的一些经验，我也就给了一些建议，但是也没深入去研究。\n那阵子让某二十年老师去折腾了一下DIY控制米家设备的方案，\n这朋友的进度不那么理想，最后也没出什么成果。\n只是那阵子知道了有一个\ngithub.com/rytilahti/python-miio 的好工具。\nPython library \u0026amp; console tool for controlling Xiaomi smart appliances 一个用于控制小米智能家居设备的Python库和控制台工具 很有趣，Mark 一下。\n最近的实践 最近嘛，又因为一些奇奇怪怪的需求，需要“正儿八经”来折腾米家设备控制方案了。\n最早做方案验证的时候，甚至是用Appium来模拟操作米家App\n但是嘛，卡顿，慢，不稳定\u0026hellip;\n到了这两周开始进入正式的实践阶段，决定还是用 python-miio 来搞了，\n虽然Hack，但是肯定比Appium来的稳定。\nSo，让我们开始吧。\npython-miio 起手 首先，我们先在本地安装 python-miio\n1 2 3 4 5 6 7 # 切记，请不要直接安装 pip install python-miio # 默认的Release版本是0.5.12，22年的版本了 pip install python-miio==0.6.0.dev0 # 或者直接从Github上安装最新的版本 pip install git+https://github.com/rytilahti/python-miio.git 这个安装好了之后，本地命令行环境应该有了 miiocli 这个命令行工具了。\n1 2 3 4 5 6 7 8 ➜ ~ miiocli --help Usage: miiocli [OPTIONS] COMMAND [ARGS]... Options: -d, --debug -o, --output [default|json|json_pretty] --version Show the version and exit. --help Show this message and exit. 正常情况下，我们应该可以通过 miiocli 来控制我们的米家设备了。\n首先，我们需要找到我们的设备的IP地址和Token。\n后面的所有操作，都是基于这两个信息来进行的。\n获取设备IP地址和Token 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ➜ ~ miiocli cloud Username: 你的小米账号 Password: 你的密码 == Xiaomi Smart Camera C400 (Device online ) == Model: chuangmi.camera.039a01 Token: XXX IP: 192.168.31.170 (mac: 94:F8:27:05:5B:AA) DID: 1029838640 Locale: cn == Xiaomi智能摄像机 (Device online ) == Model: chuangmi.camera.029a02 Token: XXX IP: 192.168.31.233 (mac: 60:7E:A4:C0:E6:26) DID: 525571884 Locale: cn == 智能插座-Ubuntu (Device online ) == Model: chuangmi.plug.212a01 Token: XXX IP: 192.168.31.141 (mac: 58:B6:23:EB:11:EF) DID: 433609370 Locale: cn 这里基本能看到自己账号下的设备了，然后我们可以通过 miiocli 命令来控制这些设备了。\n控制设备 1 2 3 4 5 6 7 8 9 # 这是一个摄像头设备 ➜ ~ miiocli device --ip 192.168.31.170 --token xxxx info Running command info Model: chuangmi.camera.039a01 Hardware version: Linux Firmware version: 5.1.6_0420 Supported using: GenericMiot Command: miiocli genericmiot --ip 192.168.31.170 --token xxxx Supported by genericmiot: True 这里需要比较关注的东西是 Supported by genericmiot ,\n有这个的话，基本就可以通过 miiocli genericmiot 来控制这个设备了。\n1 2 3 4 5 6 # Supported by genericmiot: True Note that the command field which gives you the direct command to use for controlling the device. If the device is supported by the genericmiot integration as stated in the output, you can also use miiocli genericmiot for controlling it. 以下文档从官方文档中摘录翻译。\n控制现代（MIoT）设备 大多数现代(MIoT)设备都会自动受到 genericmiot 集成的支持。\n在内部，它使用(\u0026ldquo;miot spec\u0026rdquo;)文件来了解支持的功能，如传感器、设置和操作。\nhttps://home.miot-spec.com/spec/xiaomi.controller.86v1\n米家产品库（非官方）\n此设备型号特定文件将在您首次使用 genericmiot 集成时下载（并在本地缓存）。\n所有支持设备的功能都可以使用常见命令来控制：\nstatus （显示设备状态）、 set （更改设置）、 actions 列出可用操作\n和 call 执行操作。\n设备状态 执行 status 将显示当前设备状态，以及设置的可接受值（标有访问 RW ）：\n1 2 3 4 5 6 miiocli genericmiot --ip 127.0.0.1 --token 00000000000000000000000000000000 status Service Light (light) Switch Status (light:on, access: RW): False (\u0026lt;class \u0026#39;bool\u0026#39;\u0026gt;, ) Brightness (light:brightness, access: RW): 60 % (\u0026lt;class \u0026#39;int\u0026#39;\u0026gt;, min: 1, max: 100, step: 1) Power Off Delay Time (light:off-delay-time, access: RW): 1:47:00 (\u0026lt;class \u0026#39;int\u0026#39;\u0026gt;, min: 0, max: 120, step: 1) 更改设置 要更改设置，您需要提供设置的名称（例如，在上面的示例中 light:brightness ）：\n1 2 3 miiocli genericmiot --ip 127.0.0.1 --token 00000000000000000000000000000000 set light:brightness 0 [{\u0026#39;did\u0026#39;: \u0026#39;light:brightness\u0026#39;, \u0026#39;siid\u0026#39;: 2, \u0026#39;piid\u0026#39;: 3, \u0026#39;code\u0026#39;: 0}] 使用动作 大多数设备还将提供操作：\n1 2 3 4 5 6 miiocli genericmiot --ip 127.0.0.1 --token 00000000000000000000000000000000 actions Light (light) light:toggle Toggle light:brightness-down Brightness Down light:brightness-up Brightness Up 这些可以使用 call 命令执行：\n1 2 3 miiocli genericmiot --ip 127.0.0.1 --token 00000000000000000000000000000000 call light:toggle {\u0026#39;code\u0026#39;: 0, \u0026#39;out\u0026#39;: []} 使用 miiocli genericmiot \u0026ndash;help 获取更多可用命令。\n详细的文档在这里：\n一行代码控制你的米家设备 基于上面的这些操作，\n这一行代码大概出来了。\n1 2 3 4 5 6 7 8 9 # 获取可以执行的命令 miiocli genericmiot --ip 192.168.31.170 --token xxxx actions ## 执行操作 miiocli genericmiot --ip 192.168.31.170 --token xxxx call camera:record-start ## 更改属性 miiocli genericmiot --ip 192.168.31.170 --token xxxx set camera:record-mode 1 当然如果你需要自己写点代码的话，\n大概是这样的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 from miio import Device, DeviceFactory, DeviceStatus from loguru import logger class MiIotDevice(): def __init__(self, ip, token) -\u0026gt; None: self.device: Device = DeviceFactory.create(ip, token) self.device_info = self.get_info() logger.info(f\u0026#34;Device: {ip}-{token} created\u0026#34;) def load_status(self): if self.device is None: return None d_status: DeviceStatus = self.device.status() return d_status.data def get_info(self): return { \u0026#34;ip\u0026#34;: self.device.ip, \u0026#34;model\u0026#34;: self.device.model, \u0026#34;device_id\u0026#34;: \u0026#34;nx_\u0026#34;+str(self.device.device_id), \u0026#34;mi_device_id\u0026#34;: self.device.device_id } def call_action(self, name, args): if self.device is None: raise Exception(\u0026#34;Device not ready\u0026#34;) call_result = self.device.call_action(name, args) logger.info( f\u0026#34;call_action: {name}-{args} result: {call_result}\u0026#34;) return call_result def set_properties(self, properties): if self.device is None: raise Exception(\u0026#34;Device not ready\u0026#34;) call_result = self.device.send(\u0026#34;set_properties\u0026#34;, properties) logger.info( f\u0026#34;set_properties: {properties} finish, result: {call_result}\u0026#34;) return call_result 大概，\n如上。\n总结 python-miio 是一个很好的工具，可以用来控制米家设备\n通过 miiocli 可以很方便的来控制设备 通过 miiocli genericmiot 可以控制现代设备 通过 miiocli genericmiot actions 可以查看设备支持的操作 通过 miiocli genericmiot status 可以查看设备的状态 通过 miiocli genericmiot set 可以更改设备的属性 通过 miiocli genericmiot call 可以执行设备的操作 通过 miiocli genericmiot \u0026ndash;help 可以查看更多命令 同时可以自己写代码来折腾一下具体的一些设备，\n自己去搞一些自动化的东西也很简单了。\n祝大家玩得开心~\n参考 python-miio miot-spec 米家设备属性查询（非官方） ","date":"2024-06-27T08:00:00Z","image":"https://liguobao.github.io/p/one-line-code-control-mi-iot-diy/mi-iot-diy_hu_9d626c75d55c12e6.png","permalink":"https://liguobao.github.io/p/one-line-code-control-mi-iot-diy/","title":"一行代码控制你的米家设备"},{"content":"WebCamera 基于WebRTC的点对点网络摄像头 前几天逛推，看到有个大佬开源了个小项目，基于WebRTC的点对点网络摄像头。\ngithub.com/ShouChenICU/WebCamera 顺手看了一眼代码和文档，发现这个项目还是挺有意思的，\n于是自己部署了一个，用下来有点意思，于是写个文章分享一下~\n项目介绍 WebCamera 是一个基于 WebRTC 技术的网络摄像头工具站，使用 Nuxt.js 框架开发，并通过 Yarn 进行包管理。 特性 实时视频流: 使用 WebRTC 技术实现高效的实时视频流。 跨平台支持: 兼容多种浏览器和设备。 易于开发: 基于 Nuxt.js 框架，方便扩展和维护。 模块化设计: 便于功能的扩展和集成。 隐私安全: 使用点对点加密连接，保护隐私安全。 docker部署 ccr.ccs.tencentyun.com/liguobao/tools:web-camera 是我构建的镜像，托管在腾讯云容器镜像服务上。 自行构建如下：\n1 2 docker build -t webcamera . docker run -d -p 3000:3000 webcamera k8s 部署 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 --- apiVersion: apps/v1 kind: Deployment metadata: name: web-camera labels: app: web-camera spec: replicas: 1 selector: matchLabels: app: web-camera template: metadata: labels: app: web-camera spec: containers: - name: web-camera image: ccr.ccs.tencentyun.com/liguobao/tools:web-camera ports: - containerPort: 3000 resources: requests: memory: \u0026#34;512Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; limits: memory: \u0026#34;2048Mi\u0026#34; cpu: \u0026#34;1000m\u0026#34; readinessProbe: httpGet: path: / port: 3000 initialDelaySeconds: 120 periodSeconds: 60 env: - name: DOCKER_ENABLE_SECURITY value: \u0026#34;false\u0026#34; dnsPolicy: ClusterFirst restartPolicy: Always terminationGracePeriodSeconds: 30 --- apiVersion: v1 kind: Service metadata: name: web-camera spec: selector: app: web-camera ports: - protocol: TCP port: 3000 targetPort: 3000 type: ClusterIP --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: cert-manager.io/cluster-issuer: letsencrypt-prod kubernetes.io/tls-acme: \u0026#34;true\u0026#34; generation: 1 name: ingress-web-camera spec: ingressClassName: traefik rules: - host: xxx.yyy.cn http: paths: - backend: service: name: web-camera port: number: 3000 path: / pathType: Prefix tls: - hosts: - xxx.yyy.cn secretName: xxx-yyy-cn-tls 后续 和大佬聊了下，后续可能会做个简单的在线视频会议的项目，可以期待一下~\n参考 WebCamera WebRTC 阮一峰：WebRTC 文档 WebRTC 这个协议有点意思，有兴趣的朋友可以多了解一下~\n毕竟大佬都说也就看了两天，就写出来了~\n","date":"2024-06-12T08:00:00Z","image":"https://liguobao.github.io/p/open-source-web-camera/web-c_hu_a594b9db6e22fd8c.png","permalink":"https://liguobao.github.io/p/open-source-web-camera/","title":"WebCamera 基于WebRTC的点对点网络摄像头"},{"content":"VS Code的C#插件好像不太正常 最近起了个新的C#项目，想着多个Project 按文件夹划分，\n在根目录扔一个solution就完事了，但是在VS Code里面打开的时候，\n发现在Project 源码里面引用信息和提示都不太正常，\n迷，一直都是这样用的，不应该有什么问题嘛。\n搜了一波发现，有些朋友也遇到了类似的问题。\n[VS Code] 解决C#代码F12无效 VSCode C# 转到定义(F12)和ctrl+鼠标左键无效的解决方案 说到的基本都是，OmniSharp插件不太正常，需要手动指定一下。\n但是\u0026hellip;\nomnisharp-vscode:This repository has been archived by the owner on Jun 22, 2023. It is now read-only.\n自然，这个方法也是没用的了。\n不过嘛。\ndotnet/vscode-csharp 已经是被官方支持的了。\nA Visual Studio Code extension that provides rich language support for C# and is shipped along with C# Dev Kit. Powered by a Language Server Protocol (LSP) server, this extension integrates with open source components like Roslyn and Razor to provide rich type information and a faster, more reliable C# experience.\n所以，是不是说应该安装一下这玩意就好了？\nC# Dev Kit\n最后验证了一下，确实是这样的。\nC# Dev Kit 插件支持了sln的加载，安装好了之后手动确认哪个sln文件就可以了。\n一切回归正常。\n水完。\n","date":"2024-06-10T08:00:00Z","image":"https://liguobao.github.io/p/vscode-support-csharp-sln/code_hu_233769f749c85acc.png","permalink":"https://liguobao.github.io/p/vscode-support-csharp-sln/","title":"VS Code 支持 C# 解决方案文件"},{"content":"背景：某云API网关要跑路啦 听过腾讯云API网关要下线了，之前的项目都（bu）是（shi）用的这个，现在要换成什么呢？\n【重要】API 网关产品停止售卖公告\n这玩意当年我还在白嫖腾讯云k8s master集群的时候，\n某一次升级之后他们把k8s的service 切成了API网关，\n然后开始要求我按量付费。\n接着我就开始研究怎么把这个东西给替换掉~\n到今天终于可以扬眉吐气了！！！\n方案一：腾讯云集群 + nodePort 集群还是一样的集群，自己的机器作为worker节点接入集群 直接删掉所有带内网IP的service，全部使用nodePort暴露服务。 在worker节点上安装NGINX，使用NGINX的反向代理功能，将请求转发到nodePort上。 这个方案跑了大概一年多左右，集群也开始收费了，美名曰管理费~\n算下来一个月几十块，一年几百块，并不能接受这个价格。\n遂，方案迁移~\n方案二：SuperEdge 自建集群 + nodePort + nginx 自建集群嘛，什么方便什么来。\n所以当年还写过这些文章：\n知乎专栏：边缘计算k8s集群SuperEdge初体验\n知乎专栏：SuperEdge边缘计算集群挂载NFS\n妥妥算是他们的一个自来水了。\n然而\u0026hellip;\n大概是在去年的时候，SuperEdge 微信群老群说迁移，新群加进去没人管了。\n私聊了一下之前熟悉的技术，说项目进入维护状态了。\n啧啧啧\u0026hellip;\n问题是，这玩意证书过期没法renew啊，我的集群直接崩了。\n真心累了，国内的大厂的开源项目，大多逃不过KPI的命运。\n玩不起不好进场，玩不转就只能被淘汰。\n真的，再信国内的大厂开源项目，我就是猪头！！!\n接着开始考察新的方案：\n依旧是All In K8s 依旧是自建集群 依旧是不花一分钱 然后，发现 k3s 这个东西，真香~\n最终方案：k3s + ingress-nginx 部署方案见：知乎专栏：【k3s】年度最佳边缘计算集群方案\nnode节点大概如下：\n1 2 3 4 5 6 7 NAME STATUS ROLES AGE VERSION aliyun-bj-199 Ready \u0026lt;none\u0026gt; 34d v1.29.4+k3s1 haru Ready \u0026lt;none\u0026gt; 6d16h v1.29.4+k3s1 t7610 Ready \u0026lt;none\u0026gt; 6d2h v1.29.4+k3s1 vm-16-12-ubuntu Ready control-plane,etcd,master 75d v1.28.7+k3s1 vm-28-17-ubuntu Ready,SchedulingDisabled control-plane,etcd,master 75d v1.28.7+k3s1 zj-hc1 Ready \u0026lt;none\u0026gt; 33d v1.29.4+k3s1 在上面其实可以看到，master 节点就两台，vm-16-12-ubuntu 和 vm-28-17-ubuntu ，\n两台机器在云端，内网互通，都有公网IP。（划重点）\n其他的机器部分在本地，部分在其他云，部分在边缘设备上，内网互通，但是不一定有公网IP。\n照着以前的逻辑，我们是需要一个API 网关，把流量转发到到worker节点上。\n这也是现在某云的API网关的功能，但是我们现在没有了。\n不过，没有了API网关，我们还有 ingress-nginx。\nk3s 集群中，有公网IP的节点，其实都可以直接作为流量入口。\n然后，我们可以通过 ingress-nginx 的配置，将流量转发到worker节点上。\n需要的操作只是在 server or agent 启动的时候，加上 --node-external-ip 参数，指定公网IP。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # server ExecStart=/usr/local/bin/k3s \\ server \\ --node-external-ip 公网IP \\ --flannel-backend wireguard-native \\ \u0026#39;--tls-san\u0026#39; \\ \u0026#39;公网IP\u0026#39; \\ \u0026#39;--node-name\u0026#39; \\ \u0026#39;vm-16-12-ubuntu\u0026#39; \\ \u0026#39;--server\u0026#39; \\ \u0026#39;https://10.0.28.17:6443\u0026#39; \\ # agent ExecStart=/usr/local/bin/k3s \\ agent --node-name zj-hc1 \\ --lb-server-port 5443 \\ --node-ip 10.42.4.1 \\ -node-external-ip 公网IP \\ --server https://server:6443 \\ --token=\u0026#34;YOUR_TOKEN\u0026#34; \\ 此时，这个节点的443端口和80端口就可以直接接受外部流量了。（当然，需要防火墙开放）\n然后我们把对应的域名解析到这个节点的公网IP上，就可以直接访问了。\n一个完整的部署例子 带域名证书自签名 任意有公网IP的节点都可以作为入口 如果需要负载IP负载均衡，可以在DNS解析时使用多个A记录，或者使用DNS负载均衡服务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 apiVersion: v1 kind: PersistentVolume metadata: name: stirling-pdf spec: capacity: storage: 30Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete storageClassName: local-storage local: path: /mnt/cfs-a4nopkhh/stirling-pdf nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/hostname operator: In values: - zj-hc1 --- kind: PersistentVolumeClaim apiVersion: v1 metadata: name: stirling-pdf spec: accessModes: - ReadWriteOnce resources: requests: storage: 30Gi storageClassName: local-storage --- apiVersion: apps/v1 kind: Deployment metadata: name: stirling-pdf labels: app: stirling-pdf spec: replicas: 1 selector: matchLabels: app: stirling-pdf template: metadata: labels: app: stirling-pdf spec: containers: - name: stirling-pdf image: ccr.ccs.tencentyun.com/liguobao/s-pdf:ustc ports: - containerPort: 8080 resources: requests: memory: \u0026#34;512Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; limits: memory: \u0026#34;2048Mi\u0026#34; cpu: \u0026#34;1000m\u0026#34; readinessProbe: httpGet: path: / port: 8080 initialDelaySeconds: 120 periodSeconds: 60 env: - name: DOCKER_ENABLE_SECURITY value: \u0026#34;false\u0026#34; - name: INSTALL_BOOK_AND_ADVANCED_HTML_OPS value: \u0026#34;false\u0026#34; - name: UI_APP_NAME value: \u0026#34;R2049 PDF\u0026#34; - name: ALLOW_GOOGLE_VISIBILITY value: \u0026#34;true\u0026#34; - name: LANGS value: \u0026#34;zh_CN\u0026#34; - name: APP_LOCALE value: \u0026#34;zh_CN\u0026#34; volumeMounts: - mountPath: /configs subPath: configs name: data - mountPath: /usr/share/tessdata subPath: tessdata name: data - mountPath: /customFiles/ subPath: customFiles name: data volumes: - name: data persistentVolumeClaim: claimName: stirling-pdf imagePullSecrets: - name: regcred dnsPolicy: ClusterFirst restartPolicy: Always terminationGracePeriodSeconds: 30 --- apiVersion: v1 kind: Service metadata: name: stirling-pdf-service spec: selector: app: stirling-pdf ports: - protocol: TCP port: 8080 targetPort: 8080 type: ClusterIP --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: cert-manager.io/cluster-issuer: letsencrypt-prod kubernetes.io/tls-acme: \u0026#34;true\u0026#34; generation: 1 name: ingress-pdf-house2048 spec: ingressClassName: traefik rules: - host: pdf.house2048.cn http: paths: - backend: service: name: stirling-pdf-service port: number: 8080 path: / pathType: Prefix tls: - hosts: - pdf.house2048.cn secretName: pdf-house2048-cn-tls ","date":"2024-06-03T08:00:00Z","image":"https://liguobao.github.io/p/q-cloud-api-down-k3s-up/qcloud_hu_872f4ef0e1ddd9ea.png","permalink":"https://liguobao.github.io/p/q-cloud-api-down-k3s-up/","title":"腾讯云API网关废了？集群开源方案平替"},{"content":"GPT2077 速报~\nGPT2077 免费GPT4站点~ 国内高速，免梯子，安全高效。\n支持 GPT3.5、GPT4、论文润色，按量付费。\nGPT 2077强力驱动~\n国内网络，邮箱注册激活立即可用。\nGPT4、GPT3.5、\nGPT-4o、\nGoogle Gemini-Pro、\nDALL-E3-Image文本生成图片模型\n都能用~\n论文解读、SiriGPT、\n论文润色、API调用\n等等功能都有~\n按量付费，按需使用。\n每日签到送10W Token，\n邀请好友每位赠送30W Token。\n四舍五入就是不花钱直接用~\n扫码注册\n图片\n邀请码注册\n欢迎使用我的邀请码【9NBE3XJ9】注册GPT2077，\n立即获得50W Token奖励\n（GPT4、3.5模型通用）。\n点击链接注册：\nhttps://chat.r2049.cn/user/login?inviteCode=9NBE3XJ9\nGPT4 经典问题\nQ：鲁迅打了周树人，这个是正常的吗？\n三种不同模型的回答~\n“每日签到” 入口：个人信息页 签到Token奖励额度为10W “邀请码”功能 GPT 2077 邀请码 当前邀请人奖励 30W Token额度，被邀请的新用户奖励 50W Token 额度。 Siri GPT 如何在Siri中使用GPT对话~ GPT3.5 、GPT4 对比 GPT3.5、GPT4对比 ","date":"2024-05-29T08:00:00Z","image":"https://liguobao.github.io/p/gpt2077-free-gpt4/girl_hu_9911ef3788d2ca33.png","permalink":"https://liguobao.github.io/p/gpt2077-free-gpt4/","title":"GPT2077 免费GPT4站点~"},{"content":"前几天在网上冲浪， 看到了有点意思的插件 “Slax Reader”， 值得推荐一下~\nAn AI-powered browser extension that generates outlines and highlights key points to enhance your web reading experience. An AI-powered browser extension that generates outlines and highlights key points to enhance your web reading experience.\nhttps://chromewebstore.google.com/detail/slax-reader/gdnhaajlomjkhahnmiijphnodkcfikfd ​chromewebstore.google.com/detail/slax-reader/gdnhaajlomjkhahnmiijphnodkcfikfd\nChrome插件，安装需要自行解决~ 原推地址：https://x.com/wulujia/status/1791680166382727541\n下面的一些效果图~\n原文：我们为什么相爱，又为什么分开https://mp.weixin.qq.com/s/r9wSD-Y‍81My7‍6J_74A5d4g\nzhihu某个吵架回答~\n前几天我写得Python学习~\n老早之前写的~\n暂时插件没有收费，作者说大家用量不大无所谓了。\n据说用的是openai 接口，算下来应该不算便宜了。\n快读、速读内容，整体观感还是很好的~\n大概如此。\n有点意思，又一次可以偷懒了。\n","date":"2024-05-21T08:00:00Z","image":"https://liguobao.github.io/p/slax-reader-ai-mind-map/ai_hu_3ba4fc953cced776.png","permalink":"https://liguobao.github.io/p/slax-reader-ai-mind-map/","title":"Slax Reader：AI驱动的思维导图插件"},{"content":"PS：劳动节不劳动，犯法的！\n手动狗头~\n【编程技术专区劝退提示】\n最近有台服务器要到期了，问了下IDC机房续费，报价说2500。\n供应商说去年也是这个价格。\n道理倒没错，确实去年是付了钱的。\n只是\u0026hellip;.今年嘛，日子都不太好过。\n算了，去壕各种云羊毛算求了。\n很快就买了机器，想着一不做二不休——想搞集群方案。\n于是，盯上了k3s。\n之前用过SuperEdge之类的边缘集群方案，没有release就再用了。\n然后今年他们团队\u0026hellip;基本属于不更新状态了。\n果然国内大厂开源都基本是KPI项目，我再信他们我就是狗。\nk3s一直都有点关注，\n毕竟rancher这公司在17、18年可是我们部署k8s集群的救星，\n他们开源的项目一直都算是靠谱的。\n为什么叫 K3s?\n我们希望安装的 Kubernetes 只占用一半的内存。Kubernetes 是一个 10 个字母的单词，简写为 K8s。 Kubernetes 的一半就是一个 5 个字母的单词，因此简写为 K3s。 K3s 没有全称，也没有官方的发音。https://docs.k3s.io/zh/\n对嘛，多有意思。\n同时，麻雀虽小，应用尽有。\n直接干。\n（然后我把这活扔给了海哥，海哥花了一下午把集群跑起来了。\n（接着我们晚上开始迁移服务，折腾了三个半小时。\n（期间丢失了一次Redsi缓存数据（我误删\n（很“顺利”就上线了\nvm-16-12-ubuntu Ready 42d v1.28.7+k3s1\nvm-28-17-ubuntu Ready 42d v1.28.7+k3s1\n两个节点的寒酸集群~\n这阵子忙着搞GPT2077嘛，基本机器就没咋搞了。\n（插播广告：GPT2077：支持论文解读、邀请好友升级~\n这两天没那么忙了，又遇上服务器到期续费，也是想着开始折腾下了。\n开搞。\n安装什么的，看官网文档就好。\nhttps://docs.k3s.io/zh/quick-start\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh \\\ncn user\ncurl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -\n这里主要是讲几个注意事项。\n一、安装事项\n上面的脚本安装在本地安装完成之后，\n默认直接装了一个k3s.service，同时也把k3s cli装好了，\n至于这个节点是个server还是个agent，\n主要就看自己怎么去改k3s.service的配置了。\n默认这个是启动server，我们可以根据需求启动成agent，\n或者使用其他的参数配置。\n二、边缘计算网络\n我这边的Server是两台云端的服务器，他们在同一个局域网互通，配置起来很简单。\n但是其他的机器，可能是在没有公网IP的本地，也可能是其他云的单机器。这样一来，肯定就没办法直接做内网通讯了。\n查了一些资料之后发现，WireGuard 是一个很不错的方案。\n什么是 WireGuard？ WireGuard 是一个易于配置、快速且安全的开源 VPN，它利用了最新的加密技术。目的是提供一种更快、更简单、更精简的通用 VPN，它可以轻松地在树莓派这类低端设备到高端服务器上部署。 WireGuard 最初是为 Linux 开发的，但现在可用于 Windows、macOS、BSD、iOS 和 Android。它仍在活跃开发中。 https://zhuanlan.zhihu.com/p/108365587\n最早参考的是：\n使用 k3s 和 WireGuard 网络部署 Kubernetes 集群：https://einverne.github.io/post/2021/12/kubernetes-cluster-multiple-clouds-using-k3s-netmaker-wireguard.html 折腾下来发现，Netmaker 是付费项目，配置起来还有一些概念需要理解。\n反正第一次并没有成功，而且这是21年的博客文章了,有点过时也有可能。\n没死心，继续找资料折腾。\n于是看到了 【杨斌】大佬的专栏文章：\nKubernetes 入门到实践：借助 WireGuard 跨云搭建 K3s 集群环境：https://zhuanlan.zhihu.com/p/584998631 看了一圈下来发现应该是适合我这边的。\n由于我的云主机分布在不同的云服务商，所以不能通过服务商的内网环境互相访问，这里需要借助 WireGuard 完成异地组网。由于 K3s 通过 Flannel 已经集成了 WireGuard，所以我们可以通过一些简单的配置即可轻松完成组网。https://zhuanlan.zhihu.com/p/584998631\n所以方案大体是：\nWireGuard 工具\nk3s Flannel切换成 wireguard-native\n重启集群验证\n安装 WireGuard\n安装 WireGuard apt install wireguard resolvconf -y\n开启 IPV4 IP转发 echo \u0026ldquo;net.ipv4.ip_forward = 1\u0026rdquo; \u0026raquo; /etc/sysctl.conf sysctl -p\n或者\ncentos7 sudo yum install epel-release elrepo-release -y; sudo yum install yum-plugin-elrepo -y; sudo yum install kmod-wireguard wireguard-tools systemd-resolved -y;\n开启 IPV4 IP转发 echo \u0026ldquo;net.ipv4.ip_forward = 1\u0026rdquo; \u0026raquo; /etc/sysctl.conf sysctl -p Centos 配置好了之后可能需要重启一下机器，毕竟内核文件也更新了。\nk3s Flannel切换\n修改service 启动命令 sudo vi /etc/systemd/system/k3s.service\nsudo systemctl daemon-reload sudo systemctl restart k3s\n/etc/systemd/system/k3s.service ExecStart=/usr/local/bin/k3s server \u0026ndash;node-external-ip 公网IP \u0026ndash;flannel-backend wireguard-native \u0026ndash;flannel-external-ip 公网Ip \u0026lsquo;\u0026ndash;tls-san\u0026rsquo; \u0026lsquo;公网Ip\u0026rsquo; \u0026lsquo;\u0026ndash;node-name\u0026rsquo; \u0026lsquo;vm-16-12-ubuntu\u0026rsquo; \u0026lsquo;\u0026ndash;server\u0026rsquo; \u0026lsquo;https://内网IP:6443\u0026rsquo; \\\n大概如上。\n没有问题的话，重启这个服务就好。\n有问题就去看日志了，遇神拜神~\nserver 没什么问题的话，接下来就到了折腾Agent的时候了。\nAgent也就是我们的边缘节点了。\nAgent 节点配置\n依旧还是改k3s.service\n首先，你得先知道 wireguard 会给你哪个地址。\n我一般都是先直接用k3s agent 命令看下运行输出，有问题也能马上看到。\nk3s agent \u0026ndash;node-name zj-hc1 \u0026ndash;lb-server-port 5443 \u0026ndash;server https://server的公网IP:6443 \u0026ndash;token=\u0026ldquo;你的Token\u0026rdquo; 上面lb-server-port 默认的6443端口被其他应用占用了，所以我改成了5443，正常情况下不需要加~\n更多的配置项目可以参考配置文档：\nhttps://docs.rancher.cn/docs/k3s/installation/install-options/agent-config/_index/\n没什么问题问题的，应该能看到新的节点上来了。\nOk的话，\n去 vi /etc/systemd/system/k3s.service 改下，\n然后重启k3s。\nsudo systemctl daemon-reload sudo systemctl restart k3s\n基本完事。\n一个完整的k3s.service 启动命令核心如下\nExecStart=/usr/local/bin/k3s agent \u0026ndash;node-name zj-hc2 \u0026ndash;lb-server-port 5443 \u0026ndash;node-ip 10.42.5.1 -node-external-ip 外网IP，如果需要Ingress要写 \u0026ndash;server https://你的ServerIp:6443 \u0026ndash;token=\u0026ldquo;你的Token\u0026rdquo;\n到这里，我们的集群基本搞掂了。\n简单测试了一下速度~\n基本能跑得起来非敏感时延的服务了。\n完事。\n全文在飞驰的高铁上完成，还是值得一个赞的~\n手动狗头~\n祝大家假期快乐~\n","date":"2024-05-01T08:00:00Z","image":"https://liguobao.github.io/p/k3s-edge-computing-cluster/k3s_hu_1d38b9c795580a1a.png","permalink":"https://liguobao.github.io/p/k3s-edge-computing-cluster/","title":"【k3s】年度最佳边缘计算集群方案"},{"content":"但是，麻烦别人总是不太好的，毕竟我也没给钱\u0026hellip;.\n反正技术问题，那么就用技术来解决呗。\n没什么神奇的玩意，就一句代码。\n打开对应的回答页面，如\n假定所有程序员写的代码都不出bug， 会发生什么？\n在这个页面，F12打开浏览器控制台，输入下面这一行代码。\n1 2 document.getElementsByClassName(\u0026#34;RichContent RichContent--unescapable\u0026#34;)[0].innerText 然后大概能看到。\n对着文本右键，选择 “Copy string contents”，然后粘贴到你想要粘贴的地方。\n完事。\n","date":"2024-04-27T08:00:00Z","image":"https://liguobao.github.io/p/how-to-copy-zhihu-content/gqj_hu_f9e58b77a5d18afd.png","permalink":"https://liguobao.github.io/p/how-to-copy-zhihu-content/","title":"如何在知乎复制一些不那么好复制的内容~"},{"content":"By 陈野亮-如何评价宫崎骏新作《你想活出怎样的人生》？\n最近因为精神状态问题，在知乎写回答对我来说越来越成为一件负担，但是在电影院，宫崎骏给了我没有烦恼的两个小时，回家后看知乎回答，看着看着，突然觉得，我应该用我的审美和知识储备，来为这个世界做点什么，即使这件事对我来说并不愉快。\n《你想活出怎样的人生》对于宫崎骏来说，就是一部不愉快的作品，我相信看的时候观众都能感受到。\n同样是一位少年、一位少女、奇幻的世界、一场盛大的冒险，在《千与千寻》《天空之城》等作品中，整体上是轻松愉悦的。主人公内心并没有心结，在面对未来时心念明确，眼神坚定。\n但是《你想活出怎样的人生》就完全不一样，虽然主人公眼神依旧坚定，目标依然明确，但他始终有心结。\n他的敌人不再具有实体，不是后妈，不是怪鸟，不是幽灵，不是堡主，不是鹦鹉，主角需要面对的难题十分复杂，不是把刀斩向谁，或者把枪对准谁，问题就能得到解决。他不能离开，也无法战斗，即使见到母亲也毫无办法，即使见到堡主也无济于事，世界的崩溃是必然，他只不过是见证而已。\n那么，为什么宫崎骏要拍一部不愉快的电影呢？\n因为这部片子，他刀刃对着自己。\n解剖自己从来不是轻松的事。\n这片子实际上讲了一个非常直白的故事，只要看懂就能明白他为何要留下一个不轻松的叩问。想要看懂片子，需要正确理解片子里的几个隐喻。\n这部片子有无数个隐喻，但是我只拣其中六个，组成基本脉络，分为以下六个章节，来讲清楚这到底是个什么故事。\n1、塔\n《你想活出怎样的人生》分为两个部分，一部分是1944年时期的日本，这是现实世界，另一部分则是塔里的世界，这是个幻想世界。\n连通两个世界的桥梁，就是塔。\n关于塔的存在，电影里有两种说法，一种是继母夏子提供的，说是一位聪明的叔公建起来的。另一种则是佣人们透露的，说塔其实是从天而降，聪明的叔公只是在外围包裹起了一层围墙而已，最终形成了一座塔，在建造塔的时候，发生了很多怪事，死了很多人。\n想要理解“塔”隐喻着什么，需要熟悉日本近代历史。\n日本战国时代结束后，进入了由德川幕府统治的江户时代，随着锁国令的实行，日本进入了长达200多年的闭关锁国时期。\n打破锁国令的是著名的“黑船事件”。1854年，美国准将马修佩里驾驶舰队进入江户湾，以炮舰威胁德川幕府打开国门，之后日本签订了《日美亲善条约》，这是日本与西方国家签订的第一个条约。日本被强迫睁开眼看世界。\n随着日本和世界接轨，日本国内一部分有识之士开始谋求变革，结合日本国内的下级武士以及有实力的西南各藩，开启了轰轰烈烈的倒幕运动，最终推翻了德川幕府，从此之后，大政奉还给天皇，也就是明治天皇。从这时起，开始了“明治维新”，也开启了日本的近代化。\n从天而降的塔，浑身漆黑的外表，实际上是暗喻着“黑船事件”，更进一步的说，是指西方传来的近代化思想。\n所谓“聪明的太舅公”，指的便是维新派。明治维新，就是以西方思想为内核，外面包裹上日本化的东西，最后造出了一座洋不洋、土不土的塔。\n但是塔作为沟通两个世界的桥梁，我认为肯定不是指明治维新，其隐喻还要更深一层：它应该是明治维新后，日本政治、历史、文化体系的集合体。正如大家所说，“塔的下面是一个迷宫”。\n进入这座塔，出现了一个奇幻瑰丽的世界，在这个世界里，个个动物都有隐喻，在塔里，日本的政治是可视化的。因此，我更倾向于认为“塔”代表着日本的整个体制。\n2、墓主人\n这里要将墓主人作为第二个章节。因为我看了网上很多解析，全都没有解释清楚墓主人的隐喻。\n而墓主人的隐喻又相当重要，它是整个塔楼世界崩溃的根源，是污染的来源，是一切的起点。\n相信不少人看到这里，会一头雾水：墓主人是谁？怎么完全没有印象了？\n给大家提个醒。\n在真人来到这个奇幻世界时，第一个见到的，就是这座坟墓。\n外面用围墙围着，有着一扇金色的大门，门内却是用石头搭成的墓穴，非常简陋。\n在门上，还写着一行字：“学我者死”。\n对于这座墓，强大的雾子都如临大敌，鹈鹕们崇拜但是只能卑微地伏在门外，而自始至终，这座墓的主人都未曾出来过。\n为什么宫崎骏要在幻想冒险的开头部分安排这样一个情节，为什么他后面又没有提到这座墓了，是他忘记了吗？\n想要破解这个隐喻，需要了解世界历史。\n1500年左右，欧洲人开启了地理大发现时代，所谓地理大发现，是站在欧洲人的视角，“发现”了很多之前对于他们来说“不存在”的地方。\n虽然说是地理大发现，但是给全世界带来了巨大灾难。\n欧洲人在非洲贩卖廉价商品，挑动部族内战，收割黑奴，在美洲传播瘟疫，屠杀印第安人，在亚洲更不必说，强迫落后封建王朝签订不平等条约，扶植代理政府。\n在“地理大发现”的初期，欧洲从启蒙时代进入资本主义阶段，在“地理大发现”的末期，他们完成了资本主义的血腥原始积累，全球主要资本主义国家进入帝国主义阶段。\n所谓帝国主义，即是“垄断资本主义”，是指通过资本输出，利用其它国家的劳动力、原料，为本国赚取利润。\n由殖民地提供原料，由血汗工厂进行生产，再倾销到全球，通过这个循环，资本家获取了巨额利润。\n这本质上，是先进地区对落后地区的剥削，是资产阶级对无产阶级的剥削。\n有人会说，这种体制是公平的呀，你有资本，你也可以去剥削落后地区，你要是先进，你也可以去殖民其他地方。\n确实。德国也是这样想的。\n在殖民主义盛行的时期，先发国家对于后发国家的优势是毋庸置疑的，倾销与被倾销，剥削与被剥削，不在餐桌上，就在菜单上。历来如此。\n站在东方视角，欧洲人开启的殖民时代，实际上是给这个世界重新订立了一个血腥的规则：必须依靠暴力来扩张，之后获得更大资本的站在生态高位，便有权剥削下层的国家、人民。\n墓主人的隐喻，关键在于金色大门上的那行字：\n“学我者死”。\n这句话是宫崎骏一语道破了帝国主义的本质。这句话不是墓主人的好心规劝，而是墓主人切实的威胁：学我者死。\n我可以在全球范围展开殖民，你不可以。\n我可以利用资本收割全球，你不可以。\n那座外表金光灿灿的墓地，其隐喻，就是指这一群死而不僵的老东西。\n老牌帝国主义。old money。\n所有人都怕他们，所有人都不敢得罪他们。是他们开启了罪恶的循坏，也是他们夺取了最大的利益，是他们制定了规则。\n如果没有他们，全世界都还生活在田园牧歌的世界当中，人类不会陷入波及全球的高烈度战争。也是因为他们的这一套“资本”的玩法，让全球陷入互相吞噬的怪圈当中，为了金钱而疯狂。\n他们是污染的源头。\n3、鹈鹕\n这是一群可怜的家伙。它们贪婪，它们胆怯，它们从墓主人那里学到了“吃人”。\n它们吃不了海里的鱼，于是就跑去吃哇啦哇啦。\n鹈鹕隐喻着明治维新之后，日本国内的新兴势力，也就是真人的爸爸那个阶层。\n民营资本。\n这些民营资本从老牌帝国主义那里学到了扩张和资本滚雪球，但是“海里的鱼大部分抓不了”，没那个能力。\n鱼是塔内世界里唯一不会说话的，连声音都不曾发出，因此可以认为它们不指代任何实际物，我认为，海鱼应该是指“传统的自然经济”。\n出海捕鱼，我吃肉，鱼油流出来分给哇啦哇啦，哇啦哇啦吃饱后就可以飞到天上去投胎，成为世界的未来。\n这是在帝国主义思潮传入日本之前，日本原本的自然经济模式，哇啦哇啦即是人民。只有人民能生生不息，整个世界才能维持运转。\n但是鹈鹕这种生物是被强行塞进来的。就如同明治后日本的资本主义一样，它们没有经历过西方资本主义萌芽——原始资本积累——形成庞大势力这个阶段，所以它们不能像传统的自然经济一样运作，又没办法去动墓主人的蛋糕，能做的，便只有向内压迫哇啦哇啦。\n鹈鹕也知道吃哇啦哇啦会断送未来，但是墓主人带来的法则便是“不扩张就会消亡”，所以鹈鹕只能靠吃哇啦哇啦来盲目扩张，可是即使这样还是不够，新生的鹈鹕已经不会飞了。\n于是，鹈鹕变成了鹦鹉。\n真人的爸爸生产零式战斗机的外壳，这就是鹈鹕和鹦鹉沆瀣一气的实质证据。\n4、鹦鹉\n鹦鹉是整部电影里最明显的一个隐喻，就是军国主义。\n宫崎骏怕你看不懂，就差把卫生胡贴在鹦鹉脸上了。\n那么军国主义是怎么来的呢？\n鹈鹕捕不了海里的鱼，墓主人又说学我者死得罪不起，那么日本只能以直接暴力，走上扩张的手段，参与到瓜分落后地区的狂潮当中。\n1874年，日本发动侵占台湾的战争，同清政府签订《北京专约》，获得50万两白银的战争赔款。\n1875年，入侵朝鲜江华岛，迫使朝鲜签订《江华条约》。\n1894年，发动中日甲午战争。\n1900年，参与八国联军侵华。\n1904年，与俄国爆发日俄战争。\n1914年，一战中，对德宣战，占领青岛、胶州湾、济南，迫使北洋政府签订《二十一条》。\n1918年，出兵西伯利亚。1927年，侵占东北。1939年，发动太平洋战争。\n在一次次战争中，鹦鹉的势力越来越庞大。最初的几场战争实际上都是赌国运的战争，日本谨慎又小心，慢慢蚕食，直到后来胃口越来越大，野心越来越膨胀。\n鹦鹉膨胀的野心和傲慢，最终导致了这个世界的毁灭。\n5、堡主\n堡主的隐喻也很明显，是宫崎骏自己。\n他的十三块积木，对应着他的13部作品。\n他所做的，在影片里说得也很清楚“寻找干净的石头，来搭建积木”。正如他的作品一样。宫崎骏的作品里从来没有血腥、暴力、杀戮。\n他把那些没有被世界社会规则污染过的童真、梦想、幻想，全都捡起来，拼成一座塔，维持心灵世界。\n但是他也是悲观的，甚至绝望了，因为没有被污染过的石头越来越少了。\n在宫崎骏的世界观里，由墓主人开启的这种污染，实际上符合根植于人类本性中的贪婪，最终形成的这套社会规则，强迫人们以财富、资本衡量人生是否成功的标志。\n即使心灵再纯真的孩子，长大后再不愿意加入这套规则，也必须向这套规则低头。\n就比如宫崎骏自己，他拼凑出来的积木真的没有被污染吗？他搭建出来的作品，照样要服从商业性，让作品卖出更多的钱，这样才能够拍下一部作品。\n污染是无止境的。\n他想做的，是尽量拼出一个稳定的，不会倒塌的塔，但这注定是不成功的，在鹦鹉大王眼里，这本就是很荒唐的事情——世界怎么可能因为你拼出来的这座塔而改变呢？\n所以最后，鹦鹉大王随便拼了一座塔，发现不对劲后，直接一刀劈了，随后世界就毁灭了。\n两颗原子弹落下，二战结束，日本无条件投降，新的日本诞生了。\n当所有动物都慌慌张张地从塔里逃出来时，鹦鹉也跟着一起出来了，刚刚出来，瞬间化身成为无害的小鸟，可爱地依偎在人们肩头，并且飞翔出去，在人们脸上拉下一坨坨屎。\n相信很多观众注意到了，真人从塔里出来时，脸上沾了鹦鹉屎，其他人身上或多或少都沾了鹦鹉屎。\n为什么宫崎骏要画这样的镜头，是搞笑？是严谨？还是随便画的？\n这么长的电影，所有的镜头都没有随便。他是刻意要画这些鹦鹉屎的。\n一出了塔，鹦鹉马上变得彬彬有礼起来，并且毫无惩罚地飞走了。这不是宫崎骏喜欢这些鹦鹉，不是宫崎骏只反战败不反战。\n这是事实。\n经过改造后的日本，当初那些发动战争的战犯受到惩罚没有呢？没有。甚至还活得相当好。\n就连天皇，作为国家的元首，都根本没有受到惩罚。\n在历史中，昭和天皇被包装成“没有插手，不过河”，实际上，明治维新后日本的体制就是操持在天皇一人手中，才不是像西方那样的样子货。\n在日本的新政府中，多少人都是发了战争财，安然无恙地活到新时代？并且子子孙孙，都继承家族衣钵？\n就比如日本现任自民党副总裁麻生太郎，他的父亲麻生太贺吉就是煤矿起家，在二战期间，强征朝鲜劳工，赚得盆满钵满，并且娶了吉田茂的女儿，为吉田茂提供了无数政治金。随后，麻生太郎本人也娶了铃木首相的女儿，之后自己也当上过首相。\n像麻生太郎这样的不是个例，很多很多。\n鹦鹉拉的屎，平等地落在每一个人脸上。\n说回电影，在影片最后，所有动物都从塔里出来了，几乎所有动物都发生了变形，鹦鹉是变化最大的，直接成为了无害的小鸟，雾子从人偶变成了人，但鹈鹕，没有变化。\n真人爸爸就是鹈鹕。鹈鹕鸡贼的地方在于，鹦鹉赢也好，输也好，他们都会得利。\n开头真人的爸爸有一句台词“塞班岛的失败反而导致了工厂销量暴增”，在战后，鹈鹕反倒成了最大的赢家，迎来了蓬勃的发展。\n鹈鹕也依然盘旋在今日的天空中，依然在吃人。\n6、真人·伤口\n回到最初的起点，在本文开头我说过，这部电影对于宫崎骏来说是一部不愉快的作品。\n最不愉快的地方，是开头段落的一部分蒙太奇。\n真人在学校和同学发生争吵，他用石头砸了自己的头。\n在这一段中，全程没有现场声音，没有真人的独白，也没有争吵的过程，而是用音乐铺过去了。\n这一段处理得十分奇怪。\n一般这样处理的蒙太奇，都是用来展现主角生活“不重要”日常片段的。电影用来覆盖声音的配乐也很轻。但是就内容而言，这段相当重要。\n这给人的感觉就好像是，一个人在讲故事，讲到他曾经做过的错事时，轻描淡写地略过去了，好像只是一个无关紧要的小事。\n那么，是不是宫崎骏想隐瞒自己的错误呢？\n不是的。\n如果他想隐瞒，他根本没必要把这段放到电影里。而且整部电影，真人的头上都秃了一块，两边的毛不对称，看上去十分不和谐。\n秃的这一块时时刻刻都在提醒着观众，真人做过错事。\n他砸破自己的头，故意不说实话，以此换取父母的关心，放任父亲去找同学麻烦。\n在我们看来，小孩子做这种事也没什么，但宫崎骏对这种行为的定义是，这是卑劣的。\n在最后，塔主想将石头交给真人，真人却说，我不是纯洁的，这个伤口是我卑劣的证明，我接过石头的话，石头也会被污染。\n这是什么意思呢？\n真人的父亲发战争财，真人是在这样的家庭中成长起来的。他自己心中也有卑劣的思想，他不是宫崎骏以往故事里那种纯粹而正直的主人公，他是一个“真人”。\n搭积木隐喻创造作品，积木则是生活的点点滴滴，是对世界的看法，艺术创作就是采撷生活中的种种，拼凑出自己的作品。\n但是真人认为自己是卑劣的，所以他眼中的世界，都会被这种卑劣感染，最终创作出扭曲的作品。\n这是宫崎骏对日本的担忧。\n真人隐喻着下一代的孩子。日本人都是像真人这样，背负着原罪活下来的，他们都是汲取着依靠战争、暴力、杀戮的营养，成长到现在。\n当灾难被遗忘，他们是否还能保持纯洁？他们还能制作出稳定牢固的作品吗？\n最后，作为一个受到过日本侵害国的国民，我无意去解开日本人的心结，也无意去开导他们。\n在日本侵华战争中，我的祖父、外祖父那一代，都受到过伤害，提起日本人，他们会生理性地厌恶。\n每年9月，我的城市会响起防空警报，这一天是我们城市的沦陷日。这警报就是提醒人们勿忘国耻。\n但是暴力的受害者，不一定就能避免暴力。\n在我们的社会中，也流行着这样被污染的规则，依然在吃人。\n我们的作品中，对于金钱的渴望，对于权力、地位、暴力的崇拜和全身心跪服，对消费主义的狂信，恐怕比日本要更多。\n我们的国家没有鹦鹉，但是有很多鲶鱼。他们吃人的方式更加优雅，更加隐秘，更加不可撼动。\n对于宫崎骏的理想，对于他追求的东西，我发自内心的认可。\n对于他留下的问题，我无法解答。\n编辑于 2024-04-17 09:19・IP 属地湖北\n","date":"2024-04-17T09:19:00Z","permalink":"https://liguobao.github.io/p/how-to-evaluate-the-new-work-of-hayao-miyazaki/","title":"如何评价宫崎骏新作《你想活出怎样的人生》？"},{"content":"来源：如何同时删除知乎上自己的所有回答及想法？\n备用。\n不时之需。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // 删除单个回答 function deleteAnswer(answerId) { var xhr = new XMLHttpRequest(); xhr.withCredentials = true; xhr.addEventListener(\u0026#34;readystatechange\u0026#34;, function () { if (this.readyState === 4) { console.log(this.responseText); } }); xhr.open(\u0026#34;DELETE\u0026#34;, \u0026#34;https://www.zhihu.com/api/v4/answers/\u0026#34; + answerId); xhr.setRequestHeader(\u0026#34;authority\u0026#34;, \u0026#34;www.zhihu.com\u0026#34;); xhr.setRequestHeader(\u0026#34;accept\u0026#34;, \u0026#34;*/*\u0026#34;); xhr.setRequestHeader(\u0026#34;accept-language\u0026#34;, \u0026#34;zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7\u0026#34;); xhr.send(); console.log(\u0026#39;delete answer: \u0026#39; + answerId + \u0026#39; success\u0026#39;); } // 清理整页回答（小于100字） function clearAllAnswers(longer_than = 100) { let answerItemList = document.querySelectorAll(\u0026#39;.AnswerItem\u0026#39;); for (let answerItem of answerItemList) { let answerContentDev = answerItem.querySelector(\u0026#39;.RichContent-inner\u0026#39;); if (!answerContentDev) { continue; } let ans_id = answerItem.getAttribute(\u0026#39;name\u0026#39;); let answerContent = answerContentDev.innerText; if (answerContent.length \u0026gt;= longer_than) { console.log(`answer:${ans_id} is too long, skip`); continue } console.log(`delete answerContent: ${answerContent}`); deleteAnswer(ans_id); } } 定位到回答列表页，打开浏览器控制台（F12），\n把上面的代码复制到 Console 输入处，回车。\n然后输出 clearAllAnswers(50) ，回车。\nPS: 50代表抄过50字的回答不处理。\n不断切页，重复输入\nclearAllAnswers(50)\n完事。\n","date":"2024-03-01T08:00:00Z","permalink":"https://liguobao.github.io/p/how-to-delete-all-answers-on-zhihu/","title":"如何同时删除知乎上自己的所有回答及想法？"},{"content":"来源：为什么程序员下班后只关显示器从不关电脑？\n为什么程序员下班后只关显示器从不关电脑？ 亲爱的两脚兽，欢迎来到大型打工人公司现场~\n我们这里有各种类的社畜，社畜们都安分守己兢兢业业，希望新来的两脚兽在公司里面玩的愉快。在公司社畜扮演过程中，请两脚兽务必遵循以下守则，确保自身安全，否则后果自负。\n1、本公司24小时不间断供电， 外部供电中止情况下会柴油发电机会自动发动，不存在任何的断电风险，请大家安心工作。如果发现供电房间有响亮撞击声，请不用惊慌，请勿靠近房间。如果发现有褐色液体浸出，请通知行政处，会有专人处理。\n2、所有的电脑主机开机键都在机箱上方，且只有一个按钮。如果您的主机开机键位于正前方，请不要开机，迅速离开办公位，请尽量提前下班。\n3、公司配备了19寸MacbookPro供部分开发人员使用，如有需要可以向IT申请。请注意MacBookPro颜色只有银色，绝对不可能有黑色。如果拿到了黑色的MacBookPro，请不要开机，直接归还IT部。\n4、茶水间没有可口可乐售卖，本公司提供百事无糖免费领取。如果在售卖区域看到可口可乐，请不要尝试，直接通知行政人员到场处理。如果不注意喝到了可口可乐，请尽快前往医疗处就诊。\n5、下班离开公司前请主动关闭显示器电源，节省电源。\n6、下班离开公司请不要关闭电脑主机电源，提升效率。\n7、如果到岗上班发现电脑主机自动关机，可以长按电源键开机。如果无法开机，请和IT处联系。请不要私自打开机箱或者断开主机电源。\n8、如果你早上看到有其他显示器是点亮的，请记住编号尽快远离此区域，必要情况下主动汇报给行政。\n9、办公区域没有机械狗。如果发现有类似器物，请远离它并且汇报给行政人员。\n10、公司的程序员大多内向敏感，非必要情况请不要搭讪。如果遇到主动和你搭讪的程序员，请记住他的编号汇报给行政。\n11、公司的所有门禁和人脸识别系统为了确保绝对安全均为内部开发，只有内部工卡，不存在外部人员可以进入公司。\n\u0026hellip;..\n想看再续，欢迎补充。jpg\n```javascript ","date":"2024-02-29T08:00:00Z","permalink":"https://liguobao.github.io/p/why-dont-programmers-turn-off-their-computers-after-work/","title":"为什么程序员下班后只关显示器从不关电脑？"},{"content":"来源：服务器最短可以买多久，可以只买一周的服务器吗?\n服务器最短可以买多久，可以只买一周的服务器吗? 我想买一台服务器，但是我只想买一周，不想买一年，有这种服务吗？\n回答 1. 有这种服务吗？ 有。按量付费即可。\n基本大部分的云产品都有类似的按量付费的服务。\n大部分云厂商都有类似的产品需求。\n不过国内的厂商，我记得是要求实名之后，\n充值大于 100 块才能给你开通按量付费的权限。\n很鸡贼的操作。\n2. 有没有”省钱“的方案？ 有。\nGithub Page 这种玩意，最简单了。\n静态页面嘛，扔上去就能玩。\n我前阵子写过类似的文章，可以参考一下：\n如何配置 Github Page 页面\n我想把本地的网站让公网可访问，有什么好的方案吗？ 有。 最简单的是 frp 内网穿透。\n（ 但是这里需要你有一台公网服务器。哈哈哈\u0026hellip;\n我前阵子写过类似的文章，\n可以参考一下：\n如何配置 frp 实现内网穿透\n不过，也有其他的服务商提供了类似的功能。\n我记得我在玩 stable-diffusion-webui 的时候，\n他们是会直接提供一个公网地址的，\n查了下应该是用过 ”https://www.gradio.app/“ 来做的，\n你当然也是可以用类似的服务来实现把本地的一个服务，\n暴露成一个临时的公网地址~\n类似的文档在：\ngradio.app: Sharing Your App\n最后。\n祝玩得开心~\n","date":"2024-01-29T08:00:00Z","permalink":"https://liguobao.github.io/p/how-long-can-i-buy-a-server/","title":"服务器最短可以买多久，可以只买一周的服务器吗?"},{"content":"上一个版本大概是 22 年末了，\n后面也没什么好的想法，一直也就放着它，\n不间断偶尔维护一下数据抓取~\n( 也是看精力，毕竟用爱发电\u0026hellip;\n上个月某瓣下线了老的加密直接之后，数据就少了很多了。\n于是前几天重新和小伙伴搞掂了某瓣的小组数据。\n这两天登陆了小程序后台发现有盆友反馈说无法“复制链接”了。\n图片\n有点神奇~\n找前端大佬帮忙看了下，前端大佬说\u0026hellip;\n我们用的小程序框架文档都无了。\n图片\n不亏是\u0026hellip;\n又跑路了一个框架\u0026hellip;\n很难评。\n不过还是得说，大厂的 KPI 框架少点碰。\n折腾了一波之后，项目能正常跑起来了。\n大佬研究了一波确认应该是隐私条款有变更，\n我们之前的复制到粘贴板 API 被禁用了~\nSo\u0026hellip;\n简单更新一版应该就好了。\n同时修复了一下进入列表页的自动刷新问题。\n同时修复了一下缓存命中的问题，访问速度还算不错的。\n（ 多级缓存真的被我用到极致了，导致遇到懵逼中\u0026hellip;\n大概过几个星期有空的话会启动框架迁移，\n应该也会做一个新的改版~\n（ 让我再思考思考一下\u0026hellip;\n（产品能力真的是弱鸡\u0026hellip;\n同时希望二月份能有空把 NLP 文本分类跑起来了，\n先做一版广告帖子分类，再做一版评分，\n这个工作可能不那么快，希望年中之前能上线~\n图片\n今天试了下捞了下 xhs，数据倒是跑通了，只是\u0026hellip;.\n不知道会不会把自己送进去，哈哈哈。\n水完。\n收工。\n期待下一次更新。\n或者是告别。\n人生大抵如此。\n拜了拜~\n原文链接\n","date":"2024-01-13T23:09:00Z","permalink":"https://liguobao.github.io/p/house-map-bug-fix/","title":"太久没更新以至于Bug纷飞的地图搜租房~"},{"content":"来源：二本公办计算机毕业工作一年，如何从小公司跳到大厂？\n首先，先说一下路径。\n学历情况 正儿八经的本科，道理来说至少不会被卡学历。\n（也不好说，这两年市场有点变态\u0026hellip;\n( 有些 HR 就是直接卡学历，无解\u0026hellip;\n这个看人品看脸看运气，只能说试试看，不强求。\n路径方向 从小厂往头部小厂跳。\n从头部小厂往中厂跳。\n从中厂往大厂跳。\n这种操作是比较稳妥的，就是整个经历比较漫长。\n甚至于可能会错过一些事情，也不一定赶得上“快车”。\n简历问题 好好写简历。\n写完了让朋友们帮忙看看。虚心接受朋友的意见，对不同的岗位写不同的简历。不然，简历筛选都可能过不去。手上要有点拿得出手侃侃而谈的项目，就是要让别人看起来就觉得很有意思，就是要看起来就很牛逼，聊下来也要给别人点意思。\n内推背书 尽量勾搭人帮你背书。招人的时候，大家并不介意到处捞简历。有朋友推简历过来，是我的话至少会看一眼评估一下合不合适，也会比较诚实回复是不是不匹配。甚至于如果觉得很合适，大多还是会美言几句，尽量给个机会。\n这种事情嘛，厚着脸在网上多认识点人，总有路子的。\n这个我倒建议避开一些内推贩子，就当认识多朋友就好。\n称呼人多，得罪人少，总有人愿意你搭一手的。\n就如宝哥这里，谁不愿意称呼一声宝哥啊（毕竟平日红包也没少发，对吧。\n内推贩子这个我可以可以多聊几句：\n某个程度上你只是一个资源，人家大多很难说给你点什么关照。\n朋友的话还能上心一点，大概如此。\n刷题 + 八股文 没办法。\n刷题没办法，某些厂子就是喜欢这玩意。\n硬着刷就完事了，熟能生巧。\n（靠，我都快忘光了\u0026hellip;\n八股文，见仁见智。\n如果你遇到我，大概是不太会聊得到这种玩意的。\n如果你去某团，大概率有一半的内容在聊这些东西。\n多准备，没什么好说的。\n大概如此。\n彩蛋 所以，他甚至不愿意称呼我一声宝哥~\n","date":"2024-01-08T15:00:00Z","permalink":"https://liguobao.github.io/p/how-to-jump-from-small-company-to-big-company/","title":"二本公办计算机毕业工作一年，如何从小公司跳到大厂？"},{"content":"来源：我国电视开机率自 2016 年的 70% 跌至 30% ，电视开机率为何会断崖式下跌？\n这个事情很有趣，前阵子思考过一些“场景”，想到哪写到哪了。\n“断层”效应 想想，现在在外的打工人有多少，打工人哪里有条件看什么电视。租的房子大部分客厅都没有，有客厅的话可能还没有电视，有电视至少有网才能看一些内容，有网大概率只能看网络电视，有线电视是另外办理的，一层层得\u0026quot;筛选\u0026quot;下来来，庞大的群体就只剩下一点点人了。当然，这个说起来和 16 年之后的断崖下降关联性不大，但是大概也是可以说明点问题的。\n内容提供 总所周知，电视节目在这几年来说，越发的\u0026hellip;.不好看了。如果你们还有机会打开一下以前看的 XX 台，大概会发现确实质量太差了。更有趣的事情在于，在电视上投放的广告，越发同质化了。对比我小时候看到的电视广告，现在的这些玩意真的\u0026hellip;.垃圾中的战斗机。为嘛要扯广告呢？原因很简单，电视节目的收入，基本都来源于这些玩意。没钱 -\u0026gt; 买不到好的作品 -\u0026gt;没人看 -\u0026gt; 没广告收入~恶性循环了。当然，所谓的互联网电视也不是什么好东西。除了阿 B 的 TV 端，其他家的看起来和广告软件没撒区别。云视听小电视也不是什么好东西，但是贵在同行承托。如果朋友们有机会能直接打开奈飞 TV 端，大概能看到一个正儿八经的影视电视端是什么样的。所以我只想说，不是针对谁，在座的各位内容服务商都顶呱呱的。\n用户习惯 某个程度上，新一代的朋友并没有延续看电视的习惯下来。没有条件是一部分，没有内容也是一部分。甚至于理应有新的场景，但是看起来好像被替代了。就如，本来我们的现代化发展到现在的话，大概游戏产业开始发展起来的了 ，大型游戏是有可能会促进电视的又一次“重启”的。然而，照着国内的情况来说，先是页游，再是网游，然后手游。我们的主机游戏玩家，只有存量很少增量了。那确实很难有人有机会体验到“更好”游戏体验了。（不用杠，你说得都对）。《原神》已经火了很多年了，但是知道能在 PS4、5 上面用手柄玩的人不多吧（手动狗头）。相信我，60 寸大屏用游戏手柄玩游戏，比戳手机屏幕舒服多了。\n随便扯扯 有些事物大概率会消亡，大概也就让它消亡吧。人民群众喜欢，就真的是喜欢啊。\n","date":"2024-01-07T21:44:00Z","permalink":"https://liguobao.github.io/p/our-tv-open-rate-fall/","title":"我国电视开机率自 2016 年的 70% 跌至 30% ，电视开机率为何会断崖式下跌？"},{"content":"来源：Q: 985 本，华五研一，计算机相关专业，但是代码技术能力偏低，研究方向不适合找工作，应该转哪个方向工作？\nA：\n朋友。\n如果这个世界上别人指明了好走的路，\n这个时候是不是要问下自己：\n配不配得上这条路？\n对吧。\n所以先直接告诉你一个答案。\n如果你自认编码能力偏低，\n又不打算改变这个事实，\n那么，绝大多数的方向你都搞不掂。\n很简单的道理，编码能力就是基础功，\n基础功不行，别的都是空谈。\n","date":"2024-01-02T21:44:00Z","permalink":"https://liguobao.github.io/p/985-huawu-find-job/","title":"985本，华五研一，计算机相关专业，但是代码技术能力偏低，研究方向不适合找工作，应该转哪个方向工作？"},{"content":"Q: 程序员下班后接私活吗?\n身为程序员的你们下班后接私活吗？\n有没有一起做的呢？平常如果接到一个人做不过来怎么办呢？\nA:\n“性价比” 私活这种玩意，是要看性价比的。\n我是从来不做毕设相关的那些玩意的。\n原因很简单，事多钱少，\n那群穷学生，一分钱都舍不得花，还要求你做的跟百度一样。\n真的是又菜又爱玩的典型。\n然而，这可能是市面上能看到最多的一些玩意。\n我个人的经验是，这种玩意，不要做。\n作业还是自己完成吧。\n一起做？ 实话讲，绝大多数的人，\n并没有能和别人搭手好好干活的能力。\n也没有规划好一个项目的能力。\n这个时候，自己顶着上是最好的选择。\n前端后端运维服务器全是你一个人干，\n要什么自行车，能跑起来就行。\n做不过来？ 一个人吃饱，两个人饿死。\n大部分的时候，你是是请不起另一个朋友来干活的。\n所以，你只能自己干。\n当然如果你觉得都做不过来了，\n利润这么高了，可以考虑拉人或者直接请人了，\n可以考虑开始压榨剩余价值了~\n很难说有什么长期的外包伙伴关系，\n大家都有自己的事情要做，\n大家不同时间段的工作强度也不太一样，\n不可控的因素实在是太多了。\n最后 记得。\n先定金。\n再交付。\n狗头护体。\n","date":"2024-01-02T20:00:00Z","permalink":"https://liguobao.github.io/p/programmer-do-freelance-after-work/","title":"程序员下班后接私活吗?"},{"content":"Q: 2024 年，我们如何掌握人生的节奏感？\n现代人常常因为「社会时钟」的逼迫而陷入焦虑。 如何才能克服过「标配」人生的想法， 重新拿回人生的主动权？\nA:\n标配是一种“安稳” 不管信不信，所谓的「标配」，其实是最安稳的选择。\n“标配”人生，往往是最低的风险，最容易达成的目标。\n某个程度上，社会是鼓励你过「标配」人生的。\n因为这样的人生，是最容易被社会接受的。\n","date":"2024-01-02T16:00:00Z","permalink":"https://liguobao.github.io/p/how-to-grasp-your-life/","title":"2024 年，我们如何掌握人生的节奏感？"},{"content":"Q: 说真的计算机是不是不能再入行了？\nA:\n我们在谈论什么？ 广义上，我们在谈论的是一个行业的未来。\n狭义上，我们在谈论的是一个职业的未来。\n那么久行业的未来而言，计算机这个行业，\n是不是真的已经到了尽头了呢？\n暂时来说并没有。\n信息化革命依旧还在继续。\n信息化依旧还在继续提高效率。\n那么广义上的计算机行业，\n依旧还是有未来的。\n狭义上来说，短时间内日子会趋于平稳。\n或者某个时间节点来说，可能还是艰难的。\n没什么办法，发展有时候就是螺旋上升的。\n以前看到的那种指数爆发，\n可能有生之年都不会再看到了。\n所以。\n这个时候只能耐心，努力，等待。\n“正经答案” 你都这样问了，\n我觉得你已经不适合的。\n很简单的道理。\n你的想法是奔着互联网红利去的。\n那么在红利消失之后的时间里，\n你是不太能接受这个行业现状的。\n所以，你还是去做你喜欢的事情吧。\n","date":"2024-01-02T16:00:00Z","permalink":"https://liguobao.github.io/p/can-not-join-computer/","title":"说真的计算机是不是不能再入行了？"},{"content":"Q: 为什么电脑还没有被手机淘汰掉？\nA:\n首先，也不能说没有吧。\n就如融入日常的短视频来说，大部分的内容都在手机上完成了。\n很多剪辑类型的App连拍带剪都给你实现了，\n甚至于还能直接发布到人家的平台之上~\n某个程度上，这个场合之中手机设备已经把电脑淘汰掉了。\nApple公司每年都会发布一些用iPhone拍摄的大片，\n全程iPhone拍摄和剪辑，这个秀肌肉的操作一直都很酷。\n对吧。这个场合下，电脑还真不如手机。jpg\n我不是特指谁，我是说在座的各位，\n都\u0026hellip;算是电脑啊。\n打不过嘛，就加入对方。jpg\n所有的手机，在广义上都算是电脑，\n都属于计算机类别下的设备。\n这点其实是可以正儿八经承认的。\n那一个形态取代另一个形态，\n也是很正常的事情。\n当然，这个提问下，想问的应该是：\n为什么个人电脑还没被手机取代掉？\n那么我正儿八经的想法是：\n1、 算力不够。\n2、交互不够。\n3、生态不够。\n总体来说，\n还需要新的一场革命，\n不过可能革命结果是一起完蛋。\n手动狗头。\n","date":"2023-12-31T08:00:00Z","permalink":"https://liguobao.github.io/p/why-pc-not-replaced-by-mobile-test/","title":"为什么电脑还没有被手机淘汰掉？"},{"content":"Q: 如果程序员工资没有那么高（加班等条件不变）你还会去做程序员吗？\nA:\n我觉得这个问题有点像是问：\n你会不会因为爱好而去做一件事情？\n或者说，你会不会出于爱好去选择一份工作？\n那答案是肯定的啊。\n会的啊。\n写程序，对于我来说真的很快乐。\n这份快乐，大概是来源于创造事物得到的成就感。\n同时计算机的世界，0 就是 0，1 就是 1，没有模糊的地方。\n这种严谨的世界，让我觉得很舒服。\n一个被数学证明的事物，一个被数学证明的空间，着实让人着迷。\n我觉得，这就是我喜欢写程序的原因。\n如果它不能养活我的身体，\n至少它是激励我的灵魂的。\n我觉得，这就够了。\n一个能带来快乐的事情，肯定是值得去做的。\n","date":"2023-12-30T00:00:00Z","permalink":"https://liguobao.github.io/p/if-programmer-salary-is-not-high/","title":"如果程序员工资没有那么高（加班等条件不变）你还会去做程序员吗？"},{"content":"Q:2023 年互联网大厂集体变「瘦」，未来还能「胖」起来吗？\nA: 难说。\n增长点 本质上是没有增长点了。\n大家也不愿意继续投资源的探索。\n公司倒是有钱，但是不敢花。想想，是不是像极了某些场景~\n所以要回答这个问题，到底来说还是，看你是不是相信这个行业的未来。\n或者说，是不是还能看到寒冬的尽头？\n所以，这样来说能理解为什么 GPT 出来之后，整个互联网都沸腾了吗？\n因为大家都看到了希望：\n新的方法论，新的增长点，新的领域。\n甚至于，新的革命。\n但是，这个希望是不是真的存在呢？\n沸腾了一年之后大概也真看到结果了。\n并没有那么乐观。\n神奇海螺 所以，我觉得，这个问题，我们讨论和问神奇海螺一样。\n你问它，未来还能「胖」起来吗？\n它回答你：「未来还能「胖」起来.」\n这个问题并不会有神奇的答案。\n但是，我觉得，这个问题的背后，\n其实是有一个更大的问题:\n贵国的互联网公司，究竟是有多少的部门，是本来就不应该去做的。\n或者说，究竟这种所谓的胖，是不是本来就是一种错觉。\n大部分公司其实都是互联网收租,\n和现在收租的房东没什么区别。\n那么，那确实就是\u0026hellip;.\n面临一样的困境和问题。\n我只能说，\n祝好运了~\n还有什么想法 道理上来说，尽力而为。\n理智上来说，大浪淘沙。\n情感上来说，爱咋咋地。\n","date":"2023-12-29T17:00:00Z","permalink":"https://liguobao.github.io/p/2023-big-company-change/","title":"2023年互联网大厂集体变「瘦」，未来还能「胖」起来吗？"},{"content":"具体教程：配置 GitHub Pages 站点的发布源\n重点是：\n设置对应仓库的分支。\n一般我们使用Hugo之类的模板，\n都是生成了一个public 静态文件夹的。\n然后使用Github Action生成静态文件，\n一般是发布到当前任务的独立分支。\n我的例子 我的仓库是：\niguobao/liguobao.github.io 主分支 master 就是我的配置和文章，\n静态文件分支是：\nliguobao.github.io/tree/gh-pages\n这个时候，就需要在\nGithub 项目中 settings/pages 设置我的 \u0026ldquo;Your GitHub Pages site\u0026rdquo;\n分支为 gh-pages\n然后。\n完事。\nPhoto by Pawel Czerwinski on Unsplash\n","date":"2023-12-19T13:34:08Z","image":"https://liguobao.github.io/p/how-to-set-github-page/cover_hu_c9ffe16927ade974.png","permalink":"https://liguobao.github.io/p/how-to-set-github-page/","title":"如何配置Github Page页面"},{"content":"来源：Q: 是什么提高生产力的功能让你放弃 iPhone 转投华为？\n哈？ 我刚刚从泥坑里面爬出来又让我躺回去吗？\n不不不，我不需要。\n论手机生产力，我觉得没人比老罗的 TNT 更懂吧。\n而我，是真的用过 TNT 的\u0026hellip;.\n即使作为一个挺喜欢锤子手机的人，\n就那玩意我只能说，凑合能用都不算。\n那其他的呢？\n我只能说拜托了，手机真的只是手机呀。\n所以。\n大佬觉得什么是生产力呢？\nWO\n某个程度上来说。\n所谓的生产力是不是仅仅是一个硬件或者软件系统呢？\n可能的答案是：不全是。\n如何有效管理自己的时间和精力，\n如何找到合适的工作方式，也算是一种答案。\n所以有时候会发现，有些考研的朋友喜欢把自己的手机换成功能机，\n直接杜绝了所有的娱乐可能性，直接提高了自己的学习效率。\n那照着这个想法来说，某个设备满足自己的当前需求，\n那倒也算是能提高生产力~\n那暂时来说，\n华为或者说鸿蒙，并没有能给我类似的体验。\niOS 整个生态，倒是足够的舒适和好用。\n那大概很长一段时间来说，我应该是没有非用不可的情况的。\n如果是说非 iOS 生态下的话，我可能依旧还是选择 Android。\n所以我手上是拿着另一台红米 K50，价格大概是华为鸿蒙机器的四分之一。\n对于我来说，K50 上能满足我绝大部分的需求了。\n展望 好像并没有展望。\n大家都脚踏式，\n好好努力咯。\nPhoto by Pawel Czerwinski on Unsplash\n","date":"2023-12-19T00:00:00Z","image":"https://liguobao.github.io/p/why-do-you-mo-to-huawei/cover_hu_e95a4276bf860a84.jpg","permalink":"https://liguobao.github.io/p/why-do-you-mo-to-huawei/","title":"是什么提高生产力的功能让你放弃iPhone转投华为？"},{"content":"Q: 程序员这个群体抽烟、喝酒、打牌几率高吗？\nA:\n身边情况 我先说身边的情况。\n我身边的程序员朋友，有抽烟情况的，大概是是一个半。\n一个 + 半个，一个是常年抽烟，半个是偶尔抽烟。\n喝酒的话，不完全统计，这个数量大概在 20%-30%左右。\n打牌的话，或者说是热衷于打牌的话，我没什么印象，随便估一下 5%。\n把打牌换成打游戏的话，这个大概能变成 70%。\n这个情况有趣的在于。\n其实把程序员身份去掉的话，\n上面的比列也没什么大的区别。\n能理解发生了什么事情吗？\n本问题最大的问题是：做了无关的预设。\n或者说，先问是不是再问为什么才对。\n那么这个问题如果被表达成：\n在大城市的你，身边抽烟喝酒打牌的几率高吗？\n那应该是一个比较有意思的问题了。\n扩展回答 那么，我来回答一下扩展提问。\n顺便说明上面人群的更多信息。\n还是刚刚的人群。\n抽烟的哥们大概高中就有类似的需求，一直到现在。\n喝酒的朋友呢，就很有地方特色了。\n基本喝酒的都是家里有那么点习惯的，甚至于是本地就产酒。\n他们的身体也是能消化酒精的，所以喝酒的几率就高了。\n（我个人是不喝酒的，家里有过敏基因）\n至于他们上学、工作之后，和朋友们基本也是能喝就喝。\n打牌的朋友，这个我很难说，因为我不太了解。\n看起来是他们的一种社交需求，倒不是为了赌钱。\n打游戏的朋友，这个就很好理解了。\n这年头哪有不打游戏的年轻人。jpg\n大概如此。\n","date":"2023-12-15T00:00:00Z","permalink":"https://liguobao.github.io/p/programmer-smoke-drink-play-cards/","title":"程序员这个群体抽烟、喝酒、打牌几率高吗？"},{"content":"Q:程序员和外卖员，有啥共同点？\n这个问题很有趣的。\n正经点来说：\n他们都是劳动者。\n这个说法谁都挑不出毛病~\n但是，明显这不是我们想要的答案。\n风口上的猪 那么有别的说法吗？\n我觉得有。\n首先：\n他们都曾经是风口中的行业。\n程序员是互联网风口中上飞的猪，\n外卖员是餐饮信息化风口中上飞的猪。\n因此他们都曾今因此拿到过很不错的收入。\n互联网的风还在吹，虽然已经有点下坡路的样子。\n信息化的进程还在继续，没有下一场革命之前，估计还能继续苟。\n外卖的风余温还在，但是已经不是当初的样子了。\n餐饮行业的“改造”差不多到尽头了，外卖的市场也已经饱和了。\n那么外卖员确实有点风光不再了。\n搬运工 对吧。\n程序员大多都只是代码的搬运工，\n外卖员大多都是餐饮的搬运工。\n某个程度上，\n他们都是在做着重复的工作。\n当然程序员的工作还是比外卖员的工作要好一些的。\n因为程序员的工作是在电脑前完成的，\n而外卖员的工作是在户外完成的。\n至于能创造出新事物的程序员，\n某个程度上来说也不能纯粹说是程序员了。\n燃料 某个程度上来说。\n他们都是城市的燃料。\n程序员是城市信息化的燃料，\n外卖员是城市人口的燃料。\n很是绝望。\n","date":"2023-12-14T00:00:00Z","permalink":"https://liguobao.github.io/p/programmer-and-deliveryman/","title":"程序员和外卖员，有啥共同点？"},{"content":"看了下我的日常作息，iPhone 帮我统计的数据是这样的：\n基本在十一点到两点之间卧床，\n然后七点到九点之间起来。\n睡眠时间平均在七个半小时左右。\n起床时间取决于上班时间，偶尔拖延。\n精神状况还算不错，偶尔会有疲劳感。\n入睡时间就不好说了。\n大部分时候基本十二点前结束了工作和学习，\n偶尔会因为看资料或者看书晚一点到一点多，\n周五周六比较放肆，可能会到两点多或者三点。\n就如我之前在另一个回答说的：\n白天永远都是忙忙碌碌，\n夜晚完全属于自己。\n并不好说整个习惯是多好。\n就晚睡来说，基本是从高中开始的作息了。\n以前说什么勤奋学习，其实晚上效率也不高。\n最近几年终于能很平静的看书学习，晚上确实就是一个很舒服的时间了。\n没有打扰，没有消息，没有电话，没有人来找你。\n只有你自己，你的书，你的电脑，你的代码。\n一切都属于你自己。\n还有个有趣的事情。\n如果你是一个程序员，你会发现你的程序员朋友们，大部分都是晚睡的。\n然后，你要是能上一个神奇的网站，关注某些正在使用的开源仓库。\n有机会在上面反馈一些 issue 的话，大概会发现大多数时候，\n很多 issue 会在凌晨被回复。（ 虽然，有一部分情况是因为时区~\n大概如此。\n最后。\n","date":"2023-12-10T00:00:00Z","permalink":"https://liguobao.github.io/p/programmer-sleep-time/","title":"作为一个程序员，作息几点睡觉比较合适?"},{"content":"某个小项目需要支持一下 MySQL 全库备份，\n本来想着要不做个从库之类的完事了，\n但是本来数据库也就几万条数据，\n搞这玩意实在是蛋疼。\n又想着要不直接启定时任务，\n用 MySQL dump 命令行折腾一下算了，\n但是\u0026hellip;.\n还是觉得懒。\n要不看下有没有人封了库？\nSO\n找到了\u0026hellip;\n代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 Backup/Export a MySQL Database string constring = \u0026#34;server=localhost;user=root;pwd=qwerty;database=test;\u0026#34;; string file = \u0026#34;C:\\\\backup.sql\u0026#34;; using (MySqlConnection conn = new MySqlConnection(constring)) { using (MySqlCommand cmd = new MySqlCommand()) { using (MySqlBackup mb = new MySqlBackup(cmd)) { cmd.Connection = conn; conn.Open(); mb.ExportToFile(file); conn.Close(); } } } Import/Restore a MySQL Database string constring = \u0026#34;server=localhost;user=root;pwd=qwerty;database=test;\u0026#34;; string file = \u0026#34;C:\\\\backup.sql\u0026#34;; using (MySqlConnection conn = new MySqlConnection(constring)) { using (MySqlCommand cmd = new MySqlCommand()) { using (MySqlBackup mb = new MySqlBackup(cmd)) { cmd.Connection = conn; conn.Open(); mb.ImportFromFile(file); conn.Close(); } } } 代码写得很清晰，反正抄一下就好。 生产可用代码 using System; using System.Collections.Generic; using System.Linq; using System.Net; using System.Net.Mail; using System.Text; using System.Threading.Tasks; using Microsoft.Extensions.Logging; using Microsoft.Extensions.Options; using MySql.Data.MySqlClient; namespace DatabasePro.Service { public class BackFileInfo { public int Id { get; set; } public string FileName { get; set; } public string FilePath { get; set; } public string FileSize { get; set; } public string FileSizeMB { get { var size = Convert.ToDouble(FileSize); return (size / 1024 / 1024).ToString(\u0026#34;0.00\u0026#34;); } } public string CreateTime { get; set; } } public class DBBackService : IService { private AppConfiguration configuration; private ILogger\u0026lt;DBBackService\u0026gt; _logger; public DBBackService(IOptions\u0026lt;AppConfiguration\u0026gt; options, ILogger\u0026lt;DBBackService\u0026gt; logger) { configuration = options.Value; _logger = logger; } public string ExportToFile() { string baseDir = configuration.StoredFilesPath + \u0026#34;/backup\u0026#34;; _logger.LogInformation(\u0026#34;Start backup database.\u0026#34;); var conString = configuration.QCloudMySQL; var today = DateTime.Now; string importFileName = $\u0026#34;{baseDir}/{today.ToString(\u0026#34;yyyyMMdd_HHmm\u0026#34;)}.sql\u0026#34;; _logger.LogInformation($\u0026#34;Backup file name: {importFileName}\u0026#34;); using (MySqlConnection conn = new MySqlConnection(conString)) { _logger.LogInformation($\u0026#34;ConnectionTimeout:{conn.ConnectionTimeout}\u0026#34;); using (MySqlCommand cmd = new MySqlCommand()) { cmd.CommandTimeout = 3600; using (MySqlBackup mb = new MySqlBackup(cmd)) { cmd.Connection = conn; conn.Open(); mb.ExportToFile(importFileName); conn.Close(); } } } _logger.LogInformation($\u0026#34;Backup database to {importFileName} successfully.\u0026#34;); return importFileName; } public string ImportFromFile(string filePath) { var conString = configuration.QCloudMySQL; _logger.LogInformation($\u0026#34;ImportFromFile filePath: {filePath} start.\u0026#34;); using (MySqlConnection conn = new MySqlConnection(conString)) { using (MySqlCommand cmd = new MySqlCommand()) { cmd.CommandTimeout = 3600; using (MySqlBackup mb = new MySqlBackup(cmd)) { cmd.Connection = conn; conn.Open(); mb.ImportFromFile(filePath); conn.Close(); } } } _logger.LogInformation($\u0026#34;ImportFromFile {filePath} successfully, user: {userInfo?.UserName}\u0026#34;); return filePath; } public void DeleteFile(string filePath) { if (string.IsNullOrEmpty(filePath)) { return; } if (!filePath.Contains(\u0026#34;backup\u0026#34;)) { _logger.LogInformation($\u0026#34;DeleteFile filePath: {filePath} not in backup folder, ignore.\u0026#34;); return; } if (System.IO.File.Exists(filePath)) { System.IO.File.Delete(filePath); } _logger.LogInformation($\u0026#34;DeleteFile {filePath} successfully, user: {userInfo?.UserName}\u0026#34;); } public QueryResult\u0026lt;BackFileInfo\u0026gt; LoadBackupList() { var fileList = new List\u0026lt;BackFileInfo\u0026gt;(); string baseDir = configuration.StoredFilesPath + \u0026#34;/backup\u0026#34;; _logger.LogInformation(\u0026#34;Start load backup list.\u0026#34;); if (!System.IO.Directory.Exists(baseDir)) { System.IO.Directory.CreateDirectory(baseDir); } var files = System.IO.Directory.GetFiles(baseDir); var index = 1; foreach (var file in files) { var fileInfo = new System.IO.FileInfo(file); var backFileInfo = new BackFileInfo(); backFileInfo.Id = index; backFileInfo.FileName = fileInfo.Name; backFileInfo.FilePath = file; backFileInfo.FileSize = fileInfo.Length.ToString(); backFileInfo.CreateTime = fileInfo.CreationTime.ToString(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); fileList.Add(backFileInfo); index = index + 1; } var result = new QueryResult\u0026lt;BackFileInfo\u0026gt;(); result.list = fileList.OrderByDescending(x =\u0026gt; x.CreateTime).ToList(); result.total = fileList.Count; return result; } } } 注释也没写，反正没几行代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 using Microsoft.AspNetCore.Mvc; using DatabasePro.Filters; using DatabasePro.RestAPI.Helpers; using DatabasePro.Service; using Swashbuckle.AspNetCore.Annotations; namespace DatabasePro.Controllers { [ApiController] public class DBBackController : ApiControllerBase { private readonly DBBackService \\_dbBackService; public DBBackController(DBBackService dbBackService) { _dbBackService = dbBackService; } /// \u0026lt;summary\u0026gt; /// /// \u0026lt;/summary\u0026gt; [HttpGet] [Route(\u0026#34;/v1/admin/db-back-list\u0026#34;)] [ServiceFilter(typeof(AdminTokenAttribute))] [SwaggerResponse(200, \u0026#34;successfully.\u0026#34;)] public IActionResult LoadBackupList() { var fileList = _dbBackService.LoadBackupList(); return Wrapper(fileList); } /// \u0026lt;summary\u0026gt; /// 导出到备份文件 /// \u0026lt;/summary\u0026gt; [HttpGet] [Route(\u0026#34;/v1/admin/db-back-export\u0026#34;)] [ServiceFilter(typeof(AdminTokenAttribute))] public IActionResult ExportToFile() { var backSQLFile = _dbBackService.ExportToFile(); return Ok(new { data = backSQLFile, code = 0 }); } /// \u0026lt;summary\u0026gt; /// 导入备份文件 /// \u0026lt;/summary\u0026gt; [HttpGet] [Route(\u0026#34;/v1/admin/db-back-import\u0026#34;)] [ServiceFilter(typeof(AdminTokenAttribute))] public IActionResult ExportToFile([FromQuery] string filePath) { var backSQLFile = _dbBackService.ImportFromFile(filePath); return Ok(new { data = backSQLFile, code = 0 }); } /// \u0026lt;summary\u0026gt; /// 删除备份文件 /// \u0026lt;/summary\u0026gt; [HttpDelete] [Route(\u0026#34;/v1/admin/db-back-delete\u0026#34;)] [ServiceFilter(typeof(AdminTokenAttribute))] public IActionResult DeleteFile([FromQuery] string filePath) { _dbBackService.DeleteFile(filePath); return Ok(new { data = new { }, code = 0 }); } } } 接口大概是上面，自己照着调整一下完事。\n糊个页面\n大概，就这样。\n彩蛋时间 可能会遇到 MySQL 连接超时错误。\n看情况设置一下”connect-timeout“ 参数。\nconnect-timeout=3600\n导入数据的时候，可能会遇到”mysql Packets larger than max_allowed_packet are not allowed.“\n需要调整 ”max_allowed_packet“ 参数。\nmax-allowed-packet=1073741824\n如果你的 MySQL 也是 docker-compose 部署的，可以参考这个~\nargs: - --lower-case-table-names=1 - --max-connections=4000 - --connect-timeout=3600 - --max-allowed-packet=1073741824 - --sql-mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 还有彩蛋\n如果你想实现一个定时备份，\n在 dotnet core 中可以用 IHostService 实现，\n代码大概是\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Microsoft.Extensions.Hosting; using System.Threading; namespace DatabasePro.Service { public class DBBackupTimeHostedService : IHostedService, IDisposable { private readonly DBBackService _dbBackService; private Timer _timer; public DBBackupTimeHostedService(DBBackService dBBackService) { _dbBackService = dBBackService; } public Task StartAsync(CancellationToken cancellationToken) { // 启动定时器 _timer = new Timer(DoWork, null, GetDelayTo3AM(), TimeSpan.FromDays(1)); Serilog.Log.Information($\u0026#34;DBBackupTimeHostedService: StartAsync\u0026#34;); return Task.CompletedTask; } private void DoWork(object state) { try { var filePath = _dbBackService.ExportToFile(); Serilog.Log.Information($\u0026#34;DBBackupTimeHostedService: DoWork finish, filePath:{filePath}\u0026#34;); } catch (Exception ex) { Serilog.Log.Error($\u0026#34;DBBackupTimeHostedService: DoWork error, {ex.Message}\u0026#34;); } } public Task StopAsync(CancellationToken cancellationToken) { // 停止定时器 _timer?.Change(Timeout.Infinite, 0); return Task.CompletedTask; } public void Dispose() { _timer?.Dispose(); } // 北京时间凌晨3点执行（UTC 19点） private TimeSpan GetDelayTo3AM() { DateTime nowInUTC = DateTime.UtcNow; DateTime next7PMInUTC = nowInUTC.Date.AddHours(19); if (nowInUTC.Hour \u0026gt;= 19) { next7PMInUTC = next7PMInUTC.AddDays(1); } return next7PMInUTC - nowInUTC; } } } services.AddHostedService\u0026lt;DBBackupTimeHostedService\u0026gt;(); 完事。\n结尾\n简单粗暴的方案总有风险，\n苟住苟住~\n","date":"2023-10-26T23:09:00Z","permalink":"https://liguobao.github.io/p/dotnet-core-mysql-backup/","title":"dotnet core 实现MySQL数据库备份和还原"},{"content":"奇怪的故障 家里的台式机上有两个网卡，\n主板自带有线网卡，PCIE 上插了一个无线网卡。\n上次搞 李国宝：Tesla P40 显卡 2023 年 9 月跳坑指南\n这玩意的时候，拆装过主板和机箱，\n系统重新开始之后就有线网卡就掉线了。\n很是奇怪。\n再早一些时间也遇到过类似的问题，\n每次都是把手动把之前的 Ubuntu 的 WLAN 有线网卡删掉之后，\n重新添加回来，然后就正常工作了。\n但是现在\u0026hellip;\n遇到了问题。\n我手上没有显示器了。\n（PS：之前的借给朋友用了）\n倒是客厅有电视机，但\u0026hellip;.\n网线拉不过去。很是尴尬。\n于是，无线网凑合用了好一阵子了。\n迷。\n说好的计算机世界没有玄学。\n道理上。\n只需要重置这个网卡就完事了。\n在 ifconfig 里面，正常的网卡配置长这样。\n无线网卡\n一般的虚拟网络长这样。\n不正常的网卡。\nPS：没有 inet 字段，因为系统识别异常。\nifconfig down \u0026amp; up 禁用之后再启用网卡是使用 ifconfig 命令的。\n但是在这里无效。\n参考：Linux 中国：Linux 中如何启用和禁用网卡？\n还有别的办法吗？\nLinux 中国：Linux 中如何启用和禁用网卡？\n在上面这个文章写过有 nmtui 工具。\nnmtui\nnmtui 是一个与 NetworkManager 交互的、基于 curses 图形库的终端 UI 应用。\n在启用 nmtui 的时候，如果第一个参数没有特别指定，它会引导用户选择对应的操作去执行。\n执行以下命令打开 mntui 界面。选择 “Active a connection” 然后点击 “OK”。\nPS： 这里都是正常的配置了。\n异常配置的情况下，Device 显示的是一个无效的网卡 id\n选中网卡，选择 delete。\n然后重新 Add 一个新的网络。\n填入我们在 ifconfig 看到的网卡 Id。\n选择 ok。\n完事。\n回顾问题\n到这里突然想明白了。\n这个玩意是因为，硬件变更系统重新初始化之后，\n给主板网卡分配了一个新的设备 Id，\n然后系统网络配置使用的还是旧的设备 Id，\n于是\u0026hellip;.\n网络没办法正常工作了。\n重置网卡设备对它是无效的。\n只能重新初始化网络配置。\nSo\u0026hellip;\n如上。\n","date":"2023-09-22T00:00:00Z","image":"https://liguobao.github.io/p/ubuntu-wifi-loss/xiaohei_hu_baba6c28678501c7.png","permalink":"https://liguobao.github.io/p/ubuntu-wifi-loss/","title":"Ubuntu 有线网卡掉线重启备忘"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] One line code block 1 \u0026lt;p\u0026gt;A paragraph\u0026lt;/p\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-09-07T00:00:00Z","permalink":"https://liguobao.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Hugo theme Stack supports the creation of interactive image galleries using Markdown. It\u0026rsquo;s powered by PhotoSwipe and its syntax was inspired by Typlog.\nTo use this feature, the image must be in the same directory as the Markdown file, as it uses Hugo\u0026rsquo;s page bundle feature to read the dimensions of the image. External images are not supported.\nSyntax 1 ![Image 1](1.jpg) ![Image 2](2.jpg) Result Photo by mymind and Luke Chesser on Unsplash\n","date":"2023-08-26T00:00:00Z","image":"https://liguobao.github.io/p/image-gallery/2_hu_3e58a979f20e4e46.jpg","permalink":"https://liguobao.github.io/p/image-gallery/","title":"Image gallery"},{"content":"For more details, check out the documentation.\nBilibili video Tencent video YouTube video Generic video file Your browser doesn't support HTML5 video. Here is a link to the video instead. Gist GitLab Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n― A famous person, The book they wrote Photo by Codioful on Unsplash\n","date":"2023-08-25T00:00:00Z","image":"https://liguobao.github.io/p/shortcodes/cover_hu_5667347daefb4230.jpg","permalink":"https://liguobao.github.io/p/shortcodes/","title":"Shortcodes"},{"content":"Stack has built-in support for math typesetting using KaTeX.\nIt\u0026rsquo;s not enabled by default side-wide, but you can enable it for individual posts by adding math: true to the front matter. Or you can enable it side-wide by adding math = true to the params.article section in config.toml.\nInline math This is an inline mathematical expression: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\n1 $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$ Block math $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n1 2 3 $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$ $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi),e^{2 \\pi i \\xi x},d\\xi $$\n1 2 3 $$ f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi $$ ","date":"2023-08-24T00:00:00Z","permalink":"https://liguobao.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Python Flask最佳实践：一、项目初始化 前言 Python Flask 是一个很简单方便的Web框架，\n轻轻松松就可以完成一个Web 或者纯Web API。\n前阵子需要起一个简单的Web + 脚本项目，折腾flask的时候发现没找到比较顺手的脚手架教程。\n摸索了好一些知识，踩了一下坑什么的，\n最后站在巨人肩膀上更新个教程。\n代码项目结构 正儿八经一个项目工程，遵循 三层架构 + MVC模型 对项目代码有严格的划分，\n对这两个概念不太了解的朋友可以自行课后补习一下。\n说明如下:\nsrc 所有的项目代码文件 src/service 逻辑层代码 src/model 业务实体 src/db 数据库相关，包括model定义和dao SQL查询 src/sdk 依赖的外部接口 src/job 后台进程启动的Job，一般都是通过API启动的后台任务 src/utils 工具类，config 配置类也在里面 src/app.py flask app 启动项 manage.py flask.cli 启动入口 api + job Dockerfile Docker打包流程 debug.py 本地debug 启动入口 requirements.txt 所有的依赖包 .vscode/launch.json vs code debug 配置 开搞 废话多说两句，我比较喜欢requirements这种包组织方式，其他的就看自己了。\nrequirements.txt 1 2 3 4 5 6 7 8 9 10 flask flask-swagger flask-swagger-ui flask-bootstrap SQLAlchemy pymysql pydantic requests loguru gunicorn 简单说明\nflask是核心包，flask-swagger + flask-swagger-ui 是用来做Swagger UI的，flask-bootstrap 用来乱糊 HTML页面的 SQLAlchemy + pymysql + 一个是数据库ORM框架，一个是数据库驱动 pydantic 用来配合SQLAlchemy完成Model数据转换，解决一些奇怪的序列化反序列化问题 requests 用来对接外部HTTP接口或者写爬虫脚本 loguru 简易日志框架，from loguru import logger 就完事了 gunicorn 多进程部署 ","date":"2021-09-05T00:00:00Z","permalink":"https://liguobao.github.io/p/python-flask%E4%B8%80%E9%A1%B9%E7%9B%AE%E5%88%9D%E5%A7%8B%E5%8C%96/","title":"Python Flask：一、项目初始化"},{"content":"QCloud Serverless 如何看待腾讯云.云开发推出低代码开发平台？未来真的有可能人人都是“开发者”吗？ 低代码平台不算大新闻，赶的晚的腾讯云有自己的方案 讲述一下 serverless 的历史，从简单讲讲云主机的历史，然后从 AWS lambda 平台讲起，提及一下阿里云，最后讲腾讯云 Serverless 能力 这里只能讲到 Serverless 相比托管主机、容器集群的好处 提及对开发模式的改变什么，还有讲下腾讯云的优势，不太能非常突出低代码平台什么的 腾讯云的小程序云开发有什么特别 云数据库、云存储都可以着重讲一下，这部分是比较靓丽的，其他家都没有直接集成的（据我所知） 微信生态 + 腾讯生态的便捷接入，支付、地图、身份认证相关，处处快人一步 其他工具 VS Code 插件 + 微信小程序开发工具 + 运维集成相关 人人开发者？ 讲讲软件开发是什么？开发者主要做什么？（这里要通俗点，又得讲的清楚） 腾讯云开发能为降低开发者门槛做了什么？（不能太吹得太厉害，不过吹一下小步快跑快速验证产品还是可以的） 展望一下未来（这个看要写点撒了） 如何看待小程序云开发把程序员的准入门槛降低？那如何衡量一个程序员的价值？ 先把门槛画出来 开发是什么？一个产品上线要做什么？（可能需要样例，也需要一些简单的理论） 讲清楚门槛是怎么产生的，在后面尽可能圆回来 小程序做了什么？（尽量最后中性评价吧，这个有点难） 先骂一下（自成体系？性能一般？） 再表扬一下(随用随走、开发门槛低、多端统一、质量保证) 小程序云开发做了什么？ 和小程序高度集成 提供了数据库和存储能力 部分场景可以做到无后端或者弱后端，甚至不需要自己的服务器（成本也可以讲讲） 反正这部分尽量表扬和尽可能表达 我们说的门槛低了，那么程序员的价值究竟是什么 做产品门槛低了，试错的成本低了，做成一个项目的门槛还是在的 复杂的世界里面，计算机理论要用在哪？真的可以扔掉吗？ 多快好省的开发模式究竟应该怎么玩？ 最最后总结一下 ","date":"2020-11-29T00:00:00Z","permalink":"https://liguobao.github.io/p/qcloud-serverless/","title":"QCloud Serverless"},{"content":"一次依赖注入不慎引发的一连串事故。\n起因和现象 偶尔会看到线上服务启动的时候第一波流量进来之后，\n迟迟没有任何的响应，同时服务的监控检查接口正常，\n所以 K8S 集群认为服务正常，继续放入流量。\n查看日志基本如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [2020-06-05T13:00:30.7080743+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test [2020-06-05T13:00:30.7081525+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type [2020-06-05T13:00:31.7074253+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR21\u0026#34; started. [2020-06-05T13:00:31.7077051+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test/account-balance [2020-06-05T13:00:31.7077942+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type [2020-06-05T13:00:32.2103440+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR22\u0026#34; started. [2020-06-05T13:00:32.2118432+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test/account-balance [2020-06-05T13:00:32.2125894+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-ba\u0026#39;lan\u0026#39;ce does not match a supported file type [2020-06-05T13:00:33.2223942+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR23\u0026#34; started. [2020-06-05T13:00:33.2238736+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test/account-balance [2020-06-05T13:00:33.2243808+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type [2020-06-05T13:00:34.2177528+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR24\u0026#34; started. [2020-06-05T13:00:34.2189073+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test/account-balance [2020-06-05T13:00:34.2193483+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type [2020-06-05T13:00:35.2169806+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR25\u0026#34; started. [2020-06-05T13:00:35.2178259+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test/account-balance [2020-06-05T13:00:35.2181055+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type [2020-06-05T13:00:36.2183025+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR26\u0026#34; started. [2020-06-05T13:00:36.2195050+00:00 Microsoft.AspNetCore.Hosting.Diagnostics INF] Request starting HTTP/1.0 GET http://172.16.2.52/v1/user/test/account-balance [2020-06-05T13:00:36.2199702+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type [2020-06-05T13:00:37.2373822+00:00 Microsoft.AspNetCore.Server.Kestrel DBG] Connection id \u0026#34;0HM09A1MAAR27\u0026#34; started. 引发的几种后果 客户端调用超时 经过了 30S 甚至更长时间后看到大量的数据库连接被初始化，然后开始集中式返回。\n此时可能对于客户端调用来说这一批请求都是超时的，\n严重影响用户体验和某些依赖于此的其他接口。\n数据库连接暴涨 因为同时进入大量数据库查询请求触发数据库 DbContextPool 大量创建，\n连接数随之暴涨，数据库查询性能急速下降，可能引发其他的应用问题。\n引发服务“雪崩”效应，服务不可用 请求堆积的情况下，\nhealth-check 接口响应异常，\n导致 k8s 主动重启服务，重启后继续上述情况，\n不断恶化最后导致服务不可用。\n排查问题 数据库的问题 ？ 当然，首先怀疑的就是数据库了。\n存在性能瓶颈？慢查询导致不响应？发布期间存在其他的异常？\n这类的问题都意义排查起来了。\n最后发现，\n这种情况发生的时候，数据库监控里面一片祥和。\n数据库 IO、CPU、内存都正常，\n连接数暴涨是这种情况发生的时候带来的，\n而不是连接数暴涨之后导致了此情况。\n数据库驱动或者 EF Core 框架的问题？ 是的，\n这个怀疑一直都存在于脑海中。\n最终，\n昨天带着“被挨骂的情况”去问了下“Pomelo.EntityFrameworkCore.MySql”的作者。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 春天的熊 18:34:08 柚子啊，我这边的.NET Core服务刚起来，建立MySQL连接的时候好慢，然后同一批请求可能无法正常响应，这个有什么好的解决思路吗？ Yuko丶柚子 18:34:29 Min Pool Size = 200 Yuko丶柚子 18:34:32 放连接字符串里 春天的熊 18:34:53 这个字段支持了吗？ Yuko丶柚子 18:35:07 一直都支持 春天的熊 18:35:56 等等， public static IServiceCollection AddDbContextPool\u0026lt;TContext\u0026gt;([NotNullAttribute] this IServiceCollection serviceCollection, [NotNullAttribute] Action\u0026lt;DbContextOptionsBuilder\u0026gt; optionsAction, int poolSize = 128) where TContext : DbContext; 春天的熊 18:36:13 这里不是默认最大的128么？ Yuko丶柚子 18:36:18 你这个pool size是dbcontext的 Yuko丶柚子 18:36:21 我说的是mysql连接字符串的 Yuko丶柚子 18:36:28 dbcontext的pool有什么用 春天的熊 18:43:13 我问个讨打的问题，dbcontext 是具体的链接实例，EF用的，Min Pool Size 指的是这一个实例上面的连接池吗“？ Yuko丶柚子 18:44:07 你在说什么。。。 Yuko丶柚子 18:45:58 放到mysql的连接字符串上 Yuko丶柚子 18:46:14 这样第一次调用MySqlConnection的时候就会建立200个连接 春天的熊 18:46:56 默认是多少来的？100吗？ Yuko丶柚子 18:48:33 0 Yuko丶柚子 18:48:40 max默认是100 Yuko丶柚子 18:52:50 DbContextPool要解决的问题你都没搞清楚 春天的熊 18:53:23 DbContextPool要解决的是尽量不去重复创建DbContext Yuko丶柚子 18:53:34 为什么不要重复创建DbContext 春天的熊 18:53:50 因为每个DbContext创建的代价很高，而且很慢 Yuko丶柚子 18:54:01 创建DbContext有什么代价 Yuko丶柚子 18:54:03 哪里慢了 Yuko丶柚子 18:54:06 都是毫秒级的 Yuko丶柚子 18:54:20 他的代价不在于创建 而在于回收 Yuko丶柚子 18:54:25 DbContextPool要解决的问题是 因为DbContext属于较大的对象，而且是频繁被new，而且经常失去引用导致GC频繁工作。 Yuko 大大说的情况感觉会是一个思路，\n所以第一反应就是加了参数控制连接池。\n不过，无果。\n5 个实例，\n有 3 个实例正常启动，\n2 个实例会重复“雪崩”效应，最终无法正常启动。\n这个尝试操作重复了好多次，\n根据文档和 Yuko 大大指导继续加了不少 MySQL 链接参数，\n最后，\n重新学习了一波链接参数的优化意义，\n无果。\n究竟数据库驱动有没有问题？ 没什么好的思路了，\n远程到容器里面 Debug 基本不太现实（重新打包 + 容器化打包 + k8s + 人肉和服务器垮大洋），\n要不，试试把日志登录调节到 Debug 看看所有的行为？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \u0026#34;Using\u0026#34;: [\u0026#34;Serilog.Sinks.Console\u0026#34;], \u0026#34;MinimumLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Debug\u0026#34;, \u0026#34;Override\u0026#34;: { \u0026#34;Microsoft\u0026#34;: \u0026#34;Debug\u0026#34; } }, \u0026#34;WriteTo\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;Console\u0026#34;, \u0026#34;Args\u0026#34;: { \u0026#34;outputTemplate\u0026#34;: \u0026#34;[{Timestamp:o} {SourceContext} {Level:u3}] {Message:lj}{NewLine}{Exception}\u0026#34; } } ] } 当然，这个事情没有直接在正常的生产环境执行。\n这里是使用新配置，重新起新实例来操作。\n然后我们看到程序启动的时候执行 EFMigration 的时候，\n程序和整个数据库交互的完整日志。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [2020-06-05T12:59:56.4147202+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Opening connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.4159970+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Opened connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;a\u0026#39;li\u0026#39;yun\u0026#39;. [2020-06-05T12:59:56.4161172+00:00 Microsoft.EntityFrameworkCore.Database.Command DBG] Executing DbCommand [Parameters=[], CommandType=\u0026#39;Text\u0026#39;, CommandTimeout=\u0026#39;30\u0026#39;] SELECT 1 FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA=\u0026#39;user_pool\u0026#39; AND TABLE_NAME=\u0026#39;__EFMigrationsHistory\u0026#39;; [2020-06-05T12:59:56.4170776+00:00 Microsoft.EntityFrameworkCore.Database.Command INF] Executed DbCommand (1ms) [Parameters=[], CommandType=\u0026#39;Text\u0026#39;, CommandTimeout=\u0026#39;30\u0026#39;] SELECT 1 FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA=\u0026#39;user_pool\u0026#39; AND TABLE_NAME=\u0026#39;__EFMigrationsHistory\u0026#39;; [2020-06-05T12:59:56.4171630+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Closing connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.4172458+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Closed connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.4385345+00:00 Microsoft.EntityFrameworkCore.Database.Command DBG] Creating DbCommand for \u0026#39;ExecuteReader\u0026#39;. [2020-06-05T12:59:56.4386201+00:00 Microsoft.EntityFrameworkCore.Database.Command DBG] Created DbCommand for \u0026#39;ExecuteReader\u0026#39; (0ms). [2020-06-05T12:59:56.4386763+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Opening connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.4400143+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Opened connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.4404529+00:00 Microsoft.EntityFrameworkCore.Database.Command DBG] Executing DbCommand [Parameters=[], CommandType=\u0026#39;Text\u0026#39;, CommandTimeout=\u0026#39;30\u0026#39;] SELECT `MigrationId`, `ProductVersion` FROM `__EFMigrationsHistory` ORDER BY `MigrationId`; [2020-06-05T12:59:56.4422387+00:00 Microsoft.EntityFrameworkCore.Database.Command INF] Executed DbCommand (2ms) [Parameters=[], CommandType=\u0026#39;Text\u0026#39;, CommandTimeout=\u0026#39;30\u0026#39;] SELECT `MigrationId`, `ProductVersion` FROM `__EFMigrationsHistory` ORDER BY `MigrationId`; [2020-06-05T12:59:56.4446400+00:00 Microsoft.EntityFrameworkCore.Database.Command DBG] A data reader was disposed. [2020-06-05T12:59:56.4447422+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Closing connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.4447975+00:00 Microsoft.EntityFrameworkCore.Database.Connection DBG] Closed connection to database \u0026#39;user_pool\u0026#39; on server \u0026#39;aliyun-rds\u0026#39;. [2020-06-05T12:59:56.5170419+00:00 Microsoft.EntityFrameworkCore.Migrations INF] No migrations were applied. The database is already up to date. 看到这里的时候，由于发现我们之前对 DbContext 和 DbConnection 的理解不太好，\n想搞清楚究竟是不 db connection 创建的时候有哪些行为，\n于是我们找到了 dotnet/efcore Github 的源码开始拜读，\nPS： 源码真香，能看源码真好。\n尝试通过“Opening connection”找到日志的场景。\n想了解这个日志输出的时候代码在做什么样的事情，可能同时会有哪些行为。\n在考虑是不是其他的一些行为导致了上面的服务问题？\n最终在RelationalConnection.cs确认上面这些数据库相关日志肯定是会输出的，不存在其他的异常行为。\nPS：不用细看，我们认真浏览了代码之后确认 DbContext 正常初始化，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 /// \u0026lt;summary\u0026gt; /// Asynchronously opens the connection to the database. /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;errorsExpected\u0026#34;\u0026gt; Indicate if the connection errors are expected and should be logged as debug message. \u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;cancellationToken\u0026#34;\u0026gt; /// A \u0026lt;see cref=\u0026#34;CancellationToken\u0026#34; /\u0026gt; to observe while waiting for the task to complete. /// \u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt; /// A task that represents the asynchronous operation, with a value of \u0026lt;see langword=\u0026#34;true\u0026#34;/\u0026gt; if the connection /// was actually opened. /// \u0026lt;/returns\u0026gt; public virtual async Task\u0026lt;bool\u0026gt; OpenAsync(CancellationToken cancellationToken, bool errorsExpected = false) { if (DbConnection.State == ConnectionState.Broken) { await DbConnection.CloseAsync().ConfigureAwait(false); } var wasOpened = false; if (DbConnection.State != ConnectionState.Open) { if (CurrentTransaction != null) { await CurrentTransaction.DisposeAsync().ConfigureAwait(false); } ClearTransactions(clearAmbient: false); await OpenDbConnectionAsync(errorsExpected, cancellationToken).ConfigureAwait(false); wasOpened = true; } _openedCount++; HandleAmbientTransactions(); return wasOpened; } private async Task OpenDbConnectionAsync(bool errorsExpected, CancellationToken cancellationToken) { var startTime = DateTimeOffset.UtcNow; var stopwatch = Stopwatch.StartNew(); // 日志输出在这里 var interceptionResult = await Dependencies.ConnectionLogger.ConnectionOpeningAsync(this, startTime, cancellationToken) .ConfigureAwait(false); try { if (!interceptionResult.IsSuppressed) { await DbConnection.OpenAsync(cancellationToken).ConfigureAwait(false); } // 日志输出在这里 await Dependencies.ConnectionLogger.ConnectionOpenedAsync(this, startTime, stopwatch.Elapsed, cancellationToken) .ConfigureAwait(false); } catch (Exception e) { await Dependencies.ConnectionLogger.ConnectionErrorAsync( this, e, startTime, stopwatch.Elapsed, errorsExpected, cancellationToken) .ConfigureAwait(false); throw; } if (_openedCount == 0) { _openedInternally = true; } } 当然，我们同时也去看了一眼 MySqlConnector的源码，\n确认它自身是维护了数据库连接池的。到这里基本确认不会是数据库驱动导致的上述问题。\n某种猜测 肯定是有什么奇怪的行为阻塞了当前服务进程， 导致数据库连接的日志也没有输出。 锁？ 异步等同步？资源初始化问题？ 周五晚上查到了这里已经十一点了，\n于是先下班回家休息了。\n于是，\n周六练完车之后 Call 了一下小伙伴，\n又双双开始了愉快的 Debug。\n插曲 小伙伴海林回公司前发了个朋友圈。\n“ 咋们继续昨天的 bug，\n特此立 flag：修不好直播吃 bug\n反正不是你死就是我亡…”\n我调侃评论说:\n你等下，我打包下代码去楼下打印出来待会当晚饭\n开始锁定问题 中间件导致的吗？ 1 2 3 [2020-06-05T13:00:35.2181055+00:00 Microsoft.AspNetCore.StaticFiles.StaticFileMiddleware DBG] The request path /v1/user/test/account-balance does not match a supported file type 我们对着这个日志思考了一会人生，\n然后把引用此中间件的代码注释掉了，\n不过，无果。\n自定义 filters 导致的吗？ 1 2 3 4 [2020-06-05T13:01:05.3126001+00:00 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker DBG] Execution plan of exception filters (in the following order): [\u0026#34;None\u0026#34;] [2020-06-05T13:01:05.3126391+00:00 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker DBG] Execution plan of result filters (in the following order): [\u0026#34;Microsoft.AspNetCore.Mvc.ViewFeatures.Filters.SaveTempDataFilter\u0026#34;, \u0026#34;XXX.Filters.HTTPHeaderAttribute (Order: 0)\u0026#34;] [2020-06-05T13:01:05.3072206+00:00 Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker DBG] Execution plan of authorization filters (in the following order): [\u0026#34;None\u0026#34;] 看到这个日志我们考虑了一下，\n是不是因为 filters 导致了问题。\n毕竟在 HTTPHeaderAttribute 我们还还做了 ThreadLocal\u0026lt;Dictionary\u0026lt;string, string\u0026raquo; CurrentXHeaders\n这里怀疑是不是我们的实现存在锁机制导致“假死问题”。\n尝试去掉。\n不过，\n无果。\n尝试使用 ptrace 没什么很好的头绪了，要不上一下 ptrace 之类的工具跟一下系统调用？\n最早在去年就尝试过使用 ptrace 抓进程数据看系统调用，\n后来升级到.NET Core3.0 之后，官方基于 Events + LTTng 之类的东西做了 dotnet-trace 工具，\n官网说明：dotnet-trace performance analysis utility\n改一下打包扔上去做一个数据收集看看。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 FROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS build-env WORKDIR /app # copy csproj and restore as distinct layers COPY src/*.csproj ./ RUN dotnet restore COPY . ./ # copy everything else and build RUN dotnet publish src -c Release -o /app/out # build runtime image FROM mcr.microsoft.com/dotnet/core/aspnet:3.1 # debug # Install .NET Core SDK RUN dotnet_sdk_version=3.1.100 \\ \u0026amp;\u0026amp; curl -SL --output dotnet.tar.gz https://dotnetcli.azureedge.net/dotnet/Sdk/$dotnet_sdk_version/dotnet-sdk-$dotnet_sdk_version-linux-x64.tar.gz \\ \u0026amp;\u0026amp; dotnet_sha512=\u0026#39;5217ae1441089a71103694be8dd5bb3437680f00e263ad28317665d819a92338a27466e7d7a2b1f6b74367dd314128db345fa8fff6e90d0c966dea7a9a43bd21\u0026#39; \\ \u0026amp;\u0026amp; echo \u0026#34;$dotnet_sha512 dotnet.tar.gz\u0026#34; | sha512sum -c - \\ \u0026amp;\u0026amp; rm -rf /usr/share/dotnet \\ \u0026amp;\u0026amp; rm -rf /usr/bin/dotnet \\ \u0026amp;\u0026amp; mkdir -p /usr/share/dotnet \\ \u0026amp;\u0026amp; tar -ozxf dotnet.tar.gz -C /usr/share/dotnet \\ \u0026amp;\u0026amp; rm dotnet.tar.gz \\ \u0026amp;\u0026amp; ln -s /usr/share/dotnet/dotnet /usr/bin/dotnet \\ # Trigger first run experience by running arbitrary cmd \u0026amp;\u0026amp; dotnet help RUN dotnet tool install --global dotnet-trace RUN dotnet tool install -g dotnet-dump RUN dotnet tool install --global dotnet-counters ENV PATH=\u0026#34;$PATH:/root/.dotnet/tools\u0026#34; # end debug WORKDIR /app COPY --from=build-env /app/out . ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;Your-APP.dll\u0026#34;] 更新发布，等待服务正常启动之后，\n使用 ab -c 300 -n 3000 \u0026lsquo;http://172.16.2.52/v1/user/test/account-balance\u0026rsquo; 模拟 300 个用户同时请求，\n使得程序进入上述的“假死状态”。\n接着立即进入容器，执行\u0026rsquo;dotnet-trace collect -p 1\u0026rsquo; 开始收集日志。\n最后拿到了一份大概 13M trace.nettrace 数据, 这个文件是 PerView 支持的格式，\n在 MacOS 或者 Linux 上无法使用。\n好在 dotnet-trace convert 可以将 trace.nettrace 转换成 speedscope/chromium 两种格式。\nspeedscope/chromium speedscope:A fast, interactive web-based viewer for performance profiles.\nchrome-devtools evaluate-performance 全新 Chrome Devtool Performance 使用指南\n1 2 3 $dotnet-trace convert 20200606-1753-trace.nettrace.txt --format Speedscope $dotnet-trace convert 20200606-1753-trace.nettrace.txt --format chromium $speedscope 20200606-1753-trace.nettrace.speedscope.json 然后，炸鸡了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ➜ Downloads speedscope 20200606-1625.trace.speedscope.json Error: Cannot create a string longer than 0x3fffffe7 characters at Object.slice (buffer.js:652:37) at Buffer.toString (buffer.js:800:14) at main (/home/liguobao/.nvm/versions/node/v12.16.2/lib/node_modules/speedscope/bin/cli.js:69:39) at processTicksAndRejections (internal/process/task_queues.js:97:5) Usage: speedscope [filepath] If invoked with no arguments, will open a local copy of speedscope in your default browser. Once open, you can browse for a profile to import. If - is used as the filepath, will read from stdin instead. cat /path/to/profile | speedscope - 哦， Buffer.toString 炸鸡了。\n看一眼 20200606-1625.trace.speedscope.json 多大?\n900M。\n牛逼。\n那换 Chrome performance 看看。\n手动装载一下 20200606-1753-trace.nettrace.chromium.json 看看。\n等下，20200606-1753-trace.nettrace.chromium.json 这货多大？\n哦，4G。应该没事，Intel NUC 主机内存空闲 20G，吃掉 4G 完全是没有问题的。\n看着进度条加载，看着内存涨起来，\n然后\u0026hellip;Chrome 控制台奔溃。再见再见，原来大家彼此完全没有信任了。\n唉，再来一次，把文件控制在 5M 左右看看。\n最后，把 20200606-1753-trace.nettrace.chromium.json 控制在 1.5G 了，\n终于可以正常加载起来了。\nChrome Performance 首先， 我们看到监控里面有一堆的线程\n随便选一个线程看看它做撒,选择 Call Tree 之后 点点点点点。\n从调用栈能看到 整个线程当前状态是“PerformWaitCallback”\n整个操作应该的开头应该是\nMicrosoft.AspNetCore.Server.Kestrel.Core.Internal.Infrastructure.KestrelConnection.System.Threading.IThreadPoolWorkItem.Execute()\nPS： Kestrel (https://github.com/aspnet/KestrelHttpServer) is a lightweight cross-platform web server that supports .NET Core and runs on multiple platforms such as Linux, macOS, and Windows. Kestrel is fully written in .Net core. It is based on libuv which is a multi-platform asynchronous eventing library.\nPS 人话： .NET Core 内置的 HTTP Server，和 Spring Boot 中的 tomcat 组件类似\n很正常，说明请求正常到了我们的服务里面了。\n再看一下剩下的调用链信息。\n简要的调用信息日志在这里：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start(!!0\u0026amp;) Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Infrastructure.KestrelConnection+\u0026lt;ExecuteAsync\u0026gt;d__32.MoveNext() Microsoft.AspNetCore.Server.Kestrel.Core.Internal.HttpConnectionMiddleware`1[System.__Canon].OnConnectionAsync(class Microsoft.AspNetCore.Connections.ConnectionContext) Microsoft.AspNetCore.Server.Kestrel.Core.Internal.HttpConnection.ProcessRequestsAsync(class Microsoft.AspNetCore.Hosting.Server.IHttpApplication`1\u0026lt;!!0\u0026gt;) System.Runtime.CompilerServices.AsyncTaskMethodBuilder.Start(!!0\u0026amp;) System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start(!!0\u0026amp;) Microsoft.AspNetCore.Server.Kestrel.Core.Internal.HttpConnection+\u0026lt;ProcessRequestsAsync\u0026gt;d__12`1[System.__Canon].MoveNext() Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequestsAsync(class Microsoft.AspNetCore.Hosting.Server.IHttpApplication`1\u0026lt;!!0\u0026gt;) System.Runtime.CompilerServices.AsyncTaskMethodBuilder.Start(!!0\u0026amp;) System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start(!!0\u0026amp;) Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol+\u0026lt;ProcessRequestsAsync\u0026gt;d__216`1[System.__Canon].MoveNext() Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests(class Microsoft.AspNetCore.Hosting.Server.IHttpApplication`1\u0026lt;!!0\u0026gt;) System.Runtime.CompilerServices.AsyncTaskMethodBuilder.Start(!!0\u0026amp;) System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start(!!0\u0026amp;) Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol+\u0026lt;ProcessRequests\u0026gt;d__217`1[System.__Canon].MoveNext() Microsoft.AspNetCore.Hosting.HostingApplication.ProcessRequestAsync(class Context) Microsoft.AspNetCore.HostFiltering.HostFilteringMiddleware.Invoke(class Microsoft.AspNetCore.Http.HttpContext) UserCenter.ErrorHandlingMiddleware.Invoke(class Microsoft.AspNetCore.Http.HttpContext) System.Runtime.CompilerServices.AsyncTaskMethodBuilder.Start(!!0\u0026amp;) System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start(!!0\u0026amp;) ...... ...... ...... e.StaticFiles.StaticFileMiddleware.Invoke(class Microsoft.AspNetCore.Http.HttpContext) Microsoft.AspNetCore.Builder.UseMiddlewareExtensions+\u0026lt;\u0026gt;c__DisplayClass4_1.\u0026lt;UseMiddleware\u0026gt;b__2(class Microsoft.AspNetCore.Http.HttpContext) dynamicClass.lambda_method(pMT: 00007FB6D3BBE570,class System.Object,pMT: 00007FB6D4739560,pMT: 00007FB6D0BF4F98) Microsoft.AspNetCore.Builder.UseMiddlewareExtensions.GetService(class System.IServiceProvider,class System.Type,class System.Type) Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(class System.Type) System.Runtime.CompilerServices.AsyncTaskMethodBuilder.Start(!!0\u0026amp;) Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2[Microsoft.Extensions.DependencyInjection.ServiceLookup.RuntimeResolverContext,System.__Canon].VisitCallSite(class Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceCallSite,!0) System.Runtime.CompilerServices.AsyncMethodBuilderCore.Start(!!0\u0026amp;) System.Runtime.CompilerServices.AsyncTaskMethodBuilder.Start(!!0\u0026amp;) 看到这里，其实又有了一些很给力的信息被暴露出来了。\nPerformWaitCallback 直接字面理解，线程正在执行等待回调 调用链信息 耐心点，把所有的电调用链都展开。\n我们能看到程序已经依次经过了下面几个流程：\n-\u0026gt;ProcessRequestsAsync(系统)\n-\u0026gt;ErrorHandlingMiddleware(已经加载了自定义的错误中间件)\n-\u0026gt; HostFilteringMiddleware(加载了 Filter 中间件)\n-\u0026gt; Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor(调用链中的最后一个操作)\n对应最上面的日志来说，\n请求进来，经过了中间件和 Filter 都是没问题的，\n最后在 DependencyInjection（依赖注入） 中没有了踪迹。\n到这里，\n再次验证我们昨天的思路：\n这是一个 “资源阻塞问题”产生的问题 虽然做 ptrace 是想能直接抓到“凶手”的，\n最后发现并没有能跟踪到具体的实现，\n那可咋办呢？\n控制变量实践 已知：\n并发 300 访问 /v1/user/test/account-balance 接口程序会假死 移除 Filter 中间件不能解决问题 并发 300 访问 /v1/health 健康检查接口程序正常 ptrace 信息告诉我们有“东西”在阻塞 DI 容器创建某些实例 开始控制变量 + 人肉二分查找。\n挪接口代码 /v1/user/test/account-balance 的逻辑是由 AccountService 实现的，\nAccountService 大概依赖四五个其他的 Service 和 DBContext，\n最主要的逻辑是加载用户几个账号，然后计算一下 balance。\n大概代码如下：\n1 2 3 4 5 6 7 8 9 10 /// \u0026lt;summary\u0026gt; /// 获取用户的AccountBalance汇总信息 /// \u0026lt;/summary\u0026gt; public async Task\u0026lt;AccountBalanceStat\u0026gt; LoadAccountBalanceStatAsync(string owner) { // 数据库查询 var accounts = await _dbContext.BabelAccounts.Where(ac =\u0026gt; ac.Owner == owner).ToListAsync(); // 内存计算 return ConvertToAccountBalanceStat(accounts); } 什么都不改，直接把代码 CP 到 Health 接口测一下。\n神奇，300 并发抗住了。\n结论：\n上面这一段代码并不会导致服务僵死 数据库驱动没有问题，DbContext 没有问题，数据库资源使用没有问题 当前并不会触发 DI 容器异常， 问题出在 /v1/user/test/account-balance 初始化 account-balance 有什么神奇的东西吗？ 1 2 3 4 5 6 7 8 9 10 11 12 /// \u0026lt;summary\u0026gt; /// 查询用户的Brick账号余额 /// \u0026lt;/summary\u0026gt; [HttpGet(\u0026#34;v1/user/{owner}/account-balance\u0026#34;)] [SwaggerResponse(200, \u0026#34;获取成功\u0026#34;, typeof(AccountBrickStat))] public async Task\u0026lt;IActionResult\u0026gt; GetAccountBricks( [FromRoute, SwaggerParameter(\u0026#34;所有者\u0026#34;, Required = true)] string owner) { owner = await _userService.FindOwnerAsync(owner); return Ok(new { data = await _accountService.LoadAccountAsync(owner), code = 0 }); } 我们刚刚验证了 LoadAccountAsync 的代码是没有问题的，\n要不 UserService DI 有问题，要不 AccountService DI 有问题。\n把 UserService 加入到 HealthController 中。\n1 2 3 4 5 6 public HealthController(UserService userService, UserPoolDataContext dbContext) { _dbContext = dbContext; _userService= userService; } Bool。\n300 并发没有撑住，程序僵死啦。\n完美，\n问题应该在 UserService DI 初始化了。\n接下来就是一个个验证 UserService DI 需要的资源，\nEmailSDK 没有问题，\nHTTPHeaderTools 没有问题，\nUserActivityLogService 没有问题。\nRedisClient\u0026hellip; RedisClient\u0026hellip; RedisClient\u0026hellip;\nOK OK Ok\n复现炸鸡了。\n原来是 Redis 的锅？ 是，\n也不是。\n先看下我们 RedisClient 是怎么使用的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // startup.cs 注入了单例的ConnectionMultiplexer // 程序启动的时候会调用InitRedis private void InitRedis(IServiceCollection services) { services.AddSingleton\u0026lt;ConnectionMultiplexer, ConnectionMultiplexer\u0026gt;(factory =\u0026gt; { ConfigurationOptions options = ConfigurationOptions.Parse(Configuration[\u0026#34;RedisConnectionString\u0026#34;]); options.SyncTimeout = 10 * 10000; return ConnectionMultiplexer.Connect(options); }); } //RedisClient.cs 通过构造函数传入 public class RedisClient { private readonly ConnectionMultiplexer _redisMultiplexer; private readonly ILogger\u0026lt;RedisClient\u0026gt; _logger; public RedisClient(ConnectionMultiplexer redisMultiplexer, ILogger\u0026lt;RedisService\u0026gt; logger) { _redisMultiplexer = redisMultiplexer; _logger = logger; } } DI 初始化 RedisClient 实例的时候，\n需要执行 ConnectionMultiplexer.Connect 方法，\nConnectionMultiplexer.Connect 是同步阻塞的。\nConnectionMultiplexer.Connect 是同步阻塞的。\nConnectionMultiplexer.Connect 是同步阻塞的。\n一切都能解释了。\n怎么改？\n1 2 3 4 5 6 7 8 9 // InitRedis 直接把链接创建好，然后直接注入到IServiceCollection中 private void InitRedis(IServiceCollection services) { ConfigurationOptions options = ConfigurationOptions.Parse(Configuration[\u0026#34;RedisConnectionString\u0026#34;]); options.SyncTimeout = 10 * 10000; var redisConnectionMultiplexer = ConnectionMultiplexer.Connect(options); services.AddSingleton(redisConnectionMultiplexer); Log.Information(\u0026#34;InitRedis success.\u0026#34;); } 发布验证，\n开门放并发 300 + 3000 请求。\n完美抗住，丝一般顺滑。\n还有更优的写法吗？ 看了下微软 Cache 中间件源码，更好的做法应该是通过信号量+异步锁来创建 Redis 链接，下来再研究一下 数据库中可能也存在类似的问题，不过当前会在 Startup 中戳一下数据库连接，应该问题不大。 复盘 程序启动的时候依赖注入容器同步初始化 Redis 可能很慢(几秒甚至更长)的时候，\n其他的资源都在同步等待它初始化好，\n最终导致请求堆积，引起程序雪崩效应。\nRedis 初始化过慢并不每次都发生， 所以之前服务也只是偶发。\nDI 初始化 Redis 连接的时候，redis 打来连接还是个同步的方法，\n这种情况下还可能发生异步请求中等待同步资源产生阻塞问题。\n同时还需要排查使用其他外部资源的时候是否会触发同类问题。\n几个通用的小技巧 ptrace 对此类问题分析很有意义，不同语言框架都有类似的实现\n同步、异步概念的原理和实现都要了解，这个有利于理解一些奇奇怪怪的问题\n火焰图、Chrome dev Performance 、speedscope 都是好东西\nDebug 日志能给更多的信息，在隔离生产的情况下大胆使用\n这辈子都不可能看源码的，写写 CURD 多美丽？源码真香，源码真牛逼。\n控制变量验证，大胆假设，小心求证，人肉二分查，先怀疑自己再怀疑框架\n搞事的时候不要自己一个人，有 Bug 一定要拉上小伙伴一起吃\n相关资料 IBM Developer ptrace 嵌入式系统中进程间通信的监视方法\n分析进程调用 pstack 和 starce\npstack 显示每个进程的栈跟踪\n微软：dotnet-trace performance analysis utility\n知乎：全新 Chrome Devtool Performance 使用指南\nspeedscope A fast, interactive web-based viewer for performance profiles.\njdk 工具之 jstack(Java Stack Trace)\n阮一峰:如何读懂火焰图？\n","date":"2020-06-07T00:00:00Z","permalink":"https://liguobao.github.io/p/%E4%B8%80%E6%AC%A1%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E4%B8%8D%E6%85%8E%E5%BC%95%E5%8F%91%E7%9A%84%E4%B8%80%E8%BF%9E%E4%B8%B2%E4%BA%8B%E6%95%85/","title":"一次依赖注入不慎引发的一连串事故"},{"content":"转载：CodeReview 正确的姿势是什么？ 作者：微博是阿里孤尽 链接：https://www.zhihu.com/question/383079175/answer/1109655276 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\nCodeReview 正确的姿势是什么？ ​\n全文转载于 “微博是阿里孤尽”在上面的回答，已征求本人同意。\n以下是原文：\n最近 CodeReview（以下简称 CR ）心态相当的平和，代码是一个讲道理的东西，是就是，否就否。在 CR 时，沟通特别轻松，问题讨论也特别聚焦，因为它是量化和定向的。\nCR 的过程不是恃强凌弱，也不是一言堂，大家看着代码，当作是一种灵魂的交流，那么每一次的 CR 也是同事间提升和谐度的一种方式。优良的 CR 传统可以体现团队温度，体现高年级同学传帮带的技术文化。平时，大家抬头看 PRD ，低头写代码，很少有时间静心气闲地交流一下业务流程、业务逻辑、业务未来扩展，在 CR 时，往往可以反复被讨论到。\n一个人的能力不是体现在解决了问题上，也不是发现了问题，而是利用某种手段预知问题并解决问题。曾经有段代码，我觉得取反逻辑生涩难懂，反复修改之后，发现写代码的小伙伴是错误领会了业务意图。\n提升技术质量、促进人才成长、培养技术情怀这些口号我们今天先放一边，聊聊最近 CR 的切身体会。CR 不是互相看天书，而是产生天天看书的感觉，每一段写得好，写得不好的代码都是一本书，好的代码希望见贤思齐，差的代码希望见不贤而内自省也。\n总之， CR 是一种修行，也是一种自我积累，苦涩的是看到惨不忍堵的代码，心里说：我去！有意思的是看到优雅的代码，心里也说：我去！\n业务跑得这么快，没时间 Code Review 这是一个很大的谎言，不要为自己的丑代码找华丽的借口，没有时间好好 CR ，总有时间焦头烂额地处理故障和投诉。时间老人是公平的，我一直认为某个同学在工位上噼里啪啦打字，就是说明他干活快，通过团队打字比赛，发现其中 20% 在按 BACKSPACE 键。业务跑得快，代码写得快，可能写的是一堆没有营养甚至是有毒的代码。我们需要追求的是 CR 的效能，而不是逃避 CR 。CR 是一种修行，对于双方都是一样的收获，因为如果想象成一个摊派任务，抵触情绪总会油然而生。业务跑得快，也得两腿是健康的， CR 就是保证业务持续跑的快的一个小医生，不正常的业务节奏对公司的中长远发展肯定是弊大于利。\n代码是讲道理的 我认为靠烧香来保佑代码不出问题时，保平安往往也是暂时的。优秀的代码，就是在小流量、单线程没有问题，在高流量、高并发时还是没有问题，你的限流，你的容灾，你的降级各种导弹防御系统一样自动打开并正确地发挥价值。很多人的思维觉得，代码只要在当前场景和逻辑上没有问题就行，那是因为夜路走得不够多，还没有碰到鬼。代码是讲道理的，就像有一个同学说\u0026gt;=比\u0026gt;更加慢，那只是我们的潜意识猜测，经过深达编译层的分析，发现两个指令几乎是完全一样。其实凭我们的想象，那也是一个位运算级别的操作，从左向右比，如果一处有 1 ，另一个没有 1 ，那么前者一定是更大。没有无缘无故的爱，没有无缘无故的恨，一切的故障总是代码的字里行间。我们需要做的，就是读懂她，用好她，写好她.。如果代码任性闯祸，只能是我们不懂代码的心思。\n每一行代码的存在是有意义的 更加严格地说，每一个字符的存在都应该是有意义的。如果某行代码的存在完全是可有可无的，这个时候，我们考虑过 JVM 的感受吗？凭白无故地要编译这些字节码，然后栈进栈出的忙活一阵子，然后告诉它，你的劳动是没有任何价值的。比如，Boolean assetFlag = Boolean.true ; 这里都已经明确地给给出来显示的初始值，可是在调用端，居然还有这样的判断：if ( assetFlag != null \u0026amp;\u0026amp; assetFlag == true) {\u0026hellip;}，什么情况下为 null 值啊？另外参数在框架里已经做了值的判断，那么下边又是 n 行，对所有参数重新判断一遍，是对我们的代码有多少不自信，还是对框架不自信？每一行的代码，相当于生命，它的存在一定是有意义的，一定是能够被执行到并且能够为实际的业务负责的。\n我们比拼的不是代码行数 在 Code Review 过程中，发现有些方法，重复用到一段逻辑，这段逻辑如果不抽取出来成为一个方法，未来的修改就成了一个必须多点全部修改的大坑，稍有不慎，容易遗漏。重复代码在提交行数上，似乎挺壮观的。如果在同样的效果上， 3 行代码能够实现功能的价值，就不应该用 4 行来实现。我们经常说晒出代码行数，并非是单纯地鼓励代码行数多，而是提倡大家去写代码，写优质的代码，优质的代码一定是少即是多的原则。代码的实现，不要像鲁迅先生说的一样：懒婆娘的裹脚布又臭又长。\n用户视角的成功与失败 在交付时，调用服务失败，然后返回前台一个空列表，那么前端业务的展示是后台数据正常，这个人不拥有数据列表，这明明是对数据的一种曲解。所以，后台调用服务失败，就应该明确告诉前台，服务出错了，这个用户有没有数据。系统出错的信息给用户看，合适吗？不合适。前后端的用户交界面上，往往飞着两类信息：错误码、错误信息。这样够了吗？用户提示需要额外地再给出来，往往根据不同的错误码，有不同的用户提示，可能是一个多对多的关系。多个错误码，提示给用户的信息：请输入必填项。多个用户信息，可能也对应一个错误码。一般来说后台承包这三者的联动关系， json 串推送给前端时，前端拿来主义即可。\n有重复使用的量一定要找个地方集中隔离 不管是变量，还是常量，工具类，如果是多个地方同时用到，那么如果硬编码在代码或者沉淀在包里，未来一定是一个灾难。比如，一个组装 SQL 语句的代码，到处都是 \u0026ldquo;from\u0026rdquo; \u0026ldquo;where\u0026rdquo; \u0026ldquo;limit\u0026rdquo; ，都是这类语句直接写死在代码中，注意问题来了，这些单词前后都需要加空格。有时候在复制粘粘时，发现少了一个空格，出现的问题，往往是致命的。再比如，一个互相约定的分隔符 “###” ，定义在本类中 private String ，这明显是两个共同遵守的常量，单独定义的结果就是容易造成不匹配。隔离的目的是复用它，保护程序地正常运行，易于维护。\n单测没必要代码 Code Review 单测有时候感觉像是阑尾，有或没有感觉都是无关紧急，这是错误的观点。单测感觉就是一个任务。你写单测了吗？写了。单测是否需要 MOCK ，是否进行边界值测试，是否用例覆盖到业务场景，这都也是 CR 的一部分。单测写得好， BUG 肯定少。\n需要调试来查找错误时，往往是一种对异常处理机制的侮辱 良好的日志和异常机制，是不应该出现调试的。打日志和抛异常，一定要把上下文给出来，否则，等于在破坏命案现场，把后边处理问题的人，往歪路上带。别人传一个参数进来，发现是 null ，立马抛出来一个参数异常提示，然后也不返回哪一个参数是 null ，这在调用参数很多的情况下，简直就是字谜游戏一样。到底是抛异常，还是抛错误码？我不管抛什么，反正错了什么东西，都应该透明出来。到底是抛受检异常，还是非受检异常，我只想说，没有充足的理由，不要乱抛受检异常。异常抛出时，一定要自己消化干净，告诉别人说我的方法签名抛的是 AbcException ，实际运行中，代码某个地方直接抛出 EfgException ，这也是不负责任的。\n多个 return 的语句，概率高的一定先进行判定 if(condition1) return; if(condition2) return; if(condition3) return ; 那么需要评估一下 condition1/2/3 出现概率的大小，概念大的在最前边，尽可能快地进行 return ，不需要进行后续无谓的匹配。不要总觉得计算机跑得快，不差这点蝇头小利的，这种思维，和《南辕北辙》里的寓义一样的吗？\n吝啬空行 感觉空行是廉价的，到处乱扔是一种；另一种是感觉空行是昂贵的，舍不得用，这种情况更多见。50 行代码没有一个空行，就像英语 50 句话，没有任何标点符号一样。既然标点符号起到隔断和语义区分作用，我们的空行不是同一个道理吗？在以下情形： 1、在方法的 return、break、continue、这样断开性语句后必须是空行。 2、在不同语义块之间。 3、循环之前和之后一般有空行。另外，方法和类定义下方就不需要空行了吧。\n命名太随意 代码有两件事情比较头疼：命名和循环。人如其名，如果不是它干的活，名字却是一副道貌岸然，太容易把人带偏了，一个中国人如果取名叫赵 C，一个女孩子如果取名叫石敢当，第一印象生生地给扭曲了。英语不好的同学，要么用错英文单词，要么翻词典，整出一个专八的词汇，任何人都不认得这个单词，在 CR 时，还需要打开在线翻译时的命名，绝对不是好命名。当然如果在线翻译都翻不出来的时候，那更头疼。如果表意错误，那更要命。\n注释是电影的旁白 电影的旁白：1）信息量大。2）适时出现。就像 star war 里，开始的一段一样，如果不交代那些背景，可能进入正片是一脸懵逼的。在代码上不需要写正确的废话，名字取得好，自然是自解释的。在嵌套循环中，或者在复杂条件分支中，往往是需要讲明白的。另外，添加业务背景信息，以及执行频率，执行条件，甚至维护者注意点，都是注释的重要理由。识别到哪里要写注释，也是一个对业务的阅读能力，而不是代码阅读能力。\n满天飞的函数式编程好吗？ 不好。如果一个 stream 后边的调用超过 5 个，我觉得你是为了炫耀，因为别人不敢改这段代码，体现出来你的不可替代性。这种 10 行都是函数式编程的方式，就像让人在水里憋气超过 10 分钟不能换气一样难受，有点缺氧的感觉。\n我们团队有一个优秀的 CR 习惯，\n如果加入我们，请扫码： ​ alibaba.tupu360.com\n以下是我自己的回答，也贴一下。 在我这里，\n每一次 CodeReview 都是对自己和其他人的“精神”审问。\n首先，确立原则“对事不对人”，\n同理，对代码不对人。\n用前阵子给某实习生 Review 的时候的评论举例吧。\n样例一：接口返回值不符合约定的规范\nReview 这个时候一般就说明一下具体的情况和建议。\n同时我也鼓励对方能有其他的意见或者说法加入讨论。\n样例二：语言特性下的某个基础用法可能存疑。\n这种情况下，\n一般我会提出疑问，\n期待得到一个完备的答案。\n样例三：实现逻辑不太合理、优雅\n直接指明有更好的做法，\n可以试试另一种思路。\n如果对方有其他的思量，\n非常欢迎。\n样例四：某些场景下中断整个程序的实现\n由某个不好的实现，\n引出一些思考和讨论。\nPS：\n以上 Review 有自己的适用场景，\n别追问，\n再问就是我菜。\n所以，\n在我看来，\nCodeReview 的正确姿势是：\n对事不对人，\n对思维方式不只对代码，\n对场景适宜不对鸡蛋挑骨头。\n最后，\n尽量让团队和人都达到:\n高效输出 + 优雅实践 + 按时下班 + 轻松从容应对复杂的世界。\n以上。\n谢谢。\n","date":"2020-04-05T00:00:00Z","permalink":"https://liguobao.github.io/p/%E8%BD%AC%E8%BD%BDcodereview%E6%AD%A3%E7%A1%AE%E7%9A%84%E5%A7%BF%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88/","title":"转载：CodeReview正确的姿势是什么？"},{"content":"客官来玩K8S之搭个Gitlab 前言 不需要前言.\n本次教程中包含的知识点 需要的知识点\nk8s基础, Pod/Service 相关知识\nk8s存储, PV/PVC/StorageClass 相关知识\nnginx基础\nGitlab CE 依赖的服务 postgreSQL\nredis\n2G 以上内存, 最好 4G(2G 内存不如 dog)\n当然, 以上服务一样用 K8S 部署.\npostgreSQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: run: postgresql name: postgresql spec: progressDeadlineSeconds: 600 replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: run: postgresql strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: creationTimestamp: null labels: run: postgresql spec: containers: - env: - name: POSTGRES_DB value: gitlab - name: POSTGRES_USER value: gitlab - name: POSTGRESQL_PASSWORD value: 随便写你的密码 - name: PGDATA value: /var/lib/postgresql/data/pgdata image: postgres:10 imagePullPolicy: IfNotPresent name: postgresql imagePullPolicy: IfNotPresent ports: - containerPort: 5432 protocol: TCP resources: limits: cpu: 500m memory: 1024Mi requests: cpu: 200m memory: 256Mi terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/lib/postgresql/data/ name: es-data subPath: postgresql dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 # 这里是k8s的pvc, 我这里pvc叫es-data, 和elastic用同一个磁盘 volumes: - name: es-data persistentVolumeClaim: claimName: es-data --- apiVersion: v1 kind: Service metadata: # 这个annotations是腾讯云申请内网IP的配置, 需要改成自己k8s所在网络的子网id # postgresql 这里其实可以不要内网service ip, 内网直接用service name访问即可 annotations: service.kubernetes.io/loadbalance-id: lb-你自己的loadbalanceid service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-你自己的子网id labels: run: postgresql name: postgresql spec: externalTrafficPolicy: Cluster ports: - port: 3433 protocol: TCP targetPort: 5432 selector: run: postgresql sessionAffinity: None type: LoadBalancer 这里面用的 PV/PVC 需要自己在腾讯云里面创建, 基本就是点点点就能创建出来了.\nredis 部署 跳过\u0026hellip;\n随便抄一下 k8s 部署 Redis 教程就完事了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 apiVersion: apps/v1 kind: StatefulSet metadata: generation: 2 labels: app: redis name: redis spec: podManagementPolicy: OrderedReady replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: app: redis serviceName: redis template: metadata: creationTimestamp: null labels: app: redis spec: containers: - env: - name: REDIS_PASSWORD value: 换成你的密码 image: bitnami/redis:5.0 imagePullPolicy: IfNotPresent name: redis resources: limits: cpu: 500m memory: 256Mi requests: cpu: 200m memory: 128Mi terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /bitnami/redis/data name: redis-data subPath: redis dnsPolicy: ClusterFirst imagePullSecrets: - name: regsecret nodeSelector: tuiwen-tech.com/phase: test restartPolicy: Always schedulerName: default-scheduler securityContext: runAsUser: 0 terminationGracePeriodSeconds: 30 updateStrategy: rollingUpdate: partition: 0 type: RollingUpdate volumeClaimTemplates: - metadata: creationTimestamp: null name: redis-data spec: accessModes: - ReadWriteOnce dataSource: null resources: requests: storage: 10Gi storageClassName: 换成你的storageClassName --- apiVersion: v1 kind: Service metadata: labels: app: redis name: redis spec: externalTrafficPolicy: Cluster ports: - name: headless nodePort: 31966 port: 6379 protocol: TCP targetPort: 6379 selector: app: redis sessionAffinity: None type: LoadBalancer Gitlab CE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: app: gitlab name: gitlab spec: replicas: 1 strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 0 template: metadata: labels: app: gitlab spec: containers: - env: - name: GITLAB_OMNIBUS_CONFIG value: | # external_url 这里要注意, 要不改成你的公网IP, 要不改成nginx暴露到外面的域名+端口 或者域名+二级目录 external_url \u0026#39;换成你自己的\u0026#39; # Disable the built-in Postgres postgresql[\u0026#39;enable\u0026#39;] = false # Fill in the connection details for database.yml gitlab_rails[\u0026#39;db_adapter\u0026#39;] = \u0026#39;postgresql\u0026#39; gitlab_rails[\u0026#39;db_encoding\u0026#39;] = \u0026#39;utf8\u0026#39; gitlab_rails[\u0026#39;db_host\u0026#39;] = \u0026#39;postgresql\u0026#39; gitlab_rails[\u0026#39;db_port\u0026#39;] = 3433 gitlab_rails[\u0026#39;db_database\u0026#39;] = \u0026#34;gitlab\u0026#34; gitlab_rails[\u0026#39;db_username\u0026#39;] = \u0026#39;gitlab\u0026#39; gitlab_rails[\u0026#39;db_password\u0026#39;] = \u0026#39;换成你自己的\u0026#39; # mail config gitlab_rails[\u0026#39;smtp_enable\u0026#39;] = true gitlab_rails[\u0026#39;smtp_address\u0026#39;] = \u0026#34;换成你自己的\u0026#34; gitlab_rails[\u0026#39;smtp_port\u0026#39;] = 465 gitlab_rails[\u0026#39;smtp_user_name\u0026#39;] = \u0026#34;换成你自己的\u0026#34; gitlab_rails[\u0026#39;smtp_password\u0026#39;] = \u0026#34;换成你自己的\u0026#34; gitlab_rails[\u0026#39;smtp_domain\u0026#39;] = \u0026#34;换成你自己的\u0026#34; gitlab_rails[\u0026#39;smtp_authentication\u0026#39;] = \u0026#34;login\u0026#34; gitlab_rails[\u0026#39;smtp_enable_starttls_auto\u0026#39;] = true gitlab_rails[\u0026#39;smtp_tls\u0026#39;] = true # 这个很重要，而且是官方文档里没提及的 # If your SMTP server does not like the default \u0026#39;From: [email protected]ocalhost\u0026#39; you # # can change the \u0026#39;From\u0026#39; with this setting. gitlab_rails[\u0026#39;gitlab_email_from\u0026#39;] = \u0026#39;完整邮件账户\u0026#39; # Disable the built-in Redis redis[\u0026#39;enable\u0026#39;] = true # Add any other gitlab.rb configuration here, each on its own line # Redis via TCP gitlab_rails[\u0026#39;redis_host\u0026#39;] = \u0026#39;redis\u0026#39; gitlab_rails[\u0026#39;redis_port\u0026#39;] = 6379 gitlab_rails[\u0026#39;redis_password\u0026#39;] = \u0026#39;换成你自己的\u0026#39; image: gitlab/gitlab-ce:11.11.7-ce.0 name: gitlab resources: requests: memory: \u0026#34;1Gi\u0026#34; cpu: \u0026#34;300m\u0026#34; limits: memory: \u0026#34;3Gi\u0026#34; cpu: \u0026#34;1000m\u0026#34; ports: - containerPort: 443 - containerPort: 80 - containerPort: 22 volumeMounts: - mountPath: /etc/gitlab name: es-data subPath: gitlab - mountPath: /var/opt/gitlab/git-data name: es-data subPath: gitlab restartPolicy: Always serviceAccount: gitlab serviceAccountName: gitlab volumes: - name: es-data persistentVolumeClaim: claimName: es-data --- apiVersion: v1 kind: Service metadata: annotations: service.kubernetes.io/loadbalance-id: 换成你自己的 service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: 换成你自己的 labels: app: gitlab name: gitlab spec: ports: - name: git-ssl port: 443 targetPort: 443 - name: git-http port: 80 targetPort: 80 selector: app: gitlab type: LoadBalancer --- apiVersion: v1 kind: Service metadata: annotations: service.kubernetes.io/loadbalance-id: 换成你自己的 service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: 换成你自己的 labels: app: gitlab name: gitlab-ssh spec: ports: - name: git-ssh port: 22 targetPort: 22 selector: app: gitlab type: LoadBalancer 理论上来说, 只需要等待启动就完事了..\n最后是暴露到外部的 NGINX 配置 如果直接使用 k8s ingress 拿到公网 IP 的话, 就不用自己配置 NGINX 转发了.\n如果和我一样需要自己用 Nginx 提供外部访问的话, 参考下面.\n1 2 3 4 5 location /app/git { proxy_pass http://可达的内网IP(就是k8s service的内网IP):80; client_max_body_size 50m; } 教程完毕.\n","date":"2019-08-31T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%AE%A2%E5%AE%98%E6%9D%A5%E7%8E%A9k8s%E4%B9%8B%E6%90%AD%E4%B8%AAgitlab/","title":"客官来玩K8S之搭个Gitlab"},{"content":"你不可能搞不定腾讯云K8S的Service/Ingress 前言 上一个手把手教程上简单介绍过k8s中的Pod/Service,\n里面提到过Service是K8S中的负载均衡, 同时也可以在不同Pod中使用Service name互相访问.\n如果我们在外部(公网)访问K8S的服务怎么办呢?\n首先, 你的有个公网IP.\n然后\u0026hellip;.关掉这个教程.\n回到正文.\n在k8s中, ingress来负责对外提供访问, 一般域名配置, 域名证书都在这边.\n是不是有点熟悉? 这不就是NGINX?\n对的, 甚至ingress的实现就有一部分是NGINX.\n但是, 大家都知道, 公网IP这种东西, 可是要收费的.\n腾讯云的收费标准: 应用型负载均衡器（支持HTTP/HTTPS）0.02元/小时\n有钱的同学直接用就好了,\n教程见腾讯云集群管理, 点点点就好了.\n穷人不配用公网? 不, 我们有自己的倔强! 想下, 我们在做k8s集群的时候, 用的主机不是本来就带公网IP吗?\n虽然现在主机已经是k8s的worker节点了, 不过机器还是可以继续用的呀.\n所以, 我们的方案是,\n主机上装个NGINX, 由NGINX用端口转发的方式转到内部K8S Service中 ,\n这样就完美了.\n这样的话, 那么我们的主机怎么访问k8s Service呢?\n在前面我们简单提过, k8s的pod,service都是在自己的内网的.\n虽然现在主机和k8s的服务可能都在一个主机上, 然而里面还是有逻辑层内网隔离的.\n那么, 这样怎么办呢?\n放心, k8s service早就有解决方案啦.\n答案是:\n在腾讯云中的使用service.kubernetes.io/qcloud-loadbalancer-internal-subnetid annotations来申请内网IP.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 --- apiVersion: v1 kind: Service metadata: # 这个annotations是腾讯云申请内网IP的配置, 需要改成自己k8s所在网络的子网id # postgresql 这里其实可以不要内网service ip, 内网直接用service name访问即可 annotations: service.kubernetes.io/loadbalance-id: lb-你自己的loadbalanceid service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-你自己的子网id name: codelover-blog namespace: default spec: externalTrafficPolicy: Cluster ports: - nodePort: 32278 port: 80 protocol: TCP targetPort: 80 selector: run: codelover-blog sessionAffinity: None type: LoadBalancer 查看一下配置的效果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ➜ codelover-blog git:(master) ✗ kc get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE codelover-blog LoadBalancer 172.16.255.232 172.17.0.28 80:32278/TCP 55d root@VM-0-13-ubuntu:~# curl -vvvv 172.17.0.28 * Rebuilt URL to: 172.17.0.28/ * Trying 172.17.0.28... * Connected to 172.17.0.28 (172.17.0.28) port 80 (#0) \u0026gt; GET / HTTP/1.1 \u0026gt; Host: 172.17.0.28 \u0026gt; User-Agent: curl/7.47.0 \u0026gt; Accept: */* \u0026gt; \u0026lt; HTTP/1.1 200 OK \u0026lt; Server: nginx/1.17.1 \u0026lt; Date: Sun, 01 Sep 2019 05:30:51 GMT \u0026lt; Content-Type: text/html \u0026lt; Content-Length: 45988 \u0026lt; Last-Modified: Mon, 08 Jul 2019 03:59:21 GMT \u0026lt; Connection: keep-alive \u0026lt; ETag: \u0026#34;5d22bf99-b3a4\u0026#34; \u0026lt; Accept-Ranges: bytes \u0026lt; \u0026lt;!DOCTYPE html\u0026gt; 现在内网IP有了, 下面也就是配置一下NGINX的事情了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 server { listen 80; server_name 你的域名; location / { proxy_pass http://172.17.0.28:80; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; gzip on; gzip_min_length 5k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 3; gzip_types text/plain application/json application/javascript text/css application/xml text/javascript image/jpeg image/gif image/png; gzip_vary on; } 好了, 完事.\n","date":"2019-08-31T00:00:00Z","permalink":"https://liguobao.github.io/p/%E4%BD%A0%E4%B8%8D%E5%8F%AF%E8%83%BD%E6%90%9E%E4%B8%8D%E5%AE%9A%E8%85%BE%E8%AE%AF%E4%BA%91k8s%E7%9A%84service/ingress/","title":"你不可能搞不定腾讯云K8S的Service/Ingress"},{"content":".NET Core乱糊代码之\u0026quot;异步调差性能\u0026quot;指北 前言 故事要从好久之前说起,线上某服务从零到上线都是我撸的, 架构主要是.NET Core API + EF, 从最早的日活一千到现在日活几万.\n平时在线人数几百, 高峰上千, 靠着6-8个Docker实例基本撑住了, 请求量来说QPS在100左右. 平摊下来其实每个实例的并发量不算太高.\n但是某个迭代开始发现,\n这个Web API有一定几率在启动的时候接收到大量请求后堆积起来, 看日志显示请求进来了, 但是一直没有到逻辑代码或者数据库查询,\n所有的请求看起来都是在等调度.\n已知信息 出现场景大多是刚启动的时候大量请求进来, 可能会把实例打崩\n偶尔有场景是突然涌进大量用户, 也可能把实例打崩\n发生问题时实例CPU占用率和内存都很正常, 整个宿主机运转正常, 也没有大量IO读写操作, 基本排除外部因素\n网络情况正常, 内网中没有奇怪的数据请求,不存在网络风暴之类的东西\n发生问题前此时数据库连接数正常, 实例不断被重启后或者一直僵死中, 数据库连接数会不断增加, 也有一定几率会把数据库连接数撑爆.\n开始\u0026quot;侦查模式\u0026quot; 猜想一, 数据库搞事了? 最早怀疑是数据库连接的问题.\n总所周知EF首次启动特别慢, 如果一开始查询比较多进来, 直接落到数据库查询.\n每个EF实例初始化都需要耗费一定时间, 这样势必是会影响整个性能的.\n这种情况下, 如果可以对EF DB Pool做一次预热是不是会好一些呢?\n所以曾经在Startup.cs下面写过类似的预热代码.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private static void InitDataContextService(IApplicationBuilder app) { Console.WriteLine($\u0026#34;InitDataContextService start,now:{DateTime.Now.ToString()}\u0026#34;); var tasks = new List\u0026lt;Task\u0026gt;(); for (var i = 0; i \u0026lt;= 10; i++) { var serviceScope = app.ApplicationServices.CreateScope(); var context = serviceScope.ServiceProvider.GetRequiredService\u0026lt;XXXContext\u0026gt;(); var t = context.Database.CanConnectAsync(); tasks.Add(t); } Task.WaitAll(tasks.ToArray()); Console.WriteLine($\u0026#34;InitDataContextService finish,now:{DateTime.Now.ToString()}\u0026#34;); } 用Task异步的方式来控制每次尽量产生不同的实例, 已达到预热数据量连接池的效果.\n是不是很机智啊? (P, 然而并没有半毛钱的效果)\n猜想二, 同步请求等待资源导致性能变差, 启动的时候被打崩? 最早版本所有的Controller Action 都是同步请求, 来一个请求同步查询数据, 执行HTTP请求等等都是正常的逻辑代码.\n从来不用async/awati之类的东西.(就是这么懒)\n既然出事了, 改一版看看.\n开始锵锵锵改Controller Action, 改成Task的形式.\n基本代码\n1 2 3 4 5 6 7 8 [HttpGet(\u0026#34;v1/books/{id}\u0026#34;, Name = \u0026#34;GetBook\u0026#34;)] [SwaggerResponse(200, \u0026#34;获取成功\u0026#34;, typeof(BookDetail))] [SwaggerResponse(404, \u0026#34;找不到书籍\u0026#34;)] public async Task\u0026lt;IActionResult\u0026gt; GetBook([FromRoute]string id) { return Ok(new { data = await _bookService.FindBookDetailForUser(id), code = 0 }); } service层的用到的方法同时也改造成异步, 从头到尾都是异步.\n这样测下来, 性能比同步大概涨了30%-50%左右(瞎测的, 也不太记得了数值了,没有参考意义)\n就这样又上了一个版本, 比再前面几个版本都好点了, 现在发生打崩的情况降低了很多.\n玄学现场:又做了一些奇怪的事情 后来又发现, 每次启动的时候, 在正式流量打入之前, 尽量预热一下api实例的话, 被直接打崩的几率会变低,\n整体api会比较正常启动.\n至少算是一个能操作的事情, 这个时候就很傻了, 每次发布的时候都手动ab test一下还没有转入流量的实例,\n尽可能预热一下数据库和这个HTTP管道.\n这个时候真的是玄学现场, 太让我沮丧了.\n墨菲定律总是会来的 前天晚上发布新版本, 预发布环境政策, 性能正常之后推到生产, 然后全线告警.\n神奇了, 现在又见鬼了.\n用上面的压测预热折腾了一个小时, 没有成功全部启动应用, 最后无奈先回滚了, 回滚后服务正常.\nOK, 这个迭代的代码加剧了应用被打崩的情况.\n现总结一下当前情况\n这次上线前, 数据库已经升级了配置, 整体监控上数据库没有任何的瓶颈\n没有大的逻辑变动, 老的核心接口基本都异步改造完成, 新接口基本都是异步的\n不存在缓存穿透问题, Redis缓存命中正常.\n这次发布最大变更是IP定位, 需要处理headers中的IP数据,\n使用ActionFilterAttribute在请求进入Action方法前完成IP到地区的转换.\n这里主要会用到Redis和MaxMind.Db, 优先从Redis查询IP地区缓存, 没有命中则直接查询MaxMind.Db数据, 查询好之后再写入到Redis中.\n代码大概是这样的.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public class HTTPHeaderAttribute : ActionFilterAttribute { private readonly HTTPHeaderTools _httpHeaderTools; private readonly MaxMindDBClient _maxMindDBClient; private readonly RedisService _redisService; public HTTPHeaderAttribute(HTTPHeaderTools httpHeaderTools, MaxMindDBClient maxMindDBClient, RedisService redisService) { _httpHeaderTools = httpHeaderTools; _maxMindDBClient = maxMindDBClient; _redisService = redisService; } public override void OnActionExecuting(ActionExecutingContext context) { var dicXHeaders = new Dictionary\u0026lt;string, string\u0026gt;(); string locationISOCode = GetLocationISOCode(context); dicXHeaders.Add(CommonConst.LocationHeaderKey, locationISOCode); _httpHeaderTools.CurrentXHeaders = new ThreadLocal\u0026lt;Dictionary\u0026lt;string, string\u0026gt;\u0026gt;(() =\u0026gt; dicXHeaders); } private string GetLocationISOCode(ActionExecutingContext context) { string requestIP = context.HttpContext.Request.Headers.GetHeaderValue(\u0026#34;X-Forwarded-For\u0026#34;); if(requestIP.Contains(\u0026#34;,\u0026#34;)) { requestIP = requestIP.Split(\u0026#34;,\u0026#34;)[0]; } var locationISOCode = _redisService.ReadHashValueByKey\u0026lt;string\u0026gt;(ConstRedisKey.IPLocations, requestIP); if (string.IsNullOrEmpty(locationISOCode)) { locationISOCode = _maxMindDBClient.GetIPLocationISOCode(requestIP); _redisService.WriteHash(ConstRedisKey.IPLocations, requestIP, locationISOCode); } return locationISOCode; } } 代码先扔着, 看起来没什么特别的地方.\n好了, 我要睡了明天继续\u0026hellip;\n等我睡醒了再继续..\n先直接甩真正解决问题的的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 public class HTTPHeaderAttribute : ActionFilterAttribute { private readonly HTTPHeaderTools _httpHeaderTools; private readonly MaxMindDBClient _maxMindDBClient; private readonly RedisService _redisService; public HTTPHeaderAttribute(HTTPHeaderTools httpHeaderTools, MaxMindDBClient maxMindDBClient, RedisService redisService) { _httpHeaderTools = httpHeaderTools; _maxMindDBClient = maxMindDBClient; _redisService = redisService; } public override async Task OnActionExecutionAsync(ActionExecutingContext context, ActionExecutionDelegate next) { var dicXHeaders = new Dictionary\u0026lt;string, string\u0026gt;(); string locationISOCode = await GetLocationISOCode(context); dicXHeaders.Add(CommonConst.LocationHeaderKey, locationISOCode); _httpHeaderTools.CurrentXHeaders = new ThreadLocal\u0026lt;Dictionary\u0026lt;string, string\u0026gt;\u0026gt;(() =\u0026gt; dicXHeaders); await next(); } private async Task\u0026lt;string\u0026gt; GetLocationISOCode(ActionExecutingContext context) { string requestIP = context.HttpContext.Request.Headers.GetHeaderValue(\u0026#34;X-Forwarded-For\u0026#34;); if (requestIP.Contains(\u0026#34;,\u0026#34;)) { requestIP = requestIP.Split(\u0026#34;,\u0026#34;)[0]; } if (string.IsNullOrEmpty(requestIP)) { return CommonConst.ChinaISOCode; } var locationISOCode = await _redisService.ReadHashValueByKeyAsync(ConstRedisKey.IPLocations, requestIP); if (string.IsNullOrEmpty(locationISOCode)) { locationISOCode = _maxMindDBClient.GetIPLocationISOCode(requestIP); _redisService.WriteHash(ConstRedisKey.IPLocations, requestIP, locationISOCode); } return locationISOCode; } } 先睡觉了, 有想法的朋友欢迎评论打架\u0026hellip;\n","date":"2019-08-03T00:00:00Z","permalink":"https://liguobao.github.io/p/.net-core%E4%B9%B1%E7%B3%8A%E4%BB%A3%E7%A0%81%E4%B9%8B%E5%BC%82%E6%AD%A5%E8%B0%83%E5%B7%AE%E6%80%A7%E8%83%BD%E6%8C%87%E5%8C%97/","title":".NET Core乱糊代码之\"异步调差性能\"指北"},{"content":".NET Core Web API Swagger 文档生成 REST API 中文档说明,用Swagger都快成了一种规范了,\n之前在公司里面就折腾过了, 效果还是很不错的, 不过之前都是维护一个swagger json/yaml,\n后来发现其实可以直接在API实现的地方根据实现来生成swagger在线文档,\n拖延症发作的我并没有去管, 这次有个新API在做, 于是折腾了一下.\n起步 首先要有个.NET Core项目.\n微软官方教程getting-started-with-swashbuckle\nGithub/Swashbuckle.AspNetCore\n引入一下Swashbuckle.AspNetCore和Swashbuckle.AspNetCore.Annotations 1 2 3 4 5 6 # 主要的文档生成都在这里 dotnet add package Swashbuckle.AspNetCore --version 4.0.1 # 用来描述请求的相关信息 dotnet add package Swashbuckle.AspNetCore.Annotations --version 4.0.1 代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Zhihu404API.Dao; using Microsoft.AspNetCore.Builder; using Microsoft.AspNetCore.Hosting; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.Configuration; using Microsoft.Extensions.DependencyInjection; using Microsoft.EntityFrameworkCore; using Swashbuckle.AspNetCore.Swagger; namespace XX404API { public class Startup { public Startup(IConfiguration configuration) { Configuration = configuration; } public IConfiguration Configuration { get; } // This method gets called by the runtime. Use this method to add services to the container. public void ConfigureServices(IServiceCollection services) { services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_2); services.AddOptions().Configure\u0026lt;AppSettings\u0026gt;(Configuration); services.AddSwaggerGen(c =\u0026gt; { c.SwaggerDoc(\u0026#34;v1\u0026#34;, new Info { Title = \u0026#34;XX-404 API\u0026#34;, Version = \u0026#34;v1\u0026#34; }); c.EnableAnnotations(); }); } // This method gets called by the runtime. Use this method to configure the HTTP request pipeline. public void Configure(IApplicationBuilder app, IHostingEnvironment env) { // 启用Swagger app.UseSwagger(); // 启动Swagger UI app.UseSwaggerUI(c =\u0026gt; { c.RoutePrefix = \u0026#34;docs\u0026#34;; c.SwaggerEndpoint(\u0026#34;/swagger/v1/swagger.json\u0026#34;, \u0026#34;Zhihu-404 API\u0026#34;); }); app.UseMvc(); } } } 然后随便扔两个Controller代码出来作为样例看看.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // HealthController.cs using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Microsoft.AspNetCore.Mvc; namespace XX404API.Controllers { [Route(\u0026#34;api/v1/health\u0026#34;)] [ApiController] public class HealthController : ControllerBase { // GET api/values [HttpGet] public ActionResult\u0026lt;IEnumerable\u0026lt;string\u0026gt;\u0026gt; Get() { return new string[] { \u0026#34;value1\u0026#34;, \u0026#34;value2\u0026#34; }; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // HealthController.cs using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Microsoft.AspNetCore.Mvc; using Microsoft.EntityFrameworkCore; using Swashbuckle.AspNetCore.Annotations; using Newtonsoft.Json.Linq; using RestSharp; namespace XX404API.Controllers { [ApiController] public class ExtendDataController : ControllerBase { public ExtendDataController() { } [HttpPost(\u0026#34;api/v1/extend-data\u0026#34;)] // 返回值格式会直接序列化这个typeof的类型 [SwaggerResponse(200, \u0026#34;\u0026#34;, typeof(int))] // SwaggerParameter会生成请求体的格式 public ActionResult AddExtendData([FromBody, SwaggerParameter(\u0026#34;原始数据\u0026#34;)]List\u0026lt;DBExtendData\u0026gt; extendData) { if(extendData ==null || extendData.Any(a =\u0026gt;a.Id == default(long))) { throw new Exception(\u0026#34;传入数据有误, 请检查每一项数据Id\u0026#34;); } var count = 10;// _extendDataDapper.BulkInsert(extendData); return Ok(new { code = 0, data = count }); } } class DBExtendData { [Column(\u0026#34;id\u0026#34;)] [JsonProperty(PropertyName = \u0026#34;id\u0026#34;)] public long Id { get; set; } [Column(\u0026#34;create_time\u0026#34;)] [JsonProperty(PropertyName = \u0026#34;createTime\u0026#34;)] public DateTime? CreateTime { get; set; } [Column(\u0026#34;update_time\u0026#34;)] [JsonProperty(PropertyName = \u0026#34;updateTime\u0026#34;)] public DateTime? UpdateTime { get; set; } = DateTime.Now; } } 然后访问 localhost:5000/docs 就能看到下面的文档了.\n好了, 全文完.\n我去做饭了\u0026hellip;\n","date":"2019-07-06T00:00:00Z","permalink":"https://liguobao.github.io/p/.net-core-web-api-swagger-%E6%96%87%E6%A1%A3%E7%94%9F%E6%88%90/","title":".NET Core Web API Swagger 文档生成"},{"content":"反手来个K8S入门到跑路 前言 放假前一两天发现腾讯云托管K8S集群上线好一阵子了, 还支持把原有主机迁入k8s集群, 索性开始搞事了.\n先简单科普一下, 什么是k8s?\nk8s 科普时间 Kubernetes (K8s) is an open-source system for automating deployment, scaling, and management of containerized applications. It groups containers that make up an application into logical units for easy management and discovery. Kubernetes builds upon 15 years of experience of running production workloads at Google, combined with best-of-breed ideas and practices from the community. 来自:https://kubernetes.io/\n1 2 3 4 5 6 7 8 9 Kubernetes是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。 Kubernetes一个核心的特点就是能够自主的管理容器来保证云平台中的容器按照用户的期望状态运行着（比如用户想让apache一直运行，用户不需要关心怎么去做，Kubernetes会自动去监控，然后去重启，新建. 总之，让apache一直提供服务），管理员可以加载一个微型服务，让规划器来找到合适的位置. 同时，Kubernetes也系统提升工具以及人性化方面，让用户能够方便的部署自己的应用（就像canary deployments）。 -- [https://www.kubernetes.org.cn/k8s](https://www.kubernetes.org.cn/k8s) 用人话来说, 首先我们以前已经把所有的服务(server/api)都Docker容器化了,\nk8s就是一套用来做容器服务管理/编排的系统.\n那么我们现在开始吧.\n神说, 要有k8s. 初始化自己的腾讯云/阿里云k8s 容器服务 登录一下自己的某云平台, 找一下\u0026quot;容器服务\u0026quot;, 新建集群, 选\u0026quot;托管集群\u0026quot;, 点点点之后完成配置.\n然后把自己已有的机器加入到上面的集群里面去, 基本也是在界面上点点点就好.\n简单科普一下k8s里面对于机器的定义 一个机器在k8s是一个节点,节点分成两种类型,\n一类是master节点, 跑着一堆k8s核心服务(etcd之类的, 具体的自己去了解吧);\n一类是worker节点,用于跑我们自己的业务服务(如,某个爬虫)\n一般情况下, 我们把服务扔给k8s运行起来的时候, 实际上都是在worker节点上起一个Docker容器实例 + 相关的配置.\n这边云平台的托管集群就是master节点我们不管了, 云平台负责好, 需要的机器和配置都给他们搞;\n我们把自己的已经买过的机器或者新买的机器加入到集群里面, 自己用就完事了.\n所以\u0026hellip;.\n我又来搞事了.\n神说, 让我们要开始了 等下, 上面点完了, 先把本地的kubectl搞掂.\n哈? 什么是kubectl.\n哦, 管理k8s的命令行工具.\n没有图形界面吗?\n有, 不过某云做的很难用, 原生的凑合能看, 便于理解概念的情况下, 还是先用ctl搞起吧.\n安装教程: 通过 Kubectl 连接集群\n假装到这里应该都弄好了.\n1 2 3 4 ## 输入kubectl version 查看客户端和服务端版本信息, 能正常输出信息证明都work了 ➜ codelover-blog git:(master) ✗ kubectl version Client Version: version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;11\u0026#34;, GitVersion:\u0026#34;v1.11.1\u0026#34;, GitCommit:\u0026#34;b1b29978270dc22fecc592ac55d903350454310a\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2018-07-18T11:37:06Z\u0026#34;, GoVersion:\u0026#34;go1.10.3\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;darwin/amd64\u0026#34;} Server Version: version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;12+\u0026#34;, GitVersion:\u0026#34;v1.12.4-tke.1.1\u0026#34;, GitCommit:\u0026#34;900490ac7b7ae6a13aa6599d43258f1164e9c458\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2019-01-30T10:22:33Z\u0026#34;, GoVersion:\u0026#34;go1.10.4\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} 又到概念时间 Pod/Service Kubernetes Pod概述\nKubernetes Services概述\n用人话来说,\nPod就是一堆app(一个/多个Docker容器实例)的集合;\nService就是在k8s内网坏境\u0026quot;对外\u0026quot;提供服务的一个实体;\n我们直接在举个栗子来说明一下.\n一个支持水平扩展的Web API服务, 我们为了高可用需要给它部署了三个实例, 这里就是一个Pod, 由三个实例组成\n\u0026ldquo;对外\u0026rdquo;(其他服务或者app需要访问它)来说, 我们需要直接访问它但是有没必要知道它有几个实例, 这个时候就有一个Service来承载它, Service负责把请求直接转发到Pod中, Pod里面有多少实例对Service和对调用者来说都是透明的.\n所以我们来部署我们的第一套服务吧.\n神说, 要开始入门了! 将下面的文件保存成sample.yaml, 然后执行 \u0026ldquo;kubectl apply -f sample.yaml\u0026rdquo;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 --- apiVersion: extensions/v1beta1 kind: Deployment metadata: # 给pod打上标签, 定义service 需要用 labels: run: first-web-size name: first-web-size spec: # 实例个数 replicas: 2 selector: matchLabels: run: first-web-size strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate template: metadata: creationTimestamp: null labels: run: first-web-size spec: containers: # 微软 dotnet core 样例镜像 - image: mcr.microsoft.com/dotnet/core/samples:aspnetapp imagePullPolicy: IfNotPresent name: first-web-size terminationMessagePath: /dev/termination-log livenessProbe: httpGet: path: /v1/health port: 80 initialDelaySeconds: 120 periodSeconds: 30 # CPU + 内存限制 resources: # 最高使用500m的CPU, 超过就限制CPU;最高用512M内存, 超过就炸应用 limits: cpu: 500m memory: 512Mi # 要求给50m的CPU调度和128M内存才可以启动 requests: cpu: 50m memory: 128Mi # 这里是私有镜像仓库需要自己配置的一下秘钥什么之类的, 配置过程见k8s官方文档 # imagePullSecrets: # - name: regcred dnsPolicy: ClusterFirst restartPolicy: Always terminationGracePeriodSeconds: 30 --- apiVersion: v1 kind: Service metadata: name: first-web-size annotations: # 这里:后面的值填腾讯云的子网id, 这样service就在腾讯云私有网络子网里面有自己的 ip了 service.kubernetes.io/qcloud-loadbalancer-internal-subnetid: subnet-xxx spec: selector: # 过滤标签, 在上面定义pod的时候也写了对应的label run: first-web-size ports: - protocol: TCP # service对外提供访问的端口 port: 80 # pod的端口 targetPort: 80 type: LoadBalancer externalTrafficPolicy: Cluster 将上面的文件保存成sample.yaml, 然后执行 \u0026ldquo;kubectl apply -f sample.yaml\u0026rdquo;, 可以看到下面的Log\n1 2 3 4 5 6 7 8 9 ➜ _posts git:(master) ✗ kubectl apply -f sample.yaml deployment.extensions/first-web-size created service/first-web-size created ➜ _posts git:(master) ✗ kubectl get pod first-web-size-797fb6f8cc-q79df 1/1 Running 0 68s first-web-size-797fb6f8cc-thwm7 1/1 Running 0 68s ➜ _posts git:(master) ✗ kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE first-web-size LoadBalancer 10.3.255.248 \u0026lt;pending\u0026gt; 80:31054/TCP 101s 我们在上面可以看到, 有first-web-size这个Pod有两个实例, 有一个Service\n这个时候登录和集群在同一个内网的服务器上面\n执行 curl http://10.3.255.248 能看到对应的访问HTML\n1 2 3 4 5 6 7 root@VM-0-6-ubuntu:~# curl http://10.3.255.248 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Home Page - aspnetapp\u0026lt;/title\u0026gt; 怎么对外提供访问等我下次分享了.\n用完了要删掉这些东西请执行 \u0026ldquo;kubectl delete -f sample.yaml\u0026rdquo;\n拜\u0026hellip;\n我去做饭了.\n","date":"2019-06-09T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%8F%8D%E6%89%8B%E6%9D%A5%E4%B8%AAk8s%E5%85%A5%E9%97%A8%E5%88%B0%E8%B7%91%E8%B7%AF/","title":"反手来个K8S入门到跑路"},{"content":"MySQL Online DDL导致全局锁表案例分析 我这边遇到了什么问题? 线上给某个表执行新增索引SQL, 然后整个数据CPU打到100%, 连接数暴增到极限, 最后导致所有访问数据库的应用都奔溃.\nSQL如下:\n1 2 ALTER TABLE `book` ADD INDEX `idx_sub_title` (`sub_title` ASC); 能看到什么?\n1 2 3 4 5 \u0026#39;10063293\u0026#39;, \u0026#39;root\u0026#39;, \u0026#39;10.0.0.1:35252\u0026#39;, \u0026#39;novel\u0026#39;, \u0026#39;Query\u0026#39;, \u0026#39;50\u0026#39;, \u0026#39;Waiting for table metadata lock\u0026#39;, \u0026#39;ALTER TABLE `lemon_novel`.`book` \\nADD INDEX `idx_sub_title` (`sub_title` ASC)\u0026#39; \u0026#39;10094494\u0026#39;, \u0026#39;root\u0026#39;, \u0026#39;172.16.2.112:42808\u0026#39;, \u0026#39;novel\u0026#39;, \u0026#39;Query\u0026#39;, \u0026#39;31\u0026#39;, \u0026#39;Waiting for table metadata lock\u0026#39;, \u0026#39;SELECT \\n book_trend.book_id AS book_id, 很奇怪, 这两边都在等\u0026quot;Waiting for table metadata lock\u0026quot;\n反手查一下\u0026quot;Waiting for table metadata lock\u0026quot;是什么 MySQL出现Waiting for table metadata lock的原因以及解决方法\nmysql: Waiting for table metadata lock\nHow do I find which transaction is causing a “Waiting for table metadata lock” state?\nMySQL:8.11.4 Metadata Locking\nMySQL:14.13.1 Online DDL Operations\n初步的一些结论 看下来下面的一些结论:\nMySQL 5.6以后的版本，支持在线DDL，新增index/删除index之类的可以直接InPlace操作，不需要rebuild整张表，理论上效果是很快的，详细资料见Online DDL Operations\nDDL add index 操作会lock table metadata，此操作是导致我们服务不可用的原因\n有怀疑过lock tabel matadata和MySQL autocommit有关，但是实践下来两者看起来没有关联。\n后来在阿里云上面还看到过他们特定写过类似的答疑.\n解决MDL锁导致无法操作数据库的问题\nRDS for MySQL Online DDL 使用\n阿里云建议主要是这样操作.\n这里需要找到的是一直在占用该表的会话，而不是正在等待MDL锁解除的会话，注意区分。可以根据State列的状态和Info列的命令内容来进行分析判断。\n您也可以用如下命令查询长时间未完成的事务，如果导致阻塞的语句的用户与当前用户不同，请使用导致阻塞的语句的用户登录来终止会话。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 select concat(\u0026#39;kill \u0026#39;,i.trx_mysql_thread_id,\u0026#39;;\u0026#39;) from information_schema.innodb_trx i, (select id, time from information_schema.processlist where time = (select max(time) from information_schema.processlist where state = \u0026#39;Waiting for table metadata lock\u0026#39; and substring(info, 1, 5) in (\u0026#39;alter\u0026#39; , \u0026#39;optim\u0026#39;, \u0026#39;repai\u0026#39;, \u0026#39;lock \u0026#39;, \u0026#39;drop \u0026#39;, \u0026#39;creat\u0026#39;))) p where timestampdiff(second, i.trx_started, now()) \u0026gt; p.time and i.trx_mysql_thread_id not in (connection_id(),p.id); 然而在我的场景, 上面的SQL并没有任何的进程输出.\n陷入僵局的\u0026hellip; 不过上面给了一些思路, 现在我们主要是因为有东西占用着 table metadata lock, 导致当前所有的东西都没有执行.\nshow full processlist;\n看一眼没什么卵用, 处理那两个奇怪的wait lock, 其他的都挺正常的.\n那么, 看下现在谁占用着锁?\n怎么看呢?\n1 select * from information_schema.innodb_trx; 神奇了, 真有两个东西在占用锁.\n那kill 了他们看看.\n额, 解决了.\n最终结论 某个奇怪的程序开了查询或者奇怪的操作, lock了 table metadata, 之后连接一直都没有被释放, 导致以上各种问题.\n现在的问题来了, 究竟是哪个程序或者哪个代码导致的呢?\n抱歉, 我现在也还不知道\u0026hellip;\n理论上可以查, 但是上次去查的时候发现数据库显示的host对应机器的端口早就没东西了, 死无对证ing.\n最后建议 online DDL前,最好确认一下当前数据库有没有类似lock存在\n最好的方案还是主从切换来搞\n全文完.\n","date":"2019-05-11T00:00:00Z","permalink":"https://liguobao.github.io/p/mysql-online-ddl%E5%AF%BC%E8%87%B4%E5%85%A8%E5%B1%80%E9%94%81%E8%A1%A8%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90/","title":"MySQL Online DDL导致全局锁表案例分析"},{"content":"Mac OS X 安装 pycrypto报 Clang not found \u0026lsquo;stdio.h\u0026rsquo; error 装一个Python包的时候用到了Clang编译C库, 然后一直报\n1 2 3 4 5 6 7 clang-4.0: warning: argument unused during compilation: \u0026#39;-L/usr/local/lib\u0026#39; [-Wunused-command-line-argument] src/_fastmath.c:29:10: fatal error: \u0026#39;stdio.h\u0026#39; file not found #include \u0026lt;stdio.h\u0026gt; ^~~~~~~~~ 1 error generated. error: command \u0026#39;clang\u0026#39; failed with exit status 1 见鬼, 这不是C最通用的库么? 咋还能找不到.\n检查一下clang版本.\n1 2 3 4 5 ➜ src git:(develop) clang --version clang version 4.0.1 (tags/RELEASE_401/final)Target: x86_64-apple-darwin18.5.0 Thread model: posix InstalledDir: /usr/local/opt/llvm@4/bin 挺正常的\u0026hellip;\n有人说坏境变量问题, 导入一下试试.\n1 export \u0026#34;CFLAGS=-I/usr/local/include -L/usr/local/lib\u0026#34; 无果.\n又翻了一遍stackoverflow..\n找到了这个.\n1 2 3 cd /Library/Developer/CommandLineTools/Packages open macOS_SDK_headers_for_macOS_xx.pgk # macOS_SDK_headers_for_macOS_xx.pgk 对应自己的系统版本 跳出安装界面, 点点点\u0026hellip;\nIt work!\n愉快安装 pip install pycrypto.\n","date":"2019-05-09T00:00:00Z","permalink":"https://liguobao.github.io/p/mac-os-x-%E5%AE%89%E8%A3%85-pycrypto%E6%8A%A5-clang-not-found-stdio.h-error/","title":"Mac OS X 安装 pycrypto报 Clang not found 'stdio.h' error"},{"content":".NET Core教程\u0026ndash;给API加一个服务端缓存啦 以前给API接口写缓存基本都是这样写代码:\n1 2 3 4 5 6 7 8 9 10 11 12 // redis key var bookRedisKey = ConstRedisKey.RecommendationBooks.CopyOne(bookId); // 获取缓存数据 var cacheBookIds = _redisService.ReadCache\u0026lt;List\u0026lt;string\u0026gt;\u0026gt;(bookRedisKey); if (cacheBookIds != null) { // return } else { // 执行另外的逻辑获取数据, 然后写入缓存 } 然后把这一坨坨代码都散落在每个地方。\n某一天，突然想起我这边的缓存基本时间都差不多，而且都是给Web API用的，\n直接在API层支持缓存不就完事了。\n所以， 这里用什么来做呢。\n在.NET Core Web API这里的话, 两种思路:Middleware 或者ActionFilter.\n不了解的同学可以看下面的文档:\nASP.NET Core 中文文档 第四章 MVC（4.3）过滤器\nASP.NET Core 中文文档 第三章 原理（2）中间件\n基于我这边只是部分接口支持缓存的话, 直接还是用ActionFilter实现就可以.\n没撒说的, 直接上代码.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 using System; using Microsoft.AspNetCore.Http; using Microsoft.AspNetCore.Mvc; using Microsoft.AspNetCore.Mvc.Filters; using Newtonsoft.Json.Linq; namespace XXXAPI.Filters { public class DefaultCacheFilterAttribute : ActionFilterAttribute { // 这个时间用于给子类重写,实现不同时间级别的缓存 protected TimeSpan _expireTime; // redis读写的类,没撒看的 private readonly RedisService _redisService; public DefaultCacheFilterAttribute(RedisService redisService) { _redisService = redisService; } public override void OnActionExecuting(ActionExecutingContext context) { if (context.HttpContext.Request.Query.ContainsKey(\u0026#34;refresh\u0026#34;)) { return; } KeyConfig redisKey = GetRequestRedisKey(context.HttpContext); var redisCache = _redisService.ReadCache\u0026lt;JToken\u0026gt;(redisKey); if (redisCache != null) { context.Result = new ObjectResult(redisCache); } return; } public override void OnActionExecuted(ActionExecutedContext context) { KeyConfig redisKey = GetRequestRedisKey(context.HttpContext); var objResult = (ObjectResult)context.Result; if (objResult == null) { return; } var jToken = JToken.FromObject(objResult.Value); _redisService.WriteCache(redisKey, jToken); } private KeyConfig GetRequestRedisKey(HttpContext httpContext) { var requestPath = httpContext.Request.Path.Value; if (!string.IsNullOrEmpty(httpContext.Request.QueryString.Value)) { requestPath = requestPath + httpContext.Request.QueryString.Value; } if (httpContext.Request.Query.ContainsKey(\u0026#34;refresh\u0026#34;)) { if (httpContext.Request.Query.Count == 1) { requestPath = requestPath.Replace(\u0026#34;?refresh=true\u0026#34;, \u0026#34;\u0026#34;); } else { requestPath = requestPath.Replace(\u0026#34;refresh=true\u0026#34;, \u0026#34;\u0026#34;); } } // 这里也就一个redis key的类 var redisKey = ConstRedisKey.HTTPRequest.CopyOne(requestPath); if (_expireTime != default(TimeSpan)) { redisKey.ExpireTime = _expireTime; } return redisKey; } } public static class ConstRedisKey { public readonly static KeyConfig HTTPRequest = new KeyConfig() { Key = \u0026#34;lemon_req_\u0026#34;, ExpireTime = new TimeSpan(TimeSpan.TicksPerMinute * 30), DBName = 5 }; } public class KeyConfig { public string Key { get; set; } public TimeSpan ExpireTime { get; set; } public int DBName { get; set; } public KeyConfig CopyOne(string state) { var one = new KeyConfig(); one.DBName = this.DBName; one.Key = !string.IsNullOrEmpty(this.Key) ? this.Key + state : state; one.ExpireTime = this.ExpireTime; return one; } } } 然后使用的地方, 直接给Controller的Action方法加上注解即可.\n如:\n1 2 3 4 5 6 7 8 9 10 [HttpGet(\u0026#34;v1/xxx/latest\u0026#34;)] [ServiceFilter(typeof(DefaultCacheFilterAttribute))] public IActionResult GetLatestList([FromQuery] int page = 0, [FromQuery]int pageSize = 30) { return Ok(new { data = _service.LoadLatest(page, pageSize), code = 0 }); } 完事\u0026hellip;\n哦, 记得在Startup.cs注入 DefaultCacheFilterAttribute.\n这个注入就不用我来写的吧.\n美中不足的地方在于暂时还不知道怎么直接在注解上面支持自定义缓存时间,\n凑合先用了.\n完结, 拜\u0026hellip;..\n","date":"2019-05-05T00:00:00Z","permalink":"https://liguobao.github.io/p/.net-core%E6%95%99%E7%A8%8B--%E7%BB%99api%E5%8A%A0%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%BC%93%E5%AD%98%E5%95%A6/","title":".NET Core教程--给API加一个服务端缓存啦"},{"content":".NET Core单元测试之搞死开发的覆盖率统计 这两天在给项目补单元测试，dalao们要求\b要看一下测试覆盖率\n翻了一波官方test命令覆盖率倒是有支持了，然而某个更新日志里面写着\n【“Support for Linux and Mac will be considered separately in a subsequent effort.”】\n吐血ing。。。\n8102年都要过去了，微软同学你是不有点过分啊。\n然后又翻了一堆资料之后发现，GitHub有dalao自己搞了个coverlet来支持测试覆盖率。\n开源大法拯救世界啊！！！\nstar一个再说。\ncoverlet配置和使用 首先安装一下coverlet.\n1 2 dotnet tool install --global coverlet.console 或者和我一样懒的话,直接在项目里面引用 \u0026ldquo;coverlet.msbuild\u0026rdquo; 这个包也行.\n1 \u0026lt;PackageReference Include=\u0026#34;coverlet.msbuild\u0026#34; Version=\u0026#34;2.5.0\u0026#34; /\u0026gt; 引用之后,执行dotnet test 的时候加多三个参数\n1 dotnet test /p:CollectCoverage=true /p:CoverletOutput=\u0026#39;./results/\u0026#39; /p:CoverletOutputFormat=opencover CollectCoverage 收集覆盖率\nCoverletOutput 测试报告数据输出路径\nCoverletOutputFormat 测试报告格式,支持这些格式json (default)/lcov/opencover/cobertura/teamcity\n其他参数自己看一下文档说明就好.\n执行之后大概会看到这些信息.\nPS:可怜的个位数覆盖率\u0026hellip;.\n这个时候Test项目里面的results 文件夹里面就有一个coverage.opencover.xml 文件了.\n打开这个文件大概长这个样.\n大概率这不是人看的东西.\n然后另一个工具又出来了.\nReportGenerator https://github.com/danielpalme/ReportGenerator\nReportGenerator converts XML reports generated by OpenCover, PartCover, dotCover, Visual Studio, NCover, Cobertura or JaCoCo into human readable reports in various formats. 这个工具可以讲上面这些不是人看的XML转换成HTML输出.\n美滋滋啊美滋滋啊.\n他们居然还有一个配置指导的页面ReportGenerator/usage\n真良心!!!\n我这边简单起见,直接安装 dotnet tool 全局工具算了.\n1 dotnet tool install --global dotnet-reportgenerator-globaltool 安装好了之后,直接在命令行里面使用 reportgenerator 生成对应的测试报告即可.我这边的命令大概是:\n1 reportgenerator \u0026#39;-reports:UnitTests/results/*.xml\u0026#39; \u0026#39;-targetdir:UnitTests/results\u0026#39; 打开UnitTests/results 下面的index.htm就能看到对应的测试报告了.\n全文完.\n\b明年见！\n","date":"2019-04-08T00:00:00Z","permalink":"https://liguobao.github.io/p/.net-core%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%90%9E%E6%AD%BB%E5%BC%80%E5%8F%91%E7%9A%84%E8%A6%86%E7%9B%96%E7%8E%87%E7%BB%9F%E8%AE%A1coverlet--reportgenerator/","title":".NET Core单元测试之搞死开发的覆盖率统计（coverlet + ReportGenerator ）"},{"content":"任务队列和异步接口的正确打开方式 什么是异步接口? Asynchronous Operations Certain types of operations might require processing of the request in an asynchronous manner (e.g. validating a bank account, processing an image, etc.) in order to avoid long delays on the client side and prevent long-standing open client connections waiting for the operations to complete. For such use cases, APIs MUST employ the following pattern:\nFor POST requests:\nReturn the 202 Accepted HTTP response code.\nIn the response body, include one or more URIs as hypermedia links, which could include:\nThe final URI of the resource where it will be available in future if the ID and path are already known. Clients can then make an HTTP GET request to that URI in order to obtain the completed resource. Until the resource is ready, the final URI SHOULD return the HTTP status code 404 Not Found. { \u0026quot;rel\u0026quot;: \u0026quot;self\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/v1/namespace/resources/{resource_id}\u0026quot;, \u0026quot;method\u0026quot;: \u0026quot;GET\u0026quot; }\nA temporary request queue URI where the status of the operation may be obtained via some temporary identifier. Clients SHOULD make an HTTP GET request to obtain the status of the operation which MAY include such information as completion state, ETA, and final URI once it is completed. { \u0026quot;rel\u0026quot;: \u0026quot;self\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/v1/queue/requests/{request_id}, \u0026quot;method\u0026quot;: \u0026quot;GET\u0026quot; }\u0026quot;\nFor PUT/PATCH/DELETE/GET requests:\nLike POST, you can support PUT/PATCH/DELETE/GET to be asynchronous. The behaviour would be as follows:\nReturn the 202 Accepted HTTP response code.\nIn the response body, include one or more URIs as hypermedia links, which could include:\nA temporary request queue URI where the status of the operation may be obtained via some temporary identifier. Clients SHOULD make an HTTP GET request to obtain the status of the operation which MAY include such information as completion state, ETA, and final URI once it is completed. { \u0026quot;rel\u0026quot;: \u0026quot;self\u0026quot;, \u0026quot;href\u0026quot;: \u0026quot;/v1/queue/requests/{request_id}, \u0026quot;method\u0026quot;: \u0026quot;GET\u0026quot; }\u0026quot;\nAPIs that support both synchronous and asynchronous processing for an URI:\nAPIs that support both synchronous and asynchronous operations for a particular URI and an HTTP method combination, MUST recognize the Prefer header and exhibit following behavior:\nIf the request contains a Prefer=respond-async header, the service MUST switch the processing to asynchronous mode. If the request doesn\u0026rsquo;t contain a Prefer=respond-async header, the service MUST process the request synchronously. It is desirable that all APIs that implement asynchronous processing, also support webhooks as a mechanism of pushing the processing status to the client.\n资料引自:paypal/API Design Patterns And Use Cases:asynchronous-operations\n用人话来说 简单来说就是请求过来,直接返回对应的resourceId/request_id,然后可以通过resourceId/request_id查询处理结果\n处理\b过程可能是队列,也可能直接是异步操作\n如果还没完成处理,返回404,如果处理完成,正常返回对应数据\n好像也没什么讲了\u0026hellip;.\n全文结束吧.\n样例代码部分啦 实现逻辑 创建任务,生成\u0026quot;request-id\u0026quot;存储到对应redis zset队列中\n同时往redis channel发出任务消息, 后台任务处理服务自行处理此消息(生产者-消费者模式)\n任务处理服务处理完消息之后,将处理结果写入redis,request-id为key,结果为value,然后从从redis zset从移除对应的\u0026quot;request-id\u0026quot;\n获取request-id处理结果时:如果request-id能查询到对应的任务处理结果,直接返回处理完的数据; 如果request-id还在sortset队列则直接返回404 + 对应的位置n,表示还在处理中,前面还有n个请求;\n时序图大概长这样:\n喜闻乐见代码时间 RequestService.cs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 // RequestService.cs using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using CorrelationId; using Microsoft.AspNetCore.Mvc; using Microsoft.Extensions.DependencyInjection; using Microsoft.Extensions.Logging; using Newtonsoft.Json.Linq; using StackExchange.Redis; using static StackExchange.Redis.RedisChannel; namespace MTQueue.Service { public class RequestService { private readonly ICorrelationContextAccessor _correlationContext; private readonly ConnectionMultiplexer _redisMultiplexer; private readonly IServiceProvider _services; private readonly ILogger\u0026lt;RequestService\u0026gt; _logger; public RequestService(ICorrelationContextAccessor correlationContext, ConnectionMultiplexer redisMultiplexer, IServiceProvider services, ILogger\u0026lt;RequestService\u0026gt; logger) { _correlationContext = correlationContext; _redisMultiplexer = redisMultiplexer; _services = services; _logger = logger; } public long? AddRequest(JToken data) { var requestId = _correlationContext.CorrelationContext.CorrelationId; var redisDB = _redisMultiplexer.GetDatabase(CommonConst.DEFAULT_DB); var index = redisDB.SortedSetRank(CommonConst.REQUESTS_SORT_SETKEY, requestId); if (index == null) { data[\u0026#34;requestId\u0026#34;] = requestId; redisDB.SortedSetAdd(CommonConst.REQUESTS_SORT_SETKEY, requestId, GetTotalSeconds()); PushRedisMessage(data.ToString()); } return redisDB.SortedSetRank(CommonConst.REQUESTS_SORT_SETKEY, requestId); } public static long GetTotalSeconds() { return (long)(DateTime.Now.ToLocalTime() - new DateTime(1970, 1, 1).ToLocalTime()).TotalSeconds; } private void PushRedisMessage(string message) { Task.Run(() =\u0026gt; { try { using (var scope = _services.CreateScope()) { var multiplexer = scope.ServiceProvider.GetRequiredService\u0026lt;ConnectionMultiplexer\u0026gt;(); multiplexer.GetSubscriber().PublishAsync(CommonConst.REQUEST_CHANNEL, message); } } catch (Exception ex) { _logger.LogError(-1, ex, message); } }); } public Tuple\u0026lt;JToken, long?\u0026gt; GetRequest(string requestId) { var redisDB = _redisMultiplexer.GetDatabase(CommonConst.DEFAULT_DB); var keyIndex = redisDB.SortedSetRank(CommonConst.REQUESTS_SORT_SETKEY, requestId); var response = redisDB.StringGet(requestId); if (response.IsNull) { return Tuple.Create\u0026lt;JToken, long?\u0026gt;(default(JToken), keyIndex); } return Tuple.Create\u0026lt;JToken, long?\u0026gt;(JToken.Parse(response), keyIndex); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 // RedisMQListener.cs using System; using System.Text; using System.Threading; using System.Threading.Tasks; using Microsoft.Extensions.DependencyInjection; using Microsoft.Extensions.Hosting; using Microsoft.Extensions.Logging; using Microsoft.Extensions.Options; using MTQueue.Model; using MTQueue.Service; using Newtonsoft.Json.Linq; using StackExchange.Redis; using static StackExchange.Redis.RedisChannel; namespace MTQueue.Listener { public class RedisMQListener : IHostedService { private readonly ConnectionMultiplexer _redisMultiplexer; private readonly IServiceProvider _services; private readonly ILogger\u0026lt;RedisMQListener\u0026gt; _logger; public RedisMQListener(IServiceProvider services, ConnectionMultiplexer redisMultiplexer, ILogger\u0026lt;RedisMQListener\u0026gt; logger) { _services = services; _redisMultiplexer = redisMultiplexer; _logger = logger; } public Task StartAsync(CancellationToken cancellationToken) { Register(); return Task.CompletedTask; } public virtual bool Process(RedisChannel ch, RedisValue message) { _logger.LogInformation(\u0026#34;Process start,message: \u0026#34; + message); var redisDB = _services.GetRequiredService\u0026lt;ConnectionMultiplexer\u0026gt;() .GetDatabase(CommonConst.DEFAULT_DB); var messageJson = JToken.Parse(message); var requestId = messageJson[\u0026#34;requestId\u0026#34;]?.ToString(); if (string.IsNullOrEmpty(requestId)) { _logger.LogWarning(\u0026#34;requestId not in message.\u0026#34;); return false; } var mtAgent = _services.GetRequiredService\u0026lt;ZhihuClient\u0026gt;(); var text = mtAgent.GetZhuanlan(messageJson); redisDB.StringSet(requestId, text.ToString(), CommonConst.RESPONSE_TS); _logger.LogInformation(\u0026#34;Process finish,requestId:\u0026#34; + requestId); redisDB.SortedSetRemove(CommonConst.REQUESTS_SORT_SETKEY, requestId); return true; } public void Register() { var sub = _redisMultiplexer.GetSubscriber(); var channel = CommonConst.REQUEST_CHANNEL; sub.SubscribeAsync(channel, (ch, value) =\u0026gt; { Process(ch, value); }); } public void DeRegister() { // this.connection.Close(); } public Task StopAsync(CancellationToken cancellationToken) { // this.connection.Close(); return Task.CompletedTask; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // RequestsController.cs using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using CorrelationId; using Microsoft.AspNetCore.Mvc; using MTQueue.Service; using Newtonsoft.Json.Linq; namespace MTQueue.Controllers { [Route(\u0026#34;v1/[controller]\u0026#34;)] [ApiController] public class RequestsController : ControllerBase { private readonly ICorrelationContextAccessor _correlationContext; private readonly RequestService _requestService; private readonly ZhihuClient _mtAgentClient; public RequestsController(ICorrelationContextAccessor correlationContext, RequestService requestService, ZhihuClient mtAgentClient) { _correlationContext = correlationContext; _requestService = requestService; _mtAgentClient = mtAgentClient; } [HttpGet(\u0026#34;{requestId}\u0026#34;)] public IActionResult Get(string requestId) { var result = _requestService.GetRequest(requestId); var resource = $\u0026#34;/v1/requests/{requestId}\u0026#34;; if (result.Item1 == default(JToken)) { return NotFound(new { rel = \u0026#34;self\u0026#34;, href = resource, method = \u0026#34;GET\u0026#34;, index = result.Item2 }); } return Ok(result.Item1); } [HttpPost] public IActionResult Post([FromBody] JToken data, [FromHeader(Name = \u0026#34;Prefer\u0026#34;)]string prefer) { if (!string.IsNullOrEmpty(prefer) \u0026amp;\u0026amp; prefer == \u0026#34;respond-async\u0026#34;) { var index = _requestService.AddRequest(data); var requestId = _correlationContext.CorrelationContext.CorrelationId; var resource = $\u0026#34;/v1/requests/{requestId}\u0026#34;; return Accepted(resource, new { rel = \u0026#34;self\u0026#34;, href = resource, method = \u0026#34;GET\u0026#34;, index = index }); } return Ok(_mtAgentClient.GetZhuanlan(data)); } } } 完整代码见:https://github.com/liguobao/TaskQueueSample\n","date":"2019-04-05T00:00:00Z","permalink":"https://liguobao.github.io/p/%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%E5%92%8C%E5%BC%82%E6%AD%A5%E6%8E%A5%E5%8F%A3%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F.net-core%E7%89%88%E6%9C%AC/","title":"任务队列和异步接口的正确打开方式(.NET Core版本)"},{"content":"没有执行过rm -rf /*的开发不是好运维 起因 突然收到用户反馈说网站在手机端打开是白屏, 很奇怪的问题.\n在电脑端试了下,确实也是白屏,HTML加载进来了,好像有个核心JS加载失败.\n看到一个错误是: We\u0026rsquo;re sorry but house doesn\u0026rsquo;t work properly without JavaScript enabled. Please enable it to continue.\n还有一个http请求的错误是: ERR_INCOMPLETE_CHUNKED_ENCODING\n于是尝试了一下的解决方案:\n无脑重启看看能不能解决问题?重启了一下对应Docker容器,无果\n可能是现在版本引入的Bug?回滚代码重新build,无果.\nnginx的问题? 重启nginx,无果.\n查看nginx日志,没什么有用的东西,无果.\n灵机一闪,不会是磁盘空间满了吧.\ndf -h 看了一眼,99.99%的磁盘使用率.\n某个Docker容器的磁盘空间用掉了34G.\n看一眼Docker容器,直觉告诉我应该是Elasticsearch服务\u0026hellip;\n不算太重要的服务,先停了清理空间再说.\n删掉了容器删了data文件,重启nginx,一切都正常Work了.\n问题解决!!!\n不过Elasticsearch总要重新回复回来嘛,看了下腾讯云云硬盘盘价格,也不是很贵嘛.\n单独给Elasticsearch 起个数据盘吧.\n作死开始 首先根据腾讯云的指示,挂在了数据盘到服务器上面.\n然后给数据盘分区,接着mount到对应的路径.\n嗯,好像有个警告.\n难道不是这个磁盘么?换另外一个看看.\n执行另外一个mount.\n全程\b命令如下:\n进入对应目录清空一下云盘数据吧.(PS:脑子有病才做这个,刚刚初始化的云盘哪有东西.)\nls 看一下,咋这么多奇奇怪怪的文件,难道是\b原来Elasticsearch\b docker 容器留下来的.\n先删了再说.\n执行 rm -rf ./*\n咦,怎么有文件busy无法删除.\n\b额,咋ls都没有了.\n哈?cat 也没有了.\n噗,copy也炸了.\ncd\b 还在.\n哇卡,\b\b这可咋办了.\n先复盘一下做了什么事情 初始化磁盘的时候没有格式化,但是mount失败\nmount失败后没有检查原因,直接尝试把另一个磁盘mount进去\nmount系统盘到指定文件夹后并没有检查内容,直接rm -rf ./*\nrm -rf ./* 此时已经基本没救了\n拯救尝试 还在跑的服务基本是活着的，所以暂时来说API和Web网站都是好的。\n服务器上面跑的基本都是Docker容器, Docker镜像都在阿里云上面存着，基本不怕丢失的问题。\n不过应用配置文件/服务器证书之类的东西都在上面，这个估计要折腾一下了。\ncd 还能用，ls没了，cat也没了。\n尝试cat xxx.conf也没用了,难道只能一点点翻配置文件么.\n群里的朋友提了一句，看看你的云盘有没有备份之类的.\n咦,好像两个星期前找腾讯云技术支持的时候做过一次系统镜像.\n是不是可以直接拿回来直接用?\n看了下具体的镜像版本和备注信息,看起来那时候上面的内容和现在的估计没太多变化.\n直接重装之后更新一下各个服务的镜像到最新版本应该就好了.\n放弃拯救,直接使用备份的系统镜像重装 Work\u0026hellip;\n系统备份镜像拯救世界!!!\n后续操作 + 总结 数据盘和系统盘分开,不要让程序的数据导致系统不可用\n在费用允许的情况下设置磁盘快照策略,我这边最极端的情况下也应该能回滚到一个星期前的版本\n下次大影响操作前先手动备份系统镜像,救命稻草一般的存在.\n","date":"2018-11-20T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%B2%A1%E6%9C%89%E6%89%A7%E8%A1%8C%E8%BF%87rm-rf-/%E7%9A%84%E5%BC%80%E5%8F%91%E4%B8%8D%E6%98%AF%E5%A5%BD%E8%BF%90%E7%BB%B4/","title":"没有执行过rm -rf /*的开发不是好运维"},{"content":"C#:在Task中使用依赖注入的Service/EFContext dotnet core时代,依赖注入基本已经成为标配了,这就不多说了.\n前几天在做某个功能的时候遇到在Task中使用EF DbContext的问题,学艺不精的我被困扰了不短的一段时间,\n于是有了这个文章.\n先说一下代码结构和场景.\n首先有一个HouseDbContext,代码大概是下面这样:\n1 2 3 4 5 6 7 8 public class HouseDbContext : DbContext { public HouseDbContext(DbContextOptions\u0026lt;HouseDbContext\u0026gt; options) : base(options) { } public DbSet\u0026lt;Notice\u0026gt; Notices { get; set; } } 接着已经在StarUp.cs中初始化并注入了,注入代码是这样的:\n1 2 3 4 5 6 services.AddDbContextPool\u0026lt;HouseDbContext\u0026gt;(options =\u0026gt; { options.UseLoggerFactory(loggerFactory); options.UseMySql(Configuration[\u0026#34;MySQLString\u0026#34;].ToString()); }); 有一个NoticeService.cs 会用到HouseDbContext 进行增删查改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class NoticeService { private readonly HouseDbContext _dataContext; public NoticeService(HouseDbContext dataContext) { _dataContext = dataContext; } public Notice FindNotice(long id) { var notice = _dataContext.Notices.FirstOrDefault(n =\u0026gt;n.Id == id); return notice; } } 当然我们也需要把NoticeService注入到容器中,类似这样\n1 2 services.AddScoped\u0026lt;NoticeService,NoticeService\u0026gt;(); 现在一切都是很美好的,也能正常查询出Notice\n然后某一天来了,有个需求是Update Notice之后需要把Notice同步到另外一个地方,例如Elasticsearch?\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class NoticeService { private readonly HouseDbContext _dataContext; public NoticeService(HouseDbContext dataContext) { _dataContext = dataContext; } public Notice FindNotice(long id) { var notice = _dataContext.Notices.FirstOrDefault(n =\u0026gt;n.Id == id); return notice; } public void Save(Notice notice) { _dataContext.Notices.Add(notice); _dataContext.SaveChanges(); Task.Run(() =\u0026gt; { try { var one = _dataContext.Notices.FirstOrDefault(n =\u0026gt;n.Id == notice.Id); // write to other } catch (Exception ex) { Console.WriteLine(ex.ToString()); } }); } } 然后一跑\u0026hellip;\n代码炸了\u0026hellip;\n恭喜你获得跨线程使用EF DbContext导致上下文不同步的异常.\n错误大概长这样.\n1 2 3 System.ObjectDisposedException: Cannot access a disposed object. A common cause of this error is disposing a context that was resolved from dependency injection and then later trying to use the same context instance elsewhere in your application. This may occur if you are calling Dispose() on the context, or wrapping the context in a using statement. If you are using dependency injection, you should let the dependency injection container take care of disposing context instances. Object name: \u0026#39;HouseDbContext\u0026#39;. 估计现在整个人都不好了.\n这个撒意思呢?\n1 2 3 4 5 6 无法访问被释放的对象。 这种错误的一个常见原因是使用从依赖注入中解决的上下文，然后在应用程序的其他地方尝试使用相同的上下文实例。 如果您在上下文上调用Dispose()，或者在using语句中包装上下文，可能会发生这种情况。如果使用依赖项注入，则应该让依赖项注入容器处理上下文实例。 用人话来说是什么意思呢?\n这里的HouseDbContext是依赖注入进来的,生命周期由容器本身管理;\n在Task.Run中再次使用HouseDbContext实例中由于已经切换了线程了,\nHouseDbContext实例已经被释放掉了,无法再继续使用同一个实例,我们应该自己初始化HouseDbContext来用.\n到这里的话,上次我做的时候心生一计:\n既然我们不能直接从构造函数注入的HouseDbContext实例的话,我们是不是可以直接从依赖注入容器中拿一个实例回来呢?\n那在dotnet core里面可以用个什么从容器中取出实例呢?\n答案是:IServiceProvider\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public class NoticeService { private readonly HouseDbContext _dataContext; private readonly IServiceProvider _serviceProvider; public NoticeService(HouseDbContext dataContext,IServiceProvider serviceProvider) { _dataContext = dataContext; _serviceProvider = serviceProvider; } public Notice FindNotice(long id) { var notice = _dataContext.Notices.FirstOrDefault(n =\u0026gt; n.Id == id); Task.Run(() =\u0026gt; { try { var context = _serviceProvider.GetService\u0026lt;HouseDbContext\u0026gt;(); var one = context.Notices.FirstOrDefault(n =\u0026gt; n.Id == notice.Id); Console.WriteLine(notice.Id); // write to other } catch (Exception ex) { Console.WriteLine(ex.ToString()); } }); return notice; } public void Save(Notice notice) { _dataContext.Notices.Add(notice); _dataContext.SaveChanges(); Task.Run(() =\u0026gt; { try { var one = _dataContext.Notices.FirstOrDefault(n =\u0026gt; n.Id == notice.Id); // write to other } catch (Exception ex) { Console.WriteLine(ex.ToString()); } }); } } 跑一下看看\u0026hellip;\n然而事实告诉我,实例是能拿得到,然而还是会炸,错误是一样的.\n原因其实还是一样的,这里已经不受依赖注入托管了,人家的上下文你别想用了.\n那咋办呢\u0026hellip;\n在EF6,还可以直接new HouseDbContext 一个字符串进去初始化,在EF Core这里,已经不能这样玩了.\n那可咋办呢?\n翻了好多资料都没看到有人介绍过咋办,最后居然还是在官网教程里面找到了样例.\n先看代码\u0026hellip;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Task.Run(() =\u0026gt; { try { var optionsBuilder = new DbContextOptionsBuilder\u0026lt;HouseDbContext\u0026gt;(); // appConfiguration.MySQLString appConfiguration是配置类,MySQLString为连接字符串 optionsBuilder.UseMySql(appConfiguration.MySQLString); using (var context = new HouseDbContext(optionsBuilder.Options)) { var one = context.Notices.FirstOrDefault(n =\u0026gt; n.Id == notice.Id); // 当然你也可以直接初始化其他的Service var nService = new NoticeService(context,null); var one =nService.FindOne(notice.Id); } }catch (Exception ex) { Console.WriteLine(ex.ToString()); } }); 教程代码在:Configuring a DbContext\n大功告成\u0026hellip;\n","date":"2018-11-20T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%9C%A8task%E4%B8%AD%E4%BD%BF%E7%94%A8%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E7%9A%84service/efcontext/","title":"在Task中使用依赖注入的Service/EFContext"},{"content":"年轻人的第一个APM之Skywalking 前言 什么是APM?全称:Application Performance Management\n可以参考这里:\n1 2 3 4 5 6 现代APM体系，基本都是参考Google的Dapper（大规模分布式系统的跟踪系统）的体系来做的。通过跟踪请求的处理过程，来对应用系统在前后端处理、服务端调用的性能消耗进行跟踪，关于Dapper的介绍可以看这个链接：Dapper，大规模分布式系统的跟踪系统 by bigbully 作者：刀把五 链接：https://www.zhihu.com/question/27994350/answer/118821214 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 最早使用APM还是在携程里面搬砖的时候,当时使用的是大宗点评网开源的dianping/cat框架.\n后来到了新公司,因为历史包袱有点多,追踪性能问题太麻烦,用过收费的New Relic | Real-time insights for modern software ,newrelic按照CPU核数和内存来收费,实在太贵了我们就放弃了.\n再后来我们调研一下市面的其他方案,看到了这个知乎讨论给了不少的东西.\n有什么知名的开源apm(Application Performance Management)工具吗？\n当时看到naver/pinpoint 和apache/incubator-skywalking 都很不错.\n一个是韩国搜索团队开源的,一个是国内个人用户开源,已经到了apache孵化器了.\n于是两个都试用了一下, 最后由于那时候马上考虑上分表分库组件 sharding-jdbc-dangdang, skywalking也要对应的支持,所以决定用skywalking试试.\n再后来又跑路了,不好意思给那边留下坑就没继续搭建看. 到了新公司PHP/Python/Java什么都写,开始两三个月也没管这个.\n最近不是太忙了,新公司这边服务端API暂时被我带成了dotnet core技术栈,233\u0026hellip;\n同时发现当前用的EF框架偶尔会因为不小心就写出了性能很差的SQL,测试环境基本看不出来,到了生产可能就炸.\n前阵子看到dalao 倾竹 把dotnet core agent写出来了, 于是爽歪歪就开始gang了.\n开始搭建skywalking github:incubator-skywalking\n当前release版本为5.0RC2,最新版本6.X正在开发中.\n所以当前我这里是基于5.0 RC2来搭建的.\n官方向导方案在这里:incubator-skywalking/blob/5.x/docs/README.md\n中文文档在这里:incubator-skywalking/blob/5.x/docs/README_ZH.md\n我这里今天还是全程docker部署.\n以下操作来自JaredTan95/skywalking-docker dalao准备的docker部署.\n预备条件:\ndocker\nelasticsearch\n启动Elasticsearch 1 2 3 4 # Elasticsearch版本要求5.x docker run -p 9200:9200 -p 9300:9300 -e cluster.name=elasticsearch -e xpack.security.enabled=false --name=elasticsearch --restart=always -d wutang/elasticsearch-shanghai-zone 启动好了访问一下 http://localhost:9200 看看,看到一下的内容说明ES已经正常启动了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 { \u0026#34;name\u0026#34;: \u0026#34;_PNUyiW\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;5.6.10\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;b727a60\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2018-06-06T15:48:34.860Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;6.6.1\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; } 接着使用 docker inspect elasticsearch |grep IPAddress 查看一下 elasticsearch 当前IP.\n1 2 3 4 ➜ ✗ docker inspect elasticsearch |grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.27.0.2\u0026#34;, 启动 Skywalking UI + Skywalking collector dalao wutang的wutang/skywalking-docker已经把UI和collector打包到一个镜像里面了,完全可以独立安装.\n所以我这里采用的也是这个方案.\n1 docker run -p 8080:8080 -p 10800:10800 -p 11800:11800 -p 12800:12800 -e ES_CLUSTER_NAME=elasticsearch -e ES_ADDRESSES=上一步拿到的elasticsearchIP:9300 -d wutang/skywalking-docker:5.x 启动好了之后打开 localhost:8080,如果UI页面没有500/404错误,说明整个系统已经正常启动了.\nPS:默认账号密码是:admin admin,可以在docker run指定 UI_ADMIN_PASSWORD环境变量自定义密码.\n如果有错误的话,大概率是ES没有连上,检查一下ES是不是还活着,再不行就进到容器里面看日志.日志默认路径:/apache-skywalking-apm-incubating/logs\nAgent接入 当前已经有Java/C#(dotnet core)/Node.js的Agent了.\n对应的话Java支持是最多的,其他两个我看下来基本就是主流比较多的一些框架都基本有了.\n对应agent框架链接:\ndotnet core: OpenSkywalking/skywalking-netcore\nnode.js:OpenSkywalking/skywalking-nodejs\n理论上应该遵循http://opentracing.io/ API标准的.\nJava agent 主仓库就有,直接去看release即可.\n今天我们肯定是用dotnet core 啦.\ndotnet core当前支持的库和中间件有下面这些:\nASP.NET Core .NET Core BCL types (HttpClient and SqlClient) EntityFrameworkCore Npgsql.EntityFrameworkCore.PostgreSQL Pomelo.EntityFrameworkCore.MySql CAP 嗯,该有的都有了.\n先引入一下SkyWalking.AspNetCore的Package.\n1 dotnet add package SkyWalking.AspNetCore --version 0.3.0 酌情新增 SkyWalking.Diagnostics.EntityFrameworkCore, SkyWalking.Diagnostics.HttpClient, SkyWalking.Diagnostics.EntityFrameworkCore.Npgsql,SkyWalking.Diagnostics.EntityFrameworkCore.Pomelo.MySql 等等\u0026hellip;\n或者直接在xxx.csproj 新增下面这些包.\n1 2 3 4 5 \u0026lt;PackageReference Include=\u0026#34;SkyWalking.AspNetCore\u0026#34; Version=\u0026#34;0.3.0\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;SkyWalking.Diagnostics.EntityFrameworkCore\u0026#34; Version=\u0026#34;0.3.0\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;SkyWalking.Diagnostics.HttpClient\u0026#34; Version=\u0026#34;0.3.0\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;SkyWalking.Diagnostics.EntityFrameworkCore.Npgsql\u0026#34; Version=\u0026#34;0.3.0\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;SkyWalking.Diagnostics.EntityFrameworkCore.Pomelo.MySql\u0026#34; Version=\u0026#34;0.3.0\u0026#34;/\u0026gt; 然后在 Startup.cs的ConfigureServices 方法中添加引用\n1 2 3 4 5 6 7 8 9 10 11 12 13 // using SkyWalking.AspNetCore; // using SkyWalking.Diagnostics.EntityFrameworkCore; // using SkyWalking.Diagnostics.HttpClient; // using SkyWalking.Diagnostics.SqlClient; services.AddSkyWalking(option =\u0026gt; { option.ApplicationCode = \u0026#34;my-first-api\u0026#34;; option.DirectServers = \u0026#34;127.0.0.1:11800\u0026#34;; // 每三秒采样的Trace数量,-1 为全部采集 option.SamplePer3Secs = -1; }).AddEntityFrameworkCore(c =\u0026gt; { c.AddPomeloMysql(); }) .AddHttpClient(); 接着启动应用.\n看到有类似的日志输入,说明已经应用已经正常连接到SkyWalking了.\n1 2 3 4 5 6 info: SkyWalking.Remote.GrpcApplicationService[0] Register application instance success. [applicationInstanceId] = 31 SkyWalking.Remote.GrpcApplicationService:Information: Register application instance success. [applicationInstanceId] = 31 info: SkyWalking.Remote.GrpcApplicationService[0] Register application instance success. [applicationInstanceId] = 31 这时候我们打开http://localhost:8080/#/monitor/dashboard\n可以看到APP已经有数量了.\n接着我们访问一下已有的API/Web页面,就能看到对应的信息了.\n点一下对应的URL.\nhttp client请求(其实是查询ES):\nTopology Map\n其他的一些功能就看自己玩了.\n本期结束\u0026hellip;\n","date":"2018-09-21T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%AF%8F%E5%91%A8%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%88%86%E4%BA%AB-%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AAapm%E4%B9%8Bskywalking/","title":"每周开源项目分享-年轻人的第一个APM之Skywalking"},{"content":" 新版域名 https://house2048.cn/app/house-map/#/ 新版本地址 点击我 https://house2048.cn/app/house-map 小程序已经上线，欢迎关注“人生删除指南”公众号获取。 项目地址： https://github.com/liguobao/58HouseSearch 最新版使用教程 最新地址请在教程中查看 ","date":"2018-09-04T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%9C%B0%E5%9B%BE%E6%90%9C%E7%A7%9F%E6%88%BF%E9%A1%B9%E7%9B%AE%E8%BF%81%E7%A7%BBhouse2048.cn/","title":"地图搜租房项目迁移（house2048.cn）"},{"content":"dotnet core 简易定时任务框架TimeJob 很多时候我们可能需要周期重复做一些事情, 定时任务框架应运而生.\n在Linux下面crontab集合shell脚本做一些定时重复操作是常见通用的.\n但是有时候我们可能需要在程序中做类似的事情,如:\n定时邮件推送\n定时\b监控日报生成\n\bXXX\u0026hellip;\nJava这边,一般都使用Quartz框架\b简单实现定时任务.\n.NET这边,也有Quartz.net,\b不过ASP.NET时代受制于IIS\b,经常会有同行小伙伴说抱怨定时任务偶尔突然就不跑.\n参考文章:\n网站发布后在IIS上定时执行任务\nQuartz定时任务和IIS程序池闲置超时时间冲突解决方案\n到了dotnet core时代,\b自宿主不依赖IIS了,也有自己独立的主线程之后,我们做定时任务就很方便了.\n开源dalaoAmamiya Yuuko 就自己撸了一个简易定时任务框架出来啦.\n\bGitHub开源地址:https://github.com/PomeloFoundation/dotNETCore-Extensions\nNuget地址:Pomelo.AspNetCore.TimedJob\nTimeJob 使用教程 Start.cs的ConfigureServices注入AddTimedJob服务 代码如下:\n1 2 3 4 public void ConfigureServices(IServiceCollection services) { services.AddTimedJob(); } Start.cs的Configure引入UseTimedJob中间件 1 2 3 4 public void Configure(IApplicationBuilder app, IHostingEnvironment env) { app.UseTimedJob(); } 新建\b一个XXXJob.cs类,继承于Job\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 using Microsoft.Extensions.Options; using System; using System.Collections.Generic; using System.Data; using System.Data.SqlClient; using System.Linq; using Pomelo.AspNetCore.TimedJob; namespace Sample.Jobs { public class TestJob : Job { public TestJob() { } [Invoke(Begin = \u0026#34;2018-07-27 00:00\u0026#34;, Interval = 1000 * 600, SkipWhileExecuting = true)] public void Run() { Console.WriteLine(DateTime.Now.ToString()+\u0026#34;,TestJob run...\u0026#34;); } } } 大功告成!\n如果需要把定时任务相关的内容固化到数据库,可以参考:Timed Job - Pomelo扩展包系列\n嗯?完了?\u0026hellip;\n对啊,结束了.\n真结束了\u0026hellip;.\n","date":"2018-07-28T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%AF%8F%E5%91%A8%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%88%86%E4%BA%AB-dotnet-core-%E7%AE%80%E6%98%93%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%A1%86%E6%9E%B6timejob/","title":"每周开源项目分享-dotnet core 简易定时任务框架TimeJob"},{"content":"年轻人的第一个OAuth2.0 Server:hydra hydra 是什么呢?\nOpenID Connect certified OAuth2 Server - cloud native, security-first, open source API security for your infrastructure. Written in Go. SDKs for any language. 讲人话的话就是一个OAuth2.0的服务端框架咯,开箱即用.\nOAuth是撒? QQ互联知道么?微信授权登录知道么?\n扩展阅读:理解OAuth 2.0:阮一峰\n开源地址:https://github.com/ory/hydra\n文档地址:https://www.ory.sh/docs/guides/master/hydra/\n本文结束\u0026hellip;\n开始手把手教你跑hydra server 全程Docker部署,请自行准备相关环境. 准备PostgreSQL 数据库/MySQL数据库 hydra支持PostgreSQL/MySQL,任君选择.\n官网指导教程使用的是PostgreSQL,下面我也抄过来了,同时提供MySQL的相关操作.\n启动数据库啦!!!\n哦,启动之前先创建一个docker 网络.\n1 docker network create hydraguide 启动 PostgreSQL,如下\n1 2 3 4 5 6 7 docker run \\ --network hydraguide \\ --name ory-hydra-example--postgres \\ -e POSTGRES_USER=hydra \\ -e POSTGRES_PASSWORD=secret \\ -e POSTGRES_DB=hydra \\ -d postgres:9.6 或者启动MySQL\n1 2 3 4 5 docker run -p 3306:3306 \\ --network hydraguide \\ --name hydra-mysql --restart=always \\ -v ~/docker-data/hydra-mysql/data/:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123 -d mysql:5.7 启动好了自行验证一下数据库是不是正确启动和能连接上去了.\n准备hydra相关环境变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # The system secret can only be set against a fresh database. Key rotation is currently not supported. This # secret is used to encrypt the database and needs to be set to the same value every time the process (re-)starts. # You can use /dev/urandom to generate a secret. But make sure that the secret must be the same anytime you define it. # You could, for example, store the value somewhere. $ export SYSTEM_SECRET=$(export LC_CTYPE=C; cat /dev/urandom | tr -dc \u0026#39;a-zA-Z0-9\u0026#39; | fold -w 32 | head -n 1) # # Alternatively you can obviously just set a secret: # $ export SYSTEM_SECRET=this_needs_to_be_the_same_always_and_also_very_$3cuR3-._ # The database url points us at the postgres instance. This could also be an ephermal in-memory database (`export DATABASE_URL=memory`) # or a MySQL URI. $ export DATABASE_URL=postgres://hydra:secret@ory-hydra-example--postgres:5432/hydra?sslmode=disable # MySQL的配置,host.docker.internal为宿主机IP,mysql容器的内部IP或者hydra-mysql也可以用 $ export DATABASE_URL=mysql://root:123@tcp(host.docker.internal/mysql容器的内部IP/hydra-mysql:3306)/hydra?parseTime=true SYSTEM_SECRET 是hydra启动时加密数据库使用的,Mac/Linux直接使用上面的方法设置即可,windows环境下设置一下环境变量?大概是这样.\nDATABASE_URL 是数据库连接配置,postgres和mysql 二选一即可.\n执行迁移数据库脚本 hydra自带的,直接执行即可.\n1 2 3 4 docker run -it --rm \\ --network hydraguide \\ oryd/hydra:v1.0.0-beta.5 \\ migrate sql $DATABASE_URL 正常执行的话,应该如下:\n1 2 3 4 5 6 7 8 9 10 Applying `client` SQL migrations... Applied 0 `client` SQL migrations. Applying `oauth2` SQL migrations... Applied 0 `oauth2` SQL migrations. Applying `jwk` SQL migrations... Applied 0 `jwk` SQL migrations. Applying `consent` SQL migrations... Applied 0 `consent` SQL migrations. Migration successful! Applied a total of 0 SQL migrations. Migration successful! 数据库好了,我们现在可以开始搞服务端了.\n启动hydra 服务端 1 2 3 4 5 6 7 8 9 10 docker run -d \\ --name ory-hydra-example--hydra \\ --network hydraguide \\ -p 9000:4444 \\ -e SYSTEM_SECRET=$SYSTEM_SECRET \\ -e DATABASE_URL=$DATABASE_URL \\ -e OAUTH2_ISSUER_URL=https://localhost:9000/ \\ -e OAUTH2_CONSENT_URL=http://localhost:9020/consent \\ -e OAUTH2_LOGIN_URL=http://localhost:9020/login \\ oryd/hydra:v1.0.0-beta.5 serve 这里我们留意几个传入给容器的环境变量.\nOAUTH2_ISSUER_URL hydra所在的地址\nOAUTH2_CONSENT_URL 授权页面地址\nOAUTH2_LOGIN_URL 登录页面地址\n假装大家都了解OAuth2.0的流程的情况下,其实这里就流程基本就是:\nXX应用请求授权\n-\u0026gt; 跳转到OAUTH2_LOGIN_URL地址\n-\u0026gt; 登录成功\n-\u0026gt;跳转到OAUTH2_CONSENT_URL授权页面\n-\u0026gt; 授权成功\n-\u0026gt;回调XX应用地址并且返回相关授权code/token\n-\u0026gt; XX应用使用code/token获取用户信息或者其他操作\n启动之后看一下logs是不是hydra是不是正常启动.\n常见问题:\u0026ldquo;Could not fetch private signing key for OpenID Connect - did you forget to run \u0026quot;hydra migrate sql\u0026quot; or forget to set the SYSTEM_SECRET?\u0026rdquo; error=\u0026ldquo;unexpected end of JSON input\u0026rdquo;\n确认一下SYSTEM_SECRET有没有正常设置呀,实在不行直接在docker run的时候带入.\n正常启动的话,日志如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Thank you for using ORY Hydra! Take security seriously and subscribe to the ORY newsletter. Stay on top of new patches and security insights. \u0026gt;\u0026gt; Subscribe now: http://eepurl.com/di390P \u0026lt;\u0026lt; time=\u0026#34;2018-08-09T10:23:50Z\u0026#34; level=info msg=\u0026#34;Connected to SQL!\u0026#34; time=\u0026#34;2018-08-09T10:23:50Z\u0026#34; level=info msg=\u0026#34;JSON Web Key Set hydra.openid.id-token does not exist yet, generating new key pair...\u0026#34; time=\u0026#34;2018-08-09T10:23:51Z\u0026#34; level=info msg=\u0026#34;Setting up Prometheus middleware\u0026#34; time=\u0026#34;2018-08-09T10:23:51Z\u0026#34; level=info msg=\u0026#34;Transmission of telemetry data is enabled, to learn more go to: https://www.ory.sh/docs/guides/latest/telemetry/\u0026#34; time=\u0026#34;2018-08-09T10:23:51Z\u0026#34; level=info msg=\u0026#34;Detected local environment, skipping telemetry commit\u0026#34; time=\u0026#34;2018-08-09T10:23:51Z\u0026#34; level=info msg=\u0026#34;Detected local environment, skipping telemetry commit\u0026#34; time=\u0026#34;2018-08-09T10:23:51Z\u0026#34; level=info msg=\u0026#34;JSON Web Key Set hydra.https-tls does not exist yet, generating new key pair...\u0026#34; time=\u0026#34;2018-08-09T10:23:55Z\u0026#34; level=info msg=\u0026#34;Setting up http server on :4444\u0026#34; 这时候去访问:https://localhost:9000/.well-known/jwks.json\n理论上是能正常输出结果的.\n这个时候说明我们的hydra已经正常跑起来了.\n登录/授权样例网站启动 1 2 3 4 5 6 7 docker run -d \\ --name ory-hydra-example--consent \\ -p 9020:3000 \\ --network hydraguide \\ -e HYDRA_URL=https://ory-hydra-example--hydra:4444 \\ -e NODE_TLS_REJECT_UNAUTHORIZED=0 \\ oryd/hydra-login-consent-node:v1.0.0-beta.5 在上面我们提过,XX应用请求授权的时候,首先是跳转到统一登录页面,\n这个本质是是一个统一用户中心的应用,需要我们自行开发的.\nhydra官方提供一个样例给我们来测试用,node.js写的.\n项目地址:https://github.com/ory/hydra-login-consent-node\n这里就是在启动这个登录/授权样例网站了.\nPS:我用dotnet core也实现了一套完整的用户中心授权网站,过几天空了整理一下开源发出来.\n创建oauth client 客户端 1 2 3 4 5 6 7 8 9 10 11 docker run --rm -it \\ -e HYDRA_URL=https://ory-hydra-example--hydra:4444 \\ --network hydraguide \\ oryd/hydra:v1.0.0-beta.5 \\ clients create --skip-tls-verify \\ --id facebook-photo-backup \\ --secret some-secret \\ --grant-types authorization_code,refresh_token,client_credentials,implicit \\ --response-types token,code,id_token \\ --scope openid,offline,photos.read \\ --callbacks http://127.0.0.1:9010/callback 没什么说的,留意一下callbacks地址即可.\n其实就是XX互联里面的XX应用的一些信息.\n测试hydra oauth整体授权流程 启动一个请求授权的APP,如下:\n1 2 3 4 5 6 7 8 9 10 11 docker run --rm -it \\ --network hydraguide \\ -p 9010:9010 \\ oryd/hydra:v1.0.0-beta.5 \\ token user --skip-tls-verify \\ --port 9010 \\ --auth-url https://localhost:9000/oauth2/auth \\ --token-url https://ory-hydra-example--hydra:4444/oauth2/token \\ --client-id facebook-photo-backup \\ --client-secret some-secret \\ --scope openid,offline,photos.read 启动之后访问http://127.0.0.1:9010/\n大概会看到:\n1 2 3 4 Welcome to the example OAuth 2.0 Consumer This example requests an OAuth 2.0 Access, Refresh, and OpenID Connect ID Token from the OAuth 2.0 Server (ORY Hydra). To initiate the flow, click the \u0026#34;Authorize Application\u0026#34; button. Authorize application 点击 Authorize application 立即调整到登录页面.\n登录页其实就是我们上面启动的node.js的的登录页面,即:http://localhost:9020/login?login_challenge=XXX\n输入账号密码之后会跳到授权页面,即:http://localhost:9020/consent?consent_challenge=XXXX\n授权选好了之后点击\u0026quot;\u0026quot; 允许授权,立即跳转回到回调地址,同时显示access token相关信息.\n1 2 3 4 Access Token: SwMfFOSHEFpiChmBvRtFLTeaPzCh-TNEXtxTfibgmdw.AgqJrWyn1VlH4FouUucBJSDsmcwOGDI3cHpuy2sDrpI Refresh Token: 48pXaTrBoXl9JxkweFgQV6frEYPwrkE6BaY8U5mymbo.ZuZe68sqX6wtRTk9k1cKBNPJxQzEBEb0G86tT_WVzCg Expires in: 2018-08-09 11:46:14.9905228 +0000 UTC m=+3843.912315001 ID Token: eyJhbGciOiJSUzI1NiIsImtpZCI6InB1YmxpYzo3MzBhZDc4ZC04ODJmLTQzNzItYTRhMi05NTE2NDdlNTk0ZTciLCJ0eXAiOiJKV1QifQ.eyJhdWQiOlsiZmFjZWJvb2stcGhvdG8tYmFja3VwIl0sImF1dGhfdGltZSI6MTUzMzgxMTUyMSwiZXhwIjoxNTMzODE1MTc1LCJpYXQiOjE1MzM4MTE1NzUsImlzcyI6Imh0dHBzOi8vbG9jYWxob3N0OjkwMDAvIiwianRpIjoiOGFkMWE2ZTYtZWY3NC00MTM2LThmODUtMGU0N2FhYWYxZjY1Iiwibm9uY2UiOiJkcXBrcXlkaG1iZXZhdXNtYXJzdWxjcW0iLCJyYXQiOjE1MzM4MTE0MTMsInN1YiI6ImZvb0BiYXIuY29tIn0.euqVspiSeYvMonrwHSPxhfXaCOoYtfP5S5_dJLg6zeQ-Kw6rRJfQRh2ddMiaZBOHdRrQLGHouNSd5SCWP4DgKjr6eA4YKmiTNvDKt0ktIBfTROs5HKOIp9NHLSCL636m10lEVAGJEnL2jwVn5JeNjYmn4nRqOqPBfAxmqFYu-RuHk3HP4w9cKAK2tUBvwUkjH7PBkZ4MZI3AgvK985iPxZWkiyJAn4QPSAidenlQqQJXc7kpYpvP6wauk-nWxid6p0GRL1MozEV1Kok6Nqiw5BtEhuuC3Saijezr-G7Va6SwgTe731huzM6xRH_ovh2x4gayQu-qFX6bT8gjvLh6otQbqEa11nNc0gXIauKds2FF8mD65k9-tnFvbs3T7fJS6wu3LOm9VAtCB78CiTH92E7sbGXaQRC9nsB6LCCteoBPYa8e-dYZxXZHPdWP9tDNc3t2Zr1Lg5bljpWXmFcLllO6gSTqhKiT0otQaQgLDm9GvSeobEaCYRmgk50FdGz4z4Sngek6JJBWHNDo16zuJMScLxIdUfhK9LtLpIsL7w7F01GRMkcriowloRM85qO3V-Dq6REY6VzAe3OkT3_0bxsbU_fzFEIbpDcXdq8hchkEq3aAp48dqXb0WE4R7Iwl4JhjDKiQFxP4-Wk5rPqRyRs7rWiDUxS9v29c88pXd6E 这个时候我们使用Access Token去调用userinfo API,即可正常获取到用户信息.\n1 2 3 4 5 6 curl -X GET \\ https://localhost:9000/userinfo \\ -H \u0026#39;authorization: Bearer SwMfFOSHEFpiChmBvRtFLTeaPzCh-TNEXtxTfibgmdw.AgqJrWyn1VlH4FouUucBJSDsmcwOGDI3cHpuy2sDrpI\u0026#39; \\ -H \u0026#39;cache-control: no-cache\u0026#39; \\ -H \u0026#39;content-type: application/json\u0026#39; \\ -H \u0026#39;postman-token: fecb7032-db0a-bb1b-a61b-de22add7e5bc\u0026#39; 用户信息如下:\n1 2 3 { \u0026#34;sub\u0026#34;: \u0026#34;foo@bar.com\u0026#34; } 为什么这里用户信息只有一个sub呢?\n因为他们实现ory-hydra-example\u0026ndash;consent的时候什么都没加进去,\n具体应该怎么做等我下次分享dotnet core实现 login-consent再说了..\n嗯,本文结束.\n","date":"2018-07-28T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%AF%8F%E5%91%A8%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%88%86%E4%BA%AB-%E5%B9%B4%E8%BD%BB%E4%BA%BA%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AAoauth2.0-serverhydra/","title":"每周开源项目分享-年轻人的第一个OAuth2.0 Server:hydra"},{"content":"dotnet core(读取配置文件) 第一篇:手把手教你写dotnet core(入门篇)\n第二篇:手把手教你ASP.NET Core\n今天我们来学习怎么读取dotnet core程序的配置文件.\n一般dotnet core配置文件都位于项目目录下,名为appsettings.json\n直接读文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \u0026#34;MySQLConnectionString\u0026#34;: \u0026#34;server=mysql地址;port=端口号;database=数据库名字;uid=账号;pwd=密码;charset=\u0026#39;utf-8\u0026#39;;Allow User Variables=True;Connection Timeout=30;SslMode=None;\u0026#34;, \u0026#34;RedisConnectionString\u0026#34;: \u0026#34;redis数据库地址:端口,name=名字,keepAlive=1800,syncTimeout=10000,connectTimeout=360000,password=访问密码,ssl=False,abortConnect=False,responseTimeout=360000,defaultDatabase=1\u0026#34;, \u0026#34;EmailAccount\u0026#34;: \u0026#34;QQ邮箱账号\u0026#34;, \u0026#34;EmailPassword\u0026#34;: \u0026#34;QQ邮箱密码\u0026#34;, \u0026#34;EmailSMTPDomain\u0026#34;: \u0026#34;smtp.qq.com\u0026#34;, \u0026#34;EmailSMTPPort\u0026#34;: 587, \u0026#34;SenderAddress\u0026#34;: \u0026#34;QQ邮箱账号\u0026#34;, \u0026#34;ReceiverAddress\u0026#34;: \u0026#34;QQ邮箱账号\u0026#34;, \u0026#34;ReceiverName\u0026#34;: \u0026#34;liguobao-test\u0026#34;, \u0026#34;EncryptionConfigCIV\u0026#34;: \u0026#34;加密向量,16个16进制数字\u0026#34;, \u0026#34;EncryptionConfigCKEY\u0026#34;: \u0026#34;加密秘钥,16个16进制数字\u0026#34;, \u0026#34;ESURL\u0026#34;:\u0026#34;http://127.0.0.1:9201/\u0026#34;, \u0026#34;ESUserName\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;ESPassword\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;QQAPPID\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;QQAPPKey\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;QQAuthReturnURL\u0026#34;:\u0026#34;\u0026#34; } 那么我们直接去读json然后序列化成对象是不是就可以了.\n没毛病,确实是可以这样玩的. 代码大概是这样的\u0026hellip;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public class AppSettings { public string MySQLConnectionString {get;set;} public string RedisConnectionString {get;set;} // .... } public AppSettings JsonHelper(string jsonFilePath) { _movieJsonFilePath = jsonFilePath; if (!File.Exists(jsonFilePath)) { var pvFile = File.Create(jsonFilePath); pvFile.Flush(); pvFile.Dispose(); return; } using (var stream = new FileStream(jsonFilePath, FileMode.OpenOrCreate)) { try { StreamReader sr = new StreamReader(stream); JsonSerializer serializer = new JsonSerializer { NullValueHandling = NullValueHandling.Ignore, Converters = { new JavaScriptDateTimeConverter() } }; //构建Json.net的读取流 using (var reader = new JsonTextReader(sr)) { return serializer.Deserialize\u0026lt;AppSettings\u0026gt;(reader); } } catch (Exception ex) { return null; } } } 直接读文件然后反序列化实在有点麻烦,有没有简单点的办法啊.\n客官,只要给钱什么都有.\n使用ConfigurationBuilder 读取 直接上代码:\n1 2 3 4 5 6 7 8 9 10 11 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { var mySQLConnectionString = new ConfigurationBuilder() .SetBasePath(Directory.GetCurrentDirectory()) .AddJsonFile(\u0026#34;appsettings.json\u0026#34;).Build()[\u0026#34;MySQLConnectionString\u0026#34;]; // ConnectionStrings节点下的MySQLConnectionString // var mySQLConnectionString = new ConfigurationBuilder() // .SetBasePath(Directory.GetCurrentDirectory()) // .AddJsonFile(\u0026#34;appsettings.json\u0026#34;).Build()[\u0026#34;ConnectionStrings:MySQLConnectionString\u0026#34;]; } 嗯,就是这么简单粗暴,什么都不管\u0026hellip;\n辣鸡,还有没有更优雅点的方法啊.\n哦,这样的要求么?那么我们上DI(自动注入)吧.\nDI读取配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //Startup.cs public IConfiguration Configuration { get; } public Startup(IHostingEnvironment env) { //够赞 var builder = new ConfigurationBuilder() .SetBasePath(env.ContentRootPath) .AddJsonFile(\u0026#34;appsettings.json\u0026#34;, optional: true, reloadOnChange: true); Configuration = builder.Build(); } public void ConfigureServices(IServiceCollection services) { services.AddMvc(); //将Configuration注入到APPConfiguration实例中 services.AddOptions().Configure\u0026lt;AppSettings\u0026gt;(Configuration); } 然后我们在Controller中使用构造函数注入的方式获取APPConfiguration实例\n1 2 3 4 5 6 private AppSettings configuration; public AccountController(IOptions\u0026lt;AppSettings\u0026gt; configurationOption) { this.configuration = configurationOption.Value; } 然后就可以愉快的使用了.\n本文结束\u0026hellip;\n拜\u0026hellip;\n","date":"2018-07-01T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99dotnet-core%E8%AF%BB%E5%8F%96%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","title":"手把手教你写dotnet core(读取配置文件)"},{"content":"后端API入门学习指北 了解一下一下概念.\nRESTful API标准] 所有的API都遵循[RESTful API标准].\n建议大家都简单了解一下HTTP协议和RESTful API相关资料.\n阮一峰:理解RESTful架构\n阮一峰:RESTful API 设计指南\nRESTful API指南\n依赖注入 DI 浅谈依赖注入\n阮一峰:软件架构入门\nJava版 JDK版本:1.8 +\n集成开发环境: IDEA https://www.jetbrains.com/idea/\n数据库:MySQL 5.7+\n内存数据库:Redis\n数据库访问框架: \bmybatis + \bgroovy脚本(PS:如果自己熟悉JPA也可以用)\n构建工具: maven(自己熟悉\bgradle的话也可以用)\n\bJava框架直接上Spring Boot + Spring MVC.\n资料链接 IBM:Spring 框架简介\nIBM:Maven 让事情变得简单\nSpring MVC快速入门教程\nIBM:Spring Boot 基础\nSpring Boot——开发新一代Spring Java应用\nBuilding an Application with Spring Boot\nMyBatis入门实例：整合Spring MVC与MyBatis开发问答网站\nmybatis 官网\nJava入门目标 使用Spring boot 搭建Web API,通过Web API对数据增删查改.\nC#版 .NET版本: dotnet core 2.0\n集成开发环境: Visual Studio Code + dotnet core SDK 或者 Visual Studio 2017(推荐使用 Visual Studio Code)\n数据库:MySQL 5.7+\n内存数据库:Redis\n数据库访问框架: Dapper\ndotnet core 直接使用dotnet core mvc框架即可,依赖注入直接使用原生框架.\n入门资料链接 手把手教你写dotnet core(入门篇)\n手把手教你ASP.NET Core\n微软:NET Core 教程\nASP.NET Core 中文文档 第一章 入门\nDapper 使用教程\nDapper Github\nC#入门目标 使用ASP.NET Core搭建Web API,通过Web API对数据增删查改.\nPython版 Python版本:3.6.5\n集成开发环境: Visual Studio Code + Python debug插件 或者 pycharm\n数据库:MySQL 5.7+\n内存数据库:Redis\n数据库访问框架: sqlalchemy\nPython使用flask框架搭建Web API\n入门到放弃资料 知乎-李辉:Hello, Flask!\n廖雪峰:Python教程\n菜鸟教程:Python3基础\nSQLAlchemy ORM教程\n实验楼:SQLAlchemy 基础教程\n知乎-猪了个去:SQLAlchemy入门和进阶\nPython入门目标 使用Python flask搭建Web API,通过Web API对数据增删查改.\nPHP版本 真有人选择这个?拖出去打死算了吧\u0026hellip;\nPHP版本: 7.1 +\n集成开发环境: Visual Studio Code + PHP debug插件 + nginx + php-fpm\n数据库:MySQL 5.7+\n内存数据库:Redis\n数据库访问框架: 忘了,回头补\n构建工具:composer\n入门到拍黄片 Laravel-简洁、优雅的PHP开发框架(PHP Web Framework)\nlaravel 中文教程\n拍黄片入门目标 使用laravel 搭建Web API,通过Web API对数据增删查改.\nnode.js 版 node.js版本:9.0+\n集成开发环境: Visual Studio Code\n数据库:MySQL 5.7+\n内存数据库:Redis\n数据库访问框架: sequelize 或者orm2\n构建工具:npm\nnode.js入门资料链接 Express:基于 Node.js 平台，快速、开放、极简的 web 开发框架。\n菜鸟教程:Node.js Express 框架\nsequelizejs\nSequelize 中文手册\nnode.js入门目标 使用Express 搭建Web API,通过Web API对数据增删查改.\n没了,纯粹占行用的\u0026hellip;\n拜.\n","date":"2018-06-18T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%90%8E%E7%AB%AFapi%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%8C%97/","title":"后端API入门学习指北"},{"content":"可能是全网首个支持阿里云Elasticsearch Xapck鉴权的Skywalking 对Skywalking有兴趣的同学参见:年轻人的第一个APM-Skywalking\n之前在搭建Skywalking的时候发现,官方Skywalking 5.X并支持有鉴权的Elasticsearch.\n而我司有其他需求已经购买了阿里云的Elasticsearch,咨询过阿里云技术支持后他们表示并不能去掉鉴权,所以只好自己想办法了.\n又在Skywalking技术群问了一圈,有其他人也遇到过类似的问题,但是最后还是选择自建ES了.\n实在不想自己再浪费精力去搭建ES了,还是觉得可以尝试一下别的方案.\n然后咨询了一下wusheng大大之后,他说可以自己尝试换一个支持XPack鉴权的Client,应该没什么太大的问题.\n于是就开始了\u0026quot;填坑\u0026quot;之旅.\n首先是引入x-pack-transport支持 apm-collector/apm-collector-component/client-component/pom.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.elasticsearch.client\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;x-pack-transport\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${elasticsearch.client.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;repositories\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;elasticsearch-releases\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://artifacts.elastic.co/maven\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; 接着在 \u0026hellip;in/java/org/apache/skywalking/apm/collector/client/elasticsearch/ElasticSearchClient.java\n加入PreBuiltXPackTransportClient的初始化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 private final String securityUser; private PreBuiltXPackTransportClient initXPackClient() { Settings settings = Settings.builder() .put(\u0026#34;cluster.name\u0026#34;, clusterName) .put(\u0026#34;xpack.security.transport.ssl.enabled\u0026#34;, false) .put(\u0026#34;xpack.security.user\u0026#34;, securityUser) .put(\u0026#34;client.transport.sniff\u0026#34;, false).build(); return new PreBuiltXPackTransportClient(settings); } private PreBuiltTransportClient initClient() { Settings settings = Settings.builder()\tSettings settings = Settings.builder() .put(\u0026#34;cluster.name\u0026#34;, clusterName)\t.put(\u0026#34;cluster.name\u0026#34;, clusterName) .put(\u0026#34;client.transport.sniff\u0026#34;, clusterTransportSniffer)\t.put(\u0026#34;client.transport.sniff\u0026#34;, clusterTransportSniffer) .build();\t.build(); return new PreBuiltTransportClient(settings); } // 新增 private final String securityUser; // 判断这个变量是不是null或者空字符串,如果是就默认初始化,不是则使用initXPackClient初始化 // 改一下initialize 方法 private final String securityUser; @Override public void initialize() throws ClientException { if (securityUser == null || \u0026#34;\u0026#34;.equals(securityUser)) { client = initClient(); } else { client = initXPackClient(); } 然后还要把apm-collector/pom.xml的elasticsearch.client.version 版本改成5.3.3.\n改完之后因为5.3.3和原来5.5.0有点不一样,需要修改一下很几个地方的代码.\n这时候建议直接使用IDEA build 一下,哪里报错改哪里就好.\n主要都是 searchResponse.getHits().totalHits 改成searchResponse.getHits().totalHits()\n神奇发现5.5.0版本的ES Client把5.3.3的searchResponse.getHits().totalHits() 方法改成了属性.\n不经感慨都是人才啊\u0026hellip;\n别的一些基本都是引入 import org.elasticsearch.action.bulk.byscroll.BulkByScrollResponse;\n全部代码在这里:liguobao/incubator-skywalking\n完整改好的代码在liguobao/incubator-skywalking\n同时配置的时候添加一下 securityUser参数,如果ES有鉴权就传入,没有的话就不传,这样就达到鉴权和不鉴权两种需求的兼容了.\n支持xpack的docker部署方案 完整原文链接:Skywalking-Dcoker for ES xpack 镜像\nDockerfile说明 apache-skywalking-apm-incubating.tar.gz为支持ES X-Pack修改后打包出来的压缩包,此仓库没有这个文件的.\n可以去QQ群:Apache SkyWalking交流群(392443393)群文件中下载apache-skywalking-apm-incubating-xpack.tar.gz\n或者自行编译liguobao/incubator-skywalking/tree/5.x 此版本的源码.\n编译步骤:\n1 2 3 4 5 6 7 8 9 # Prepare git, JDK8 and maven3 git clone https://github.com/liguobao/incubator-skywalking.git cd incubator-skywalking/ git checkout 5.x #Switch to the tag by using git checkout [tagname] (Optional, switch if want to build a release from source codes) git submodule init git submodule update Run ./mvnw clean package -DskipTests #All packages are in /dist.(.tar.gz for Linux and .zip for Windows). Docker 镜像名称:liguobao/skywalking-docker\n拉取镜像（Pull Image）: docker pull liguobao/skywalking-docker:5.0.RC2.xpack\n运行镜像（Run）for ES xpack: docker run -p 8080:8080 -p 10800:10800 -p 11800:11800 -p 12800:12800 -e ES_CLUSTER_NAME=elasticsearch -e ES_ADDRESSES=192.168.2.96:9300 -e SECURITY_USER='elastic:password' -d liguobao/skywalking-docker:5.0.RC2.xpack 使用浏览器访问http://localhost:8080即可. 日志挂载 -v /your/log/path:/apache-skywalking-apm-incubating/logs 环境变量（Environment Variables） ES_CLUSTER_NAME,ES_ADDRESSES:elasticsearch 地址和集群名称。注意：此处Elasticsearch地址中的端口务必是Elasticsearch TCP端口。 SECURITY_USER,SECURITY_USER:elasticsearch 的账号密码,使用X-Pack实现的,常见阿里云ES,格式为:\u0026lsquo;user:password\u0026rsquo;.此参数不传入或者传入\u0026rsquo;\u0026rsquo; ,默认使用没有授权的client. NAMING_BIND_HOST,NAMING_BIND_PORT:OS real network IP(binding required),for agent to find collector cluster. BIND_HOST,REMOTE_BIND_PORT:OS real network IP(binding required),for collector nodes communicate with each other in cluster. collectorN \u0026ndash;(gRPC) \u0026ndash;\u0026gt; collectorM AGENT_GRPC_BIND_PORT:OS real network IP(binding required),for agent to uplink data(trace/metrics) to collector. agent\u0026ndash;(gRPC)\u0026ndash;\u0026gt; collector AGENT_JETTY_BIND_HOST,AGENT_JETTY_BIND_PORT:OS real network IP(binding required), for agent to uplink data(trace/metrics) to collector through HTTP. agent\u0026ndash;(HTTP)\u0026ndash;\u0026gt; collector -UI_JETTY_BIND_HOST,UI_JETTY_BIND_PORT:Stay in 0.0.0.0 if UI starts up in default mode.Change it to OS real network IP(binding required), if deploy collector in different machine. 与elasticsearch-shanghai-zone镜像配合使用请参考 wutang/elasticsearch-shanghai-zone quick start 后记 本来还打算把代码提给主仓库的,但是wusheng 大大说xpack客户端和Apache要求的授权有冲突,遂\u0026hellip;\n那就留着自己玩了.\n拜\u0026hellip;\n","date":"2018-06-18T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%8F%AF%E8%83%BD%E6%98%AF%E5%85%A8%E7%BD%91%E9%A6%96%E4%B8%AA%E6%94%AF%E6%8C%81%E9%98%BF%E9%87%8C%E4%BA%91elasticsearch-xapck%E9%89%B4%E6%9D%83%E7%9A%84skywalking/","title":"可能是全网首个支持阿里云Elasticsearch Xapck鉴权的Skywalking"},{"content":"asp.net core篇 上一篇手把手教你写dotnet core(入门篇)我们已经简单在dotnet core里面跑了个\u0026quot;hello world!\u0026ldquo;和累加程序.\n今天我们的步子迈大一点,直接上 ASP.NET Core了.\nASP.NET Core 是一个新的开源和跨平台的框架，用于构建如 Web 应用、物联网（IoT）应用和移动后端应用等连接到互联网的基于云的现代应用程序。ASP.NET Core 应用可运行于 .NET Core 和完整的 .NET Framework 之上。 构建它的目的是为那些部署在云端或者内部运行（on-premises）的应用提供一个优化的开发框架。它由最小开销的模块化的组件构成，因此在构建你的解决方案的同时可以保持灵活性。你可以在 Windows、Mac 和 Linux 上跨平台的开发和运行你的 ASP.NET Core 应用。 ASP.NET Core 开源在 GitHub 上。 创建ASP.NET Core程序 开发环境: dotnet SDK + VS Code 这里还是直接使用dotnet new命令来创建ASP.NET Core项目, 终端中输入\u0026quot;dotnet new web -n FirsrMVC\u0026rdquo;.\n自动创建FirsrMVC文件夹并生成对应的csproj和CS文件,具体操作和输出信息如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ➜ codelover-blog git:(master) ✗ dotnet new web -n FirsrMVC The template \u0026#34;ASP.NET Core Empty\u0026#34; was created successfully. This template contains technologies from parties other than Microsoft, see https://aka.ms/template-3pn for details. Processing post-creation actions... Running \u0026#39;dotnet restore\u0026#39; on FirsrMVC/FirsrMVC.csproj... Restoring packages for /Users/liguobao/code/codelover-blog/FirsrMVC/FirsrMVC.csproj... Generating MSBuild file /Users/liguobao/code/codelover-blog/FirsrMVC/obj/FirsrMVC.csproj.nuget.g.props. Generating MSBuild file /Users/liguobao/code/codelover-blog/FirsrMVC/obj/FirsrMVC.csproj.nuget.g.targets. Restore completed in 1.97 sec for /Users/liguobao/code/codelover-blog/FirsrMVC/FirsrMVC.csproj. Restore succeeded. ➜ codelover-blog git:(master) ✗ cd FirsrMVC ➜ FirsrMVC git:(master) ✗ ls FirsrMVC.csproj Program.cs Startup.cs obj/ wwwroot/ Program.cs 在VS Code中打开FirsrMVC文件夹,简单看一下文件和Program.cs的代码\nProgram.cs依旧是Main主方法,然后调用了一下BuildWebHost方法,BuildWebHost返回一个IWebHost的实例,接着Run.\n先不管这里具体做了什么事情,我们从语义上理解一下.\nBuildWebHost构建一个Web的Host实例,然后把WebHost实例运行起来了\n创建WebHost使用了一个Startup的类\n关于详细WebHost的详细解析见:ASP.NET Core 运行原理解剖[1]:Hosting\nStartup.cs 先直接上一波代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Microsoft.AspNetCore.Builder; using Microsoft.AspNetCore.Hosting; using Microsoft.AspNetCore.Http; using Microsoft.Extensions.DependencyInjection; namespace FirsrMVC { public class Startup { // This method gets called by the runtime. Use this method to add services to the container. // For more information on how to configure your application, visit https://go.microsoft.com/fwlink/?LinkID=398940 public void ConfigureServices(IServiceCollection services) { } // This method gets called by the runtime. Use this method to configure the HTTP request pipeline. public void Configure(IApplicationBuilder app, IHostingEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } //直接往HTTP Response中写入\u0026#34;Hello World!\u0026#34;,即在页面直接显示此字符 app.Run(async (context) =\u0026gt; { await context.Response.WriteAsync(\u0026#34;Hello World!\u0026#34;); }); } } } ConfigureServices:运行时被调用,将服务(services)添加到容器(container)中\nConfigure:运行时被调用, 配置HTTP request 的pipeline\n嗯,看不懂?没关系,待会一个个演示.\n我们这里还是直接先跑一下程序,FirsrMVC文件夹路径下执行:dotnet run 输出如下:\n1 2 3 4 5 ➜ FirsrMVC git:(master) ✗ dotnet run Hosting environment: Production Content root path: /Users/liguobao/code/codelover-blog/FirsrMVC Now listening on: http://localhost:5000 Application started. Press Ctrl+C to shut down. 然后访问http://localhost:5000看看.\n好了,第一个MVC程序已经跑起来了,本文结束.逃\u0026hellip;\n这里应该还有人吧?那我们继续了.\nwwwroot中的静态文件 在wwwroot文件夹新增first.html,随便写个能看见的HTML标签(我写的是p标签)\n在 Configure 方法中添加一句 app.UseStaticFiles(); 然后再重新运行一下\n访问http://localhost:5000/first.html\n本步骤完成.\nUseStaticFiles()方法:调用一个读取wwwroot文件夹下面的静态文件输出的中间件注册到程序中,从而完成静态文件的输出.\n这里也告诉我们,ASP.NET Core的静态文件(JS+CSS+图片\u0026hellip;)之类的都可以放这边来.\n甚至于如果简单做前后端分离的话,前端的vue/react项目都可以扔这里去.\n重头戏MVC 终于要讲到MVC了.\nMVC模式最早由Trygve Reenskaug在1978年提出[1]，是施乐帕罗奥多研究中心（Xerox PARC）在20世纪80年代为程序语言Smalltalk发明的一种软件架构。MVC模式的目的是实现一种动态的程式设计，使后续对程序的修改和扩展简化，并且使程序某一部分的重复利用成为可能。除此之外，此模式通过对复杂度的简化，使程序结构更加直观。软件系统通过对自身基本部分分离的同时也赋予了各个基本部分应有的功能。专业人员可以通过自身的专长分组：\n控制器（Controller）- 负责转发请求，对请求进行处理。 视图（View） - 界面设计人员进行图形界面设计。 模型（Model） - 程序员编写程序应有的功能（实现算法等等）、数据库专家进行数据管理和数据库设计(可以实现具体的功能)。 以上概念来自维基百科:MVC\n在ASP.NET Core,MVC模型一般就对应着三个文件夹,Models/Views/Controllers.\nModels:存放一些业务实体类,如Student,Course等,表现上就是C#的.cs文件\nViews:存放CSHTML文件,ASP.NET Core的模板文件,类HTML,也可以写C#代码\nControllers: cs文件,继承Controller类的XXXController,实现业务逻辑代码\n下面一起来写一个简单的MVC玩玩.\nStartup 修改 Startup.cs的代码,新增MVC中间件的引用,操作如下:\nStartup.cs中的ConfigureServices方法下新增:services.AddMvc();\nConfigure方法下去掉之前的UseMvc,改成\n1 2 3 4 5 6 app.UseMvc(routes =\u0026gt; { routes.MapRoute( name: \u0026#34;default\u0026#34;, template: \u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); 全部代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Microsoft.AspNetCore.Builder; using Microsoft.AspNetCore.Hosting; using Microsoft.Extensions.Configuration; using Microsoft.Extensions.DependencyInjection; namespace FirsrMVC { public class Startup { public Startup(IConfiguration configuration) { Configuration = configuration; } public IConfiguration Configuration { get; } // This method gets called by the runtime. Use this method to add services to the container. public void ConfigureServices(IServiceCollection services) { services.AddMvc(); } // This method gets called by the runtime. Use this method to configure the HTTP request pipeline. public void Configure(IApplicationBuilder app, IHostingEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } else { app.UseExceptionHandler(\u0026#34;/Home/Error\u0026#34;); } app.UseStaticFiles(); app.UseMvc(routes =\u0026gt; { routes.MapRoute( name: \u0026#34;default\u0026#34;, template: \u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); } } } Controllers 新增Controllers文件夹,在此文件下新建HomeController.cs文件,然后填入一下代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 using System; using System.Collections.Generic; using System.Diagnostics; using System.Linq; using System.Threading.Tasks; using Microsoft.AspNetCore.Mvc; namespace FirsrMVC.Controllers { public class HomeController : Controller { public IActionResult Index() { return View(); } public IActionResult About() { return Json(new { name = \u0026#34;我的名字\u0026#34;, success = true }); } } } 到这里,我们先运行一下代码.\n如无意外的话,\n访问http://localhost:5000/ 空白一片,\n访问http://localhost:5000/Home/About 会输出\n1 2 3 4 { \u0026#34;name\u0026#34;: \u0026#34;我的名字\u0026#34;, \u0026#34;success\u0026#34;: true } http://localhost:5000/ 其实这里访问的是http://localhost:5000/Home/Index,对应方法是HomeController/Index\n我们看一下Log输出会发现这样的一句错误\u0026quot;fail: The view \u0026lsquo;Index\u0026rsquo; was not found. Searched locations: /Views/Home/Index.cshtml, /Views/Shared/Index.cshtml\u0026quot;\n原因是HomeController中的Index返回的是View,\n程序默认就会去/Views/目录下寻找/Home/Index.cshtml文件来渲染然后返回给浏览器,但是这里我们并没有这个文件,所以直接GG.\nhttp://localhost:5000/Home/About 对应方法是HomeController/About,返回为Json数据,不需要View.\n所以直接就往浏览器输出了{ name = \u0026ldquo;我的名字\u0026rdquo;, success = true }的Json格式数据\nViews 上一步我们的的Controller已经建好了,但是缺View文件,我们这里来创建一下View文件\n新建Views/Home文件夹,然后再在此文件夹下新增Index.cshtml文件\n然后在Index.cshtml中输入:\n1 \u0026lt;p\u0026gt;First View Page\u0026lt;/p\u0026gt;\u0026gt; 刷新一下http://localhost:5000/页面.\nView文件也建立好了.\nModels 最后简单讲一下Model.\n同理,新建Models文件夹,在此文件夹下新增Student.cs文件.\n1 2 3 4 5 6 7 8 9 10 namespace FirsrMVC { public class Student { public string Name { get; set; } public int Age { get; set; } } } 我们想做的要做的是把Student信息通过Controller返回给View,然后用View渲染出来.\n修改一下HomeController/Index方法:\n1 2 3 4 5 public IActionResult Index() { Models.Student student = new Models.Student() { Name = \u0026#34;小明\u0026#34;, Age = 16 }; return View(student); } 修改一下Views/Home/Index.cshtml\n1 2 3 4 5 6 7 8 @model FirsrMVC.Models.Student @if(Model !=null) { \u0026lt;p\u0026gt;@Model.Name\u0026lt;span\u0026gt;今年\u0026lt;/span\u0026gt;@Model.Age\u0026lt;span\u0026gt;岁\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt; }else { \u0026lt;p\u0026gt;这里什么都没有.\u0026lt;/p\u0026gt; } 重新运行一下程序,访问http://localhost:5000/\nMVC结束.\n本文完.\n下一节配置文件+DI依赖注入.\n","date":"2018-05-30T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99dotnet-coremvc/","title":"手把手教你写dotnet core(MVC)"},{"content":"dotnet core(入门篇) 开发环境准备 dotnet core最低开发环境要求就是一个.NET SDK,在这里可以下载的到最新版本的SDK,各个平台都有.\n理论上有了SDK什么事都能做了.\n安装SDK的步骤参考上面的连接就OK,这部分我们跳过.\n简单讲一下不同操作系统的开发工具选择.\nWindows平台下首选Visual Studio 2017,安装的时候选择 .NET Core部分即可,安装下来估计占用磁盘空间5G,同时会帮你装好SDK的,好用,很好用.\nMacOS/Linux平台选择 SDK + Visual Studio Code + Debug插件 + Nuget插件,很不错,完全生产级别\n备选方案 Jetbrains家的rider,暂时没用过,resharper一直好评如潮\n今天我这边主要是是以VS Code + Debug插件 + 命令行来进来讲解.\n装好dotnet core SDK之后,打开命令行界面,输入dotnet看看.\nWindows中为CMD或者Powershell,MacOS/Linux为终端 1 2 3 4 5 6 7 8 9 Usage: dotnet [options] Usage: dotnet [path-to-application] Options: -h|--help Display help. --version Display version. path-to-application: 再输入dotnet \u0026ndash;version查看一下当前版本,我这边显示2.1.4.\n输入dotnet help\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 .NET Command Line Tools (2.1.4) Usage: dotnet [runtime-options] [path-to-application] Usage: dotnet [sdk-options] [command] [arguments] [command-options] path-to-application: The path to an application .dll file to execute. SDK commands: new Initialize .NET projects. restore Restore dependencies specified in the .NET project. run Compiles and immediately executes a .NET project. build Builds a .NET project. publish Publishes a .NET project for deployment (including the runtime). test Runs unit tests using the test runner specified in the project. pack Creates a NuGet package. migrate Migrates a project.json based project to a msbuild based project. clean Clean build output(s). sln Modify solution (SLN) files. add Add reference to the project. remove Remove reference from the project. list List reference in the project. nuget Provides additional NuGet commands. msbuild Runs Microsoft Build Engine (MSBuild). vstest Runs Microsoft Test Execution Command Line Tool. Common options: -v|--verbosity Set the verbosity level of the command. Allowed values are q[uiet], m[inimal], n[ormal], d[etailed], and diag[nostic]. -h|--help Show help. 有类似的这些信息,说明我们的SDK安装以及完成了.\nVisual Studio 和Visual Studio Code的安装就不多说了.\n创建 dotnet core程序 我这边只有SDK + VS Code环境,创建程序直接使用命令行了.\ndotnet core SDK中已经有很多现成的APP模板,我们直接使用dotnet new命令就可以创建对应的程序.\n命令行输入 \u0026quot; dotnet new \u0026ldquo;, 显示如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 Usage: new [options] Options: -h, --help Displays help for this command. -l, --list Lists templates containing the specified name. If no name is specified, lists all templates. -n, --name The name for the output being created. If no name is specified, the name of the current directory is used. -o, --output Location to place the generated output. -i, --install Installs a source or a template pack. -u, --uninstall Uninstalls a source or a template pack. --type Filters templates based on available types. Predefined values are \u0026#34;project\u0026#34;, \u0026#34;item\u0026#34; or \u0026#34;other\u0026#34;. --force Forces content to be generated even if it would change existing files. -lang, --language Specifies the language of the template to create. Templates Short Name Language Tags -------------------------------------------------------------------------------------------------------- Console Application console [C#], F#, VB Common/Console Class library classlib [C#], F#, VB Common/Library Unit Test Project mstest [C#], F#, VB Test/MSTest xUnit Test Project xunit [C#], F#, VB Test/xUnit ASP.NET Core Empty web [C#], F# Web/Empty ASP.NET Core Web App (Model-View-Controller) mvc [C#], F# Web/MVC ASP.NET Core Web App razor [C#] Web/MVC/Razor Pages ASP.NET Core with Angular angular [C#] Web/MVC/SPA ASP.NET Core with React.js react [C#] Web/MVC/SPA ASP.NET Core with React.js and Redux reactredux [C#] Web/MVC/SPA ASP.NET Core Web API webapi [C#], F# Web/WebAPI global.json file globaljson Config NuGet Config nugetconfig Config Web Config webconfig Config Solution File sln Solution Razor Page page Web/ASP.NET MVC ViewImports viewimports Web/ASP.NET MVC ViewStart viewstart Web/ASP.NET Examples: dotnet new mvc --auth Individual dotnet new viewimports --namespace dotnet new --help 既然是手把手教程,肯定从最原始的Console Application 开始咯,在命令行中输入命令\u0026quot;dotnet new console -n FirstApplication\u0026rdquo;,创建一个名为FirstApplication的命令行程序\n1 2 3 4 5 6 dotnet new console -n FirstApplication; \bcd FirstApplication; ls FirstApplication; #✗ cd FirstApplication # FirstApplication git:(master) ✗ ls # FirstApplication.csproj Program.cs obj/ 我们切换到FirstApplication文件中,可以看到现在已经有三个文件.简单讲解一下:\nFirstApplication.csproj .csproj为项目构建文件(C Sharp Project”),对应maven中的pom.xml或者是gradle中的build.gradle\nProgram.cs 为程序的主入口, 有一个静态的Main方法\nobj用于存放编译过程中生成的中间临时文件,一般不用管\n我们使用VS Code打开这个文件夹看看.\n首次在VS Code中打开带有.csproj文件的文件夹,VS Code会提示是否需要安装相关插件,直接选择是即可.\n我们这里要用到的插件主要是\u0026quot;C# for Visual Studio Code (powered by OmniSharp)\u0026quot;,直接在插件仓库搜C#基本就能看到.\n直接看下Program.cs的代码:\n一句话输出\u0026quot;Hello World!\u0026quot;\u0026hellip;\n我们试着运行一下看看.\n有两种方式:\n直接在对应项目文件夹位置的命令行中执行dotner run;\nVS Code debug启动\ndotnet run \u0026ldquo;VS Code-查看-集成终端\u0026quot;可以直接调出终端,并且切到当前项目文件路径,执行 dotnet run输出如下:\n1 2 ➜ FirstApplication git:(master) ✗ dotnet run Hello World! VS Code debug VS Code左侧切到debug(一只虫子的图标),点击调试旁边的绿色按钮开始启动.\n终端输出:\n调试控制台输出:\n都说了Debug了,我们简单也做个debug断点调试.\n点击代码文件左侧黑色边栏,鼠标左键单击在第8,9行,对应位置出现断点(小红点),\b 如下图: 再次Debug运行程序.\n第8行位置出现黄色条纹,程序处于debug默认等待下一步操作.\n左侧可查看相关变量当前值,正上方有debug相关操作(F5继续,F10单步跳过,F11单步调试\u0026hellip;)\nF5按一下,黄色条纹往下走一步到第9行(上一步也下了断点).此时尚未输出任何的信息.\nF5下一步执行Console.WriteLine(\u0026ldquo;Hello World!\u0026rdquo;);输出\u0026quot;Hello World!\u0026rdquo;\n写个累加程序试试水 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 using System; namespace FirstApplication { class Program { static void Main(string[] args) { var sum = 0; for (var i = 0; i \u0026lt; 10; i++) { sum = sum + i; Console.WriteLine($\u0026#34;当前i值为:{i},sum:{sum}\u0026#34;); } } } } /* Loaded \u0026#39;/usr/local/share/dotnet/shared/Microsoft.NETCore.App/2.0.5/System.Runtime.Extensions.dll\u0026#39;. Skipped loading symbols. Module is optimized and the debugger option \u0026#39;Just My Code\u0026#39; is enabled. 当前i值为:0,sum:0 当前i值为:1,sum:1 当前i值为:2,sum:3 当前i值为:3,sum:6 当前i值为:4,sum:10 当前i值为:5,sum:15 当前i值为:6,sum:21 当前i值为:7,sum:28 当前i值为:8,sum:36 当前i值为:9,sum:45 The program \u0026#39;[32086] FirstApplication.dll\u0026#39; has exited with code 0 (0x0). */ 在循环里面打个断点看看i的值和sum的值.\n鼠标移动到对应变量上. 到这里,第一个dotnet core程序基本已经完成了,本教程结束\u0026hellip;.\n骗你的,这里还有 还记得我们上面看到的FirstApplication.csproj吗?\n我们直接在VS Code中打开看看.(VS用户随便找个文件编辑器打开)\n1 2 3 4 5 6 7 8 \u0026lt;Project Sdk=\u0026#34;Microsoft.NET.Sdk\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;OutputType\u0026gt;Exe\u0026lt;/OutputType\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.0\u0026lt;/TargetFramework\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;/Project\u0026gt; 这里就指定了SDK版本和程序版本,没有其他多余的东西了.\n暂时没什么看的,我们找个web项目的来看看.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;Project Sdk=\u0026#34;Microsoft.NET.Sdk.Web\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;TargetFramework\u0026gt;netcoreapp2.0\u0026lt;/TargetFramework\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;ItemGroup\u0026gt; \u0026lt;Folder Include=\u0026#34;wwwroot\\\u0026#34;/\u0026gt; \u0026lt;/ItemGroup\u0026gt; \u0026lt;ItemGroup\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Dapper\u0026#34; Version=\u0026#34;1.50.4\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.ApplicationInsights.AspNetCore\u0026#34; Version=\u0026#34;2.2.1\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.AspNetCore\u0026#34; Version=\u0026#34;2.0.2\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.AspNetCore.Mvc\u0026#34; Version=\u0026#34;2.0.3\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.AspNetCore.StaticFiles\u0026#34; Version=\u0026#34;2.0.2\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.EntityFrameworkCore.Design\u0026#34; Version=\u0026#34;2.0.2\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.Extensions.Logging.Debug\u0026#34; Version=\u0026#34;2.0.1\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.VisualStudio.Web.BrowserLink\u0026#34; Version=\u0026#34;2.0.2\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.VisualStudio.Web.CodeGeneration.Design\u0026#34; Version=\u0026#34;2.0.3\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Newtonsoft.Json\u0026#34; Version=\u0026#34;11.0.2\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;StackExchange.Redis.StrongName\u0026#34; Version=\u0026#34;1.2.6\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;System.Diagnostics.Tools\u0026#34; Version=\u0026#34;4.3.0\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;System.Text.Encoding.CodePages\u0026#34; Version=\u0026#34;4.4.0\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;System.ValueTuple\u0026#34; Version=\u0026#34;*\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Microsoft.Extensions.Configuration.Json\u0026#34; Version=\u0026#34;2.1.0-rc1-final\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Pomelo.AspNetCore.TimedJob\u0026#34; Version=\u0026#34;2.0.0-rtm-10046\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MySqlConnector\u0026#34; Version=\u0026#34;0.40.3\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MongoDB.Driver.Core\u0026#34; Version=\u0026#34;2.7.0-beta0001\u0026#34;/\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MongoDB.Driver\u0026#34; Version=\u0026#34;2.7.0-beta0001\u0026#34;/\u0026gt; \u0026lt;/ItemGroup\u0026gt; \u0026lt;/Project\u0026gt; 这边能看的东西就很多了.\nProject Sdk=\u0026ldquo;Microsoft.NET.Sdk.Web\u0026rdquo; SDk为Web\n\bFolder Include=\u0026ldquo;wwwroot\u0026quot; 包含 wwwroot静态文件\nPackageReference Include=\u0026ldquo;Dapper\u0026rdquo; Version=\u0026ldquo;1.50.4\u0026rdquo; 引用了Dapper程序包(一个ORM框架)\nPackageReference Include=\u0026ldquo;Microsoft.AspNetCore.Mvc\u0026rdquo; Version=\u0026ldquo;2.0.3\u0026rdquo; 引用了MVC框架\nPackageReference Include=\u0026ldquo;Newtonsoft.Json\u0026rdquo; Version=\u0026ldquo;11.0.2\u0026rdquo; 引用了Newtonsoft.Json Json库\n这里我们先看看,具体内容在下一讲asp.net core 入门我们会详细讲解.\n全文完\u0026hellip;.\n","date":"2018-05-29T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99dotnet-core%E5%85%A5%E9%97%A8%E7%AF%87/","title":"手把手教你写dotnet core(入门篇)"},{"content":"半个小时教你写一个毕设之地图搜租房 首先需要一个Python3环境,怎么准备我就不多说了,实在不会的出门右转看一下廖雪峰老师的博客.\nHTML部分 代码来自:高德API+Python解决租房问题,简单改了下加载数据部分 代码路径:/static/index.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;initial-scale=1.0, user-scalable=no, width=device-width\u0026#34;\u0026gt; \u0026lt;title\u0026gt;毕业生租房\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;http://cache.amap.com/lbs/static/main1119.css\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;http://cache.amap.com/lbs/static/jquery.range.css\u0026#34; /\u0026gt; \u0026lt;script src=\u0026#34;http://cache.amap.com/lbs/static/jquery-1.9.1.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://cache.amap.com/lbs/static/es5.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://webapi.amap.com/maps?v=1.3\u0026amp;key=22d3816e107f199992666d6412fa0691\u0026amp;plugin=AMap.ArrivalRange,AMap.Scale,AMap.Geocoder,AMap.Transfer,AMap.Autocomplete\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://cache.amap.com/lbs/static/jquery.range.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; .control-panel { position: absolute; top: 30px; right: 20px; } .control-entry { width: 280px; background-color: rgba(119, 136, 153, 0.8); font-family: fantasy, sans-serif; text-align: left; color: white; overflow: auto; padding: 10px; margin-bottom: 10px; } .control-input { margin-left: 120px; } .control-input input[type=\u0026#34;text\u0026#34;] { width: 160px; } .control-panel label { float: left; width: 120px; } #transfer-panel { position: absolute; background-color: white; max-height: 80%; overflow-y: auto; top: 30px; left: 20px; width: 250px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;control-panel\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;control-entry\u0026#34;\u0026gt; \u0026lt;label\u0026gt;选择工作地点：\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026#34;control-input\u0026#34;\u0026gt; \u0026lt;input id=\u0026#34;work-location\u0026#34; type=\u0026#34;text\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;control-entry\u0026#34;\u0026gt; \u0026lt;label\u0026gt;选择通勤方式：\u0026lt;/label\u0026gt; \u0026lt;div class=\u0026#34;control-input\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;vehicle\u0026#34; value=\u0026#34;SUBWAY,BUS\u0026#34; onClick=\u0026#34;takeBus(this)\u0026#34; checked/\u0026gt; 公交+地铁 \u0026lt;input type=\u0026#34;radio\u0026#34; name=\u0026#34;vehicle\u0026#34; value=\u0026#34;SUBWAY\u0026#34; onClick=\u0026#34;takeSubway(this)\u0026#34; /\u0026gt; 地铁 \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;transfer-panel\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; var map = new AMap.Map(\u0026#34;container\u0026#34;, { resizeEnable: true, zoomEnable: true, center: [116.397428, 39.90923], zoom: 11 }); var scale = new AMap.Scale(); map.addControl(scale); var arrivalRange = new AMap.ArrivalRange(); var x, y, t, vehicle = \u0026#34;SUBWAY,BUS\u0026#34;; var workAddress, workMarker; var rentMarkerArray = []; var polygonArray = []; var amapTransfer; var infoWindow = new AMap.InfoWindow({ offset: new AMap.Pixel(0, -30) }); var auto = new AMap.Autocomplete({ input: \u0026#34;work-location\u0026#34; }); AMap.event.addListener(auto, \u0026#34;select\u0026#34;, workLocationSelected); function takeBus(radio) { vehicle = radio.value; loadWorkLocation() } function takeSubway(radio) { vehicle = radio.value; loadWorkLocation() } function workLocationSelected(e) { workAddress = e.poi.name; loadWorkLocation(); } function loadWorkMarker(x, y, locationName) { workMarker = new AMap.Marker({ map: map, title: locationName, icon: \u0026#39;http://webapi.amap.com/theme/v1.3/markers/n/mark_r.png\u0026#39;, position: [x, y] }); } function loadWorkRange(x, y, t, color, v) { arrivalRange.search([x, y], t, function(status, result) { if (result.bounds) { for (var i = 0; i \u0026lt; result.bounds.length; i++) { var polygon = new AMap.Polygon({ map: map, fillColor: color, fillOpacity: \u0026#34;0.4\u0026#34;, strokeColor: color, strokeOpacity: \u0026#34;0.8\u0026#34;, strokeWeight: 1 }); polygon.setPath(result.bounds[i]); polygonArray.push(polygon); } } }, { policy: v }); } function addMarkerByAddress(address, url) { var geocoder = new AMap.Geocoder({ city: \u0026#34;北京\u0026#34;, radius: 1000 }); geocoder.getLocation(address, function(status, result) { if (status === \u0026#34;complete\u0026#34; \u0026amp;\u0026amp; result.info === \u0026#39;OK\u0026#39;) { var geocode = result.geocodes[0]; rentMarker = new AMap.Marker({ map: map, title: address, icon: \u0026#39;http://webapi.amap.com/theme/v1.3/markers/n/mark_b.png\u0026#39;, position: [geocode.location.getLng(), geocode.location.getLat()] }); rentMarkerArray.push(rentMarker); rentMarker.content = \u0026#34;\u0026lt;div\u0026gt;房源：\u0026lt;a target = \u0026#39;_blank\u0026#39; href=\u0026#39;\u0026#34; + url + \u0026#34;\u0026#39;\u0026gt;\u0026#34; + address + \u0026#34;\u0026lt;/a\u0026gt;\u0026lt;div\u0026gt;\u0026#34; rentMarker.on(\u0026#39;click\u0026#39;, function(e) { infoWindow.setContent(e.target.content); infoWindow.open(map, e.target.getPosition()); if (amapTransfer) amapTransfer.clear(); amapTransfer = new AMap.Transfer({ map: map, policy: AMap.TransferPolicy.LEAST_TIME, city: \u0026#34;北京市\u0026#34;, panel: \u0026#39;transfer-panel\u0026#39; }); amapTransfer.search([{ keyword: workAddress }, { keyword: address }], function(status, result) {}) }); } }) } function delWorkLocation() { if (polygonArray) map.remove(polygonArray); if (workMarker) map.remove(workMarker); polygonArray = []; } function delRentLocation() { if (rentMarkerArray) map.remove(rentMarkerArray); rentMarkerArray = []; } function loadWorkLocation() { delWorkLocation(); var geocoder = new AMap.Geocoder({ city: \u0026#34;北京\u0026#34;, radius: 1000 }); geocoder.getLocation(workAddress, function(status, result) { if (status === \u0026#34;complete\u0026#34; \u0026amp;\u0026amp; result.info === \u0026#39;OK\u0026#39;) { var geocode = result.geocodes[0]; x = geocode.location.getLng(); y = geocode.location.getLat(); loadWorkMarker(x, y); loadWorkRange(x, y, 60, \u0026#34;#3f67a5\u0026#34;, vehicle); map.setZoomAndCenter(12, [x, y]); } }) } $(function() { $.get(\u0026#34;/get_houses\u0026#34;, function(data) { data.forEach(function(element, index) { addMarkerByAddress(element.address, element.url); }); }); }) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Python flask部分 Python3环境,使用安装Flask,pymysql,BeautifulSoup\n1 2 3 4 pip install Flask; pip install pymysql; pip install beautifulsoup4; pip install requests; 然后直接上代码咯.\n路径:/app.py\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 from flask import Flask, request from flask import jsonify from flask import render_template from flask import Response import requests from bs4 import BeautifulSoup import pymysql app = Flask(__name__) @app.route(\u0026#34;/get_houses_db/\u0026#34;) def get_houses_db(): # 从数据库读出来的数据,url为房源url,address为房源定位地址 houses = [] # Connect to the database connection = pymysql.connect(host=\u0026#39;127.0.0.1\u0026#39;, user=\u0026#39;root\u0026#39;, password=\u0026#39;123\u0026#39;, db=\u0026#39;你的数据库名字\u0026#39;, charset=\u0026#39;utf8mb4\u0026#39;, cursorclass=pymysql.cursors.DictCursor) try: with connection.cursor() as cursor: # Read a single record sql = \u0026#34;SELECT 你的URL字段,你的地址字段 FROM 你的房源数据表 where 1=1;\u0026#34; keyword = request.args.get(\u0026#39;keyword\u0026#39;) if keyword is not None: sql = sql + \u0026#34;查询字段 like %%s%\u0026#34; % keyword cursor.execute(sql) houses = cursor.fetchall() finally: connection.close() return jsonify(houses) @app.route(\u0026#34;/get_houses\u0026#34;, methods=[\u0026#39;POST\u0026#39;, \u0026#39;GET\u0026#39;]) def get_houses(): # 直接从网页获取数据,url为房源url,address为房源定位地址 houses = [] city = request.args.get(\u0026#39;city\u0026#39;) if city is None: city = \u0026#39;bj\u0026#39; city_url = \u0026#39;http://%s.58.com\u0026#39; % city for page_num in range(1, 10): url = \u0026#34;%s/pinpaigongyu/pn/%d/\u0026#34; % (city_url, page_num) headers = { \u0026#39;connection\u0026#39;: \u0026#34;keep-alive\u0026#34;, \u0026#39;upgrade-insecure-requests\u0026#39;: \u0026#34;1\u0026#34;, \u0026#39;user-agent\u0026#39;: \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\u0026#34;, \u0026#39;accept\u0026#39;: \u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\u0026#34;, \u0026#39;accept-encoding\u0026#39;: \u0026#34;gzip, deflate\u0026#34;, \u0026#39;accept-language\u0026#39;: \u0026#34;zh-CN,zh;q=0.9,en;q=0.8,da;q=0.7\u0026#34;, \u0026#39;cookie\u0026#39;: \u0026#34;f=n; f=n; id58=c5/njVsEqPqC7y9vB/RHAg==; 58tj_uuid=ac94c044-cbb8-451c-b6be-974f90197010; new_uv=1; utm_source=; spm=; init_refer=https%253A%252F%252Fcn.bing.com%252F; als=0; f=n; new_session=0; qz_gdt=; Hm_lvt_dcee4f66df28844222ef0479976aabf1=1527032264,1527032267,1527032270,1527032380; Hm_lpvt_dcee4f66df28844222ef0479976aabf1=1527032421; ppStore_fingerprint=3283C76981CCD1090B42ACBBF624A4C9613FE967CDC69C58%EF%BC%BF1527032420843\u0026#34;, \u0026#39;cache-control\u0026#39;: \u0026#34;no-cache\u0026#34;, } response = requests.request(\u0026#34;GET\u0026#34;, url, headers=headers) htmlSoup = BeautifulSoup(response.text, \u0026#34;html.parser\u0026#34;) ul = htmlSoup.find(attrs={\u0026#34;class\u0026#34;: \u0026#34;list\u0026#34;}) if ul is None: continue li_list = ul.find_all(\u0026#34;li\u0026#34;) if li_list is None: continue for li in li_list: house = {} house[\u0026#39;url\u0026#39;] = \u0026#39;%s/%s\u0026#39; % (city_url, li.find(\u0026#34;a\u0026#34;)[\u0026#39;href\u0026#39;]) house[\u0026#39;address\u0026#39;] = li.find(\u0026#34;h2\u0026#34;).text houses.append(house) return jsonify(houses) @app.route(\u0026#39;/\u0026#39;) def index(): return app.send_static_file(\u0026#39;index.html\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: app.run(port=8888) # python3 安装flask之后,安装命令pip install Flask # 运行 python app.py 效果图:\n然后\u0026hellip;\n写完了\u0026hellip;\n下次见\u0026hellip;\n","date":"2018-05-23T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%8D%8A%E4%B8%AA%E5%B0%8F%E6%97%B6%E6%95%99%E4%BD%A0%E5%86%99%E4%B8%80%E4%B8%AA%E6%AF%95%E8%AE%BE%E4%B9%8B%E5%9C%B0%E5%9B%BE%E6%90%9C%E7%A7%9F%E6%88%BF/","title":"半个小时教你写一个毕设之地图搜租房"},{"content":"同步博客到腾讯云社区声明 我的博客即将搬运同步至腾讯云+社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=2wlwxlkrybgg8\n","date":"2018-05-22T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%90%8C%E6%AD%A5%E5%8D%9A%E5%AE%A2%E5%88%B0%E8%85%BE%E8%AE%AF%E4%BA%91%E7%A4%BE%E5%8C%BA%E5%A3%B0%E6%98%8E/","title":"同步博客到腾讯云社区声明"},{"content":"用Visual Studio Code Debug世界上最好的语言(Mac篇) 首先,你要有台Macbook Pro,接着才继续看这个教程.\nPS:Windows用户看这里用Visual Studio Code Debug世界上最好的语言\nbrew 环境准备 见brew.sh,或者\n1 /usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; PHP7 + nginx + php-fpm + xdebug \bPHP7 1 2 brew install php@7.1 安装完了之后看下安装路径:\n1 2 3 4 5 6 where php; ##➜ ~ where php ## /usr/local/opt/php@7.1/bin/php ## /usr/bin/php 一般php.ini在/usr/local/etc/php/7.1\n1 2 ls /usr/local/etc/php/7.1 #conf.d pear.conf php-fpm.conf php-fpm.d php.ini 待会我们配置xdebug和php-fpm的时候会用到这个这些配置文件的,先跳过\nxdebug安装 本来其实一句brew install php71-xdebug \u0026ndash;without-homebrew-php就完事的,谁知道homebrew-php最近被移除了,所以就尴尬了\u0026hellip;\n手动去下载xdebug然后配置吧.下载页面:https://xdebug.org/files/\n选择自己要安装的版本,我这里选了2.6.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 创建一个你喜欢的路径存放,我放在了~/tool/目录下; mkdir tool; wget https://xdebug.org/files/xdebug-2.6.0.tgz; # 解压 tar xvzf xdebug-2.6.0.tgz; cd xdebug-2.6.0; # 初始化php模块 phpize; # 生成对应的so文件 # ./configure --enable-xdebug --with-php-config=PHP安装路径/bin/php-config; ./configure --enable-xdebug --with-php-config=/usr/local/Cellar/php@7.1/7.1.17/bin/php-config; make; make test; # 上一步正常make执行完毕之后会在xdebug-2.6.0/modules/文件夹下生成xdebug.la和xdebug.so,待会我们在php.ini中配置xdebug会用到这个文件 https://www.techflirt.com/install-configure-xdebug-on-xampp-windows-and-mac/\n安装nginx 1 2 brew install nginx 配置nginx.conf 安装完成之后开始配置nginx,首先创建一堆需要用到的文件件.\n1 2 3 4 5 6 7 8 9 10 11 12 13 mkdir -p /usr/local/var/logs/nginx mkdir -p /usr/local/etc/nginx/sites-available mkdir -p /usr/local/etc/nginx/sites-enabled mkdir -p /usr/local/etc/nginx/conf.d mkdir -p /usr/local/etc/nginx/ssl sudo mkdir -p /var/www sudo chown :staff /var/www sudo chmod 777 /var/www #作者：GQ1994 #链接：https://www.jianshu.com/p/a642ee8eca9a #來源：简书 #著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 然后vim /usr/local/etc/nginx/nginx.conf 输入以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 user root wheel; #默认的是nobody会导致403 worker_processes 1; error_log /usr/local/var/logs/nginx/error.log debug; pid /usr/local/var/run/nginx.pid; events { worker_connections 256; } http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /usr/local/var/logs/access.log main; sendfile on; keepalive_timeout 65; port_in_redirect off; include /usr/local/etc/nginx/sites-enabled/*; } 设置nginx php-fpm配置文件 vim /usr/local/etc/nginx/conf.d/php-fpm 修改为(没有则创建)\n1 2 3 4 5 6 7 8 #proxy the php scripts to php-fpm location ~ \\.php$ { try_files $uri = 404; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_intercept_errors on; include /usr/local/etc/nginx/fastcgi.conf; } 创建默认虚拟主机default vim /usr/local/etc/nginx/sites-available/default输入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 server { listen 80;#如果80被用了可以换成别的,随你开心 server_name www.qilipet.com admin.qilipet.com; root /var/www/pet/public; access_log /usr/local/var/logs/nginx/default.access.log main; index index.php index.html index.htm; location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ /index.php?$query_string; # Uncomment to enable naxsi on this location # include /etc/nginx/naxsi.rules } location ~ \\.php$ { fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } } 此部分内容基本来自GQ1994:mac下配置php、nginx、mysql、redis\n配置php.ini 回到我们的/usr/local/etc/php/7.1文件夹\n在php.ini中加入xdebug\b配置\n1 2 3 4 5 6 7 8 9 10 11 [xdebug] ;zend_extension=\u0026#34;刚刚的xdebug路径/modules/xdebug.so\u0026#34; zend_extension=\u0026#34;~/tool/xdebug-2.6.0/modules/xdebug.so\u0026#34; xdebug.remote_enable = 1 xdebug.remote_autostart = 1 xdebug.remote_connect_back = 1 ;默认的9000已经被php-fpm占用了,切记换一个端口 xdebug.remote_port = 9001 xdebug.scream = 0 xdebug.show_local_vars = 1 重启一下php-fpm和nginx,看一下php是不是都正常跑起来了.\nVS Code配置 User Settings配置PHP目录 1 \u0026#34;php.executablePath\u0026#34;: \u0026#34;/usr/local/opt/php@7.1/bin/php\u0026#34; 安装php debug插件 安装完成之后配置一下launch.json\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 { // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Listen for XDebug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;php\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;port\u0026#34;: 9001 //默认是9000已经被php-fpm占用,上一步我们配置远程端口是9001 }, { \u0026#34;name\u0026#34;: \u0026#34;Launch currently open script\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;php\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${file}\u0026#34;, \u0026#34;cwd\u0026#34;: \u0026#34;${fileDirname}\u0026#34;, \u0026#34;port\u0026#34;: 9001 //默认是9000已经被php-fpm占用,上一步我们配置远程端口是9001 } ] } 然后就愉快debug最好的语言吧!\n其他部分 macOS系统PHP7增加Xdebug\nInstall PEAR and PECL on Mac OS X\nXdebug on macOS 10.13 with PHP 7\ninstall-configure-xdebug-on-xampp-windows-and-mac\ninstalling-pecl-and-pear-on-os-x-10-11-el-capitan-macos-10-12-sierra-macos-10\n","date":"2018-05-21T00:00:00Z","permalink":"https://liguobao.github.io/p/%E7%94%A8visual-studio-code-debug%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%A5%BD%E7%9A%84%E8%AF%AD%E8%A8%80mac%E7%AF%87/","title":"用Visual Studio Code Debug世界上最好的语言(Mac篇)"},{"content":"logstash grok配置规则 logstash.conf 这里主要需要配置grok match,把日志信息切分成索引数据(match本质是一个正则匹配)\n日志原文:\n1 2018-04-13 16:03:49.822 INFO o.n.p.j.c.XXXXX - Star Calculator grok match:\n1 match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{DATA:log_date} %{TIME:log_localtime} %{WORD:log_type} %{JAVAFILE:log_file} - %{GREEDYDATA:log_content}\u0026#34;} 切出来的数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 { \u0026#34;log_date\u0026#34;: [ [ \u0026#34;2018-04-13\u0026#34; ] ], \u0026#34;log_localtime\u0026#34;: [ [ \u0026#34;16:03:49.822\u0026#34; ] ], \u0026#34;HOUR\u0026#34;: [ [ \u0026#34;16\u0026#34; ] ], \u0026#34;MINUTE\u0026#34;: [ [ \u0026#34;03\u0026#34; ] ], \u0026#34;SECOND\u0026#34;: [ [ \u0026#34;49.822\u0026#34; ] ], \u0026#34;log_type\u0026#34;: [ [ \u0026#34;INFO\u0026#34; ] ], \u0026#34;log_file\u0026#34;: [ [ \u0026#34;o.n.p.j.c.XXXX\u0026#34; ] ], \u0026#34;log_content\u0026#34;: [ [ \u0026#34;Star Calculator\u0026#34; ] ] } 上面所有切出来的field都是\bes中mapping index,都可以在用来做条件查询.\ngrokdebug.herokuapp.com里面可以做测试.\ngrokdebug.herokuapp.com/patterns 所有可用的patterns都可以在这里查到.\n现在我们在用的配置见/logstash/logstash-k8s.conf\nQ: 需要指定mapping index的数据类型怎么办? A: grok match本质是一个正则匹配,默认出来的数据都是String.\b有些时候我们知道某个值其实是个数据类型,这时候可以直接指定数据类型. 不过match中仅支持直接转换成int ,float,语法是 %{NUMBER:response_time:int} 完整配置:\n1 2 match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{DATA:log_date} %{TIME:log_localtime} %{WORD:log_type} %{JAVAFILE:log_file} - %{WORD:method} %{URIPATHPARAM:uri} %{NUMBER:status:int} %{NUMBER:size:int} %{NUMBER:response_time:int}\u0026#34;} Q: 索引文件想需要按日期分别存放,怎么办? A: out中指定index\b格式,如 index=\u0026gt; \u0026ldquo;k8s-%{+YYYY.MM.dd}\u0026rdquo;\n完整out如下:\n1 2 3 4 5 6 7 output { elasticsearch { hosts =\u0026gt; \u0026#34;${ES_URL}\u0026#34; manage_template =\u0026gt; false index =\u0026gt; \u0026#34;k8s-%{+YYYY.MM.dd}\u0026#34; } } 完整logstash.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 input { beats { host =\u0026gt; \u0026#34;0.0.0.0\u0026#34; port =\u0026gt; 5043 } } filter { if [type] == \u0026#34;kube-logs\u0026#34; { mutate { rename =\u0026gt; [\u0026#34;log\u0026#34;, \u0026#34;message\u0026#34;] } date { match =\u0026gt; [\u0026#34;time\u0026#34;, \u0026#34;ISO8601\u0026#34;] remove_field =\u0026gt; [\u0026#34;time\u0026#34;] } grok { match =\u0026gt; { \u0026#34;source\u0026#34; =\u0026gt; \u0026#34;/var/log/containers/%{DATA:pod_name}_%{DATA:namespace}_%{GREEDYDATA:container_name}-%{DATA:container_id}.log\u0026#34;} match =\u0026gt; { \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;%{DATA:log_date} %{TIME:log_localtime} %{WORD:log_type} %{JAVAFILE:log_file} - %{WORD:method} %{URIPATHPARAM:uri} %{NUMBER:status:int} %{NUMBER:size:int} %{NUMBER:response_time:int}\u0026#34;} remove_field =\u0026gt; [\u0026#34;source\u0026#34;] break_on_match =\u0026gt; false } } } output { elasticsearch { hosts =\u0026gt; \u0026#34;${ES_URL}\u0026#34; manage_template =\u0026gt; false index =\u0026gt; \u0026#34;k8s-%{+YYYY.MM.dd}\u0026#34; } } ","date":"2018-05-20T00:00:00Z","permalink":"https://liguobao.github.io/p/logstash-grok%E9%85%8D%E7%BD%AE%E8%A7%84%E5%88%99/","title":"logstash grok配置规则"},{"content":"手把手教你用Docker搭建Hexo博客 hexo 快速、简洁且高效的博客框架,Node.js 所带来的超快生成速度，让上百个页面在几秒内瞬间完成渲染。\n只需一条指令即可部署到 GitHub Pages, Heroku 或其他网站。\nHexo 拥有强大的插件系统，安装插件可以让 Hexo 支持 Jade, CoffeeScript。\n1 2 3 4 5 npm install hexo-cli -g hexo init blog cd blog npm install hexo server 以上来自Hexo官网\n到这里,你的hexo博客已经初始化好了, blog/public文件夹下面已经生成了对应的HTML文件.\n扩展阅读:\nhexo next主题\nhexo next主题配置\ndocker 部署 不BB这么多,先上Dockerfile\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # node环境镜像 FROM node:latest AS build-env # 创建hexo-blog文件夹且设置成工作文件夹 RUN mkdir -p /usr/src/hexo-blog WORKDIR /usr/src/hexo-blog # 复制当前文件夹下面的所有文件到hexo-blog中 COPY . . # 安装 hexo-cli RUN npm --registry=https://registry.npm.taobao.org install hexo-cli -g \u0026amp;\u0026amp; npm install # 生成静态文件 RUN hexo clean \u0026amp;\u0026amp; hexo g # 配置nginx FROM nginx:latest ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone WORKDIR /usr/share/nginx/html # 把上一部生成的HTML文件复制到Nginx中 COPY --from=build-env /usr/src/hexo-blog/public /usr/share/nginx/html EXPOSE 80 接着跑一下看看.\n1 2 docker build -t 镜像名:latest .; docker run -p 80:80 -d 镜像名:latest; 好了,完事\u0026hellip;.\nNginx https证书配置 最后Nginx配置https证书的步骤.\n首先,你要有个证书,哪来的我不管了.\nPS:良心推荐https://freessl.org/直接生成免费证书\n然后nginx.conf如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 events { worker_connections 1024; } http { server { listen 443; server_name codelover.link; root /usr/share/nginx/html; index index.html index.htm; ssl on; ssl_certificate /etc/nginx/full_chain.pem; ssl_certificate_key /etc/nginx/private.key; include /etc/nginx/mime.types; default_type application/octet-stream; gzip on; gzip_min_length 5k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 3; gzip_types text/plain application/json application/javascript text/css application/xml text/javascript image/jpeg image/gif image/png; gzip_vary on; } server { listen 80; server_name codelover.link; root /usr/share/nginx/html; index index.html index.htm; include /etc/nginx/mime.types; default_type application/octet-stream; } } 这时候用docker跑你的hexo-blog镜像的时候把对应的pem和key文件映射到对应路径记录.\n如下:\n1 2 3 4 5 6 7 # codelover-blog 为配置文件路径,codelover-blog/ssl为证书路径 docker run -p 80:80 -p 443:443 \\ --name codelover-blog \\ -v ~/docker-data/codelover-blog/nginx.conf:/etc/nginx/nginx.conf \\ -v ~/docker-data/codelover-blog/ssl/full_chain.pem:/etc/nginx/full_chain.pem \\ -v ~/docker-data/codelover-blog/ssl/private.key:/etc/nginx/private.key \\ --restart=always -d 你的hexo-blog博客镜像; 顺手也把非静态文件的nginx配置放一份,如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 events { worker_connections 1024; } http { upstream webservers { #weigth参数表示权值，权值越高被分配到的几率越大 #本机上的Squid开启3128端口 server 10.31.160.197:8080 weight=5; server 192.168.0.1:9090 weight=3; } server { listen 443; server_name woyaozufang.live; location / { proxy_pass http://webservers; } ssl on; ssl_certificate /etc/nginx/full_chain.pem; ssl_certificate_key /etc/nginx/private.key; error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } gzip on; gzip_min_length 5k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 3; gzip_types text/plain application/json application/javascript text/css application/xml text/javascript image/jpeg image/gif image/png; gzip_vary on; } server { listen 8080; server_name woyaozufang.live; location / { proxy_pass http://webservers; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 80; server_name woyaozufang.live; location / { proxy_pass http://webservers; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } ","date":"2018-05-18T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8docker%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2/","title":"手把手教你用Docker搭建Hexo博客"},{"content":"Jenkins部分 首先,我们要有个Jenkins咯,下载链接:https://jenkins.io/download/\n我们安装官网教程安装好jenkins,安装教程略\u0026hellip;.\n嗯?不是说好手把手么?你妹的.\n好好好,我们还是来手把手教程好了.\n首先安装JDK8 添加安装源之后直接apt-get install就好,下面是ubuntu的安装命令,其他系统自己玩一下就好.\n1 2 3 4 5 6 sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer 下载jenkins.war + 启动Jenkins 下载链接:http://mirrors.jenkins.io/war-stable/\n在这里面找最新的下载,我当前最新的应该是2.107.2\n下载好了jenkins.war之后,在当前目录创建一个jenkins-home文件夹,设置JENKINS_HOME环境变量为jenkins-home(不设置也可以,默认在~/.jenkins)\n1 2 3 4 5 6 wget http://mirrors.jenkins.io/war-stable/2.107.2/jenkins.war; mkdir ~/jenkins-home; export JENKINS_HOME=~/jenkins-home; tmux; java -jar jenkins.war 一般建议开个后台进程来跑jenkins,免得终端退出之后jenkins就死掉了.\n所以上面我先打开了tmux之后再跑java -jar jenkins.war.\n如下图: 接着\b留意一下initialAdminPassword的输出\n1 2 3 4 5 6 7 Jenkins initial setup is required. An admin user has been created and a password generated. Please use the following password to proceed to installation: XXXXXXXXXXXXXX This may also be found at: /root/jenkins-home/secrets/initialAdminPassword 这个时候访问当前主机的8080端口已经可以看到jenkins正在启动了,稍等片刻就可以看到jenkins登录页.\n这个时候把上面的XXXXXXXXXXXXXX复制出来,输进去点击\b继续配置jenkins账号密码信息之类的.\n\b\n接着安装默认插件.\n这里估计也要等几分钟不等,看你的机器性能和网络速度.\n安装好了之后会进入配置登录账号密码,安装提示配置就完事.\n最后\b进入jenkins页面是这样的. \b到现在我们已经把jenkins跑起来了,也有了一些常用的插件.\n我们先去把dotnet core docker 编译发布相关的东西弄好之后再回来继续做jenkins任务.\ndotnet core docker 打包 在项目目录下新建Dockerfile文件,内容如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 FROM microsoft/aspnetcore-build:2.0 AS build-env WORKDIR /app # copy csproj and restore as distinct layers COPY *.csproj ./ RUN dotnet restore # copy everything else and build COPY . ./ RUN dotnet publish -c Release -o out # build runtime image FROM microsoft/aspnetcore:2.0 WORKDIR /app COPY --from=build-env /app/out . ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;你的dotnet core程序.dll\u0026#34;] 这个Dockerfile基本就是把当前目录的\b文件\b拷贝到aspnetcore-build镜像中,再里面编译好之后再发布到aspnetcore:2.0\b镜像\b中,\n最后指定运行你的dotnet core程序\n来源:https://github.com/DaoCloud/dotnet-docker-samples\ndocker build + run 脚本(非必须,可以使用jenkins中脚本编译替代) 以HouseCrawler.Web为例,\n1 2 3 4 5 6 7 8 9 10 11 12 #!/bin/sh image_version=`date +%Y%m%d%H%M`; echo $image_version; cd ~/code/58HouseSearch/HouseCrawler.Core/HouseCrawler.Web; git pull --rebase origin master; docker stop house-web; docker rm house-web; docker build -t house-web:$image_version .; docker images; docker run -p 8080:80 -v ~/docker-data/house-web/appsettings.json:/app/appsettings.json -v ~/docker-data/house-web/NLogFile/:/app/NLogFile --restart=always --name house-web -d house-web:$image_version; docker logs house-web; 通过上面这个build+run脚本,我们已经把dotnet core程序编译好了,并且打包成了docker images,还直接跑起来了.\n但是我们想要的应该是自动化编译部署,而且上面我们都把jenkins跑起来了,所以\u0026hellip;.\njenkins job配置 新建Job 打开jenkins首页,左侧选择\u0026quot;新建任务\u0026quot;(newJob),如下图:\n给新的job取个名字,然后选择\u0026quot;构建自由风格的软件项目\u0026quot;,如图:\n添加源码仓库 确认之后进入Job配置页面,源码管理里面选择git,如图: 如果git仓库是需要权限的话需要配置一下权限,我一般简单粗暴直接把jenkins主机的公钥添加到git仓库里面,所以这里直接配置成\u0026rsquo;From the Jenkins master ~/.ssh\u0026rsquo;,也可以用账号密码访问等等的.\n\u0026ldquo;Branch Specifier (blank for \u0026lsquo;any\u0026rsquo;)\t\u0026ldquo;默认master分支,根据自己的需求填入不同的分支.\n构建触发器和构建环境先跳过,我们不管,待会弄.\n构建 点击\u0026quot;添加构建步骤\u0026rdquo;,选择\u0026quot;Execute shell\u0026rdquo;,然后能看到如下图: 还记得我们上一步的脚本么?修改一下源码路径再放进去.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 切换到源码目录,对应在jenkins-home的workspace下面 cd ~jenkins-home/workspace/项目名称/Dockerfile所在目录; image_version=`date +%Y%m%d%H%M`; echo $image_version; # 停止之前的docker container docker stop house-web; # 删除这个container docker rm house-web; # build镜像并且打上tag docker build -t house-web:$image_version .; docker images; # 把刚刚build出来的镜像跑起来 docker run -p 8080:80 -v ~/docker-data/house-web/appsettings.json:/app/appsettings.json -v ~/docker-data/house-web/NLogFile/:/app/NLogFile --restart=always --name house-web -d house-web:$image_version; docker logs house-web; 如果jenkins主机和程序运行主机不在一台机器上,建议直接在把上面的脚本放在运行主机上,命名成 start_XXX.sh.\n上面的命令直接就是成了\n1 ssh username@发布主机的IP \u0026#39;~/start_XXX.sh\u0026#39; ps:记得在jenkins主机配置ssh免登陆\n构建触发器 构建触发器就是我们选择什么时候来触发构建任务,有几种方案可以做.\n使用 Build periodically,定时 or 隔N久去拉一次代码构建 Poll SCM：定时检查源码变更（根据SCM软件的版本号）,如果有变化就去执行构建 GitHub hook trigger for GITScm polling 或者其他Git平台提供的webhook 安装Generic Webhook Trigger插件之后,使用其他平台的webhook来触发构建任务. 我这里选择第4种方案,安装Generic Webhook Trigger插件,下面马上回告诉你为什么这样做的.\nGeneric Webhook Trigger插件在\u0026quot;系统管理-管理插件-可选插件\u0026quot;里面直接搜\u0026quot;Generic Webhook Trigger\u0026quot;安装就可以.\n从上一步的构建步骤里面的脚本中我们就知道,其实我们现在要不就在jenkins主机上docker build,要不就在发布目标主机上build,\nbuild过程比较慢而且还会产生镜像在本机or目标主机上,docker images也没有被管理起来.\n有什么好的办法么?嗯,还真有.直接用阿里云\u0026quot;容器镜像服务\u0026quot;来构建镜像\n使用阿里云-容器镜像服务 首先登录阿里云,然后进入容器镜像服务,地址是https://cr.console.aliyun.com/\n首次进入估计需要创建一个命名空间,一般用公司名或者你的名字就完事.\n接着选择\u0026quot;创建镜像仓库\u0026quot;.\n选地区-选命名空间-填仓库名称(就是镜像名称)-填摘要-设置代码源(支持GitHub/阿里云code/Bitbucket/私有Gitlab/本地Git等等,给个授权就完事)\n构建设置选择\u0026quot;代码变更时自动构建镜像\u0026quot;,然后选一下构建分支为你想要的分支,填入Dockerfile在源码中的路径,然后保存 接着我们进入管理平台看一下.\n点击一下\u0026quot;立即构建\u0026quot;,然后查看一下日志. 这个时候,我们用docker pull registry-internal.cn-hangzhou.aliyuncs.com/你的命名空间/你的镜像名称 就可以拉到这个阿里云build成功的镜像了.\n镜像build的问题解决了,那么我们怎么自动把镜像发布到我们的运行主机呢?\n这时候webhook又出来了.\njenkins webhook触发配置 我们看阿里云镜像构建服务里面,有一项是webhook的,官方介绍在这里:阿里云-webhook管理\n这里就需要填入我们的webhook地址,还记得前面我无端端选择的第四种方案,然后让大家跟着安装的Generic Webhook Trigger插件么?\n我们就是用这货来为我们提供webhook API.\n理一下流程:\ngit仓库代码变化 -\u0026gt;阿里云容器构建服务启动 -\u0026gt; 构建好镜像之后触发webhook -\u0026gt; jenkins收到阿里云的webhook之后触发job执行部署脚本 -\u0026gt;部署脚本使用阿里云镜像run起来 -\u0026gt;完事.\n我们继续配置Generic Webhook Trigger.\nGeneric Webhook Trigger支持的命名触发URL格式是这样的:\n1 http://jenkins登录用户名:token授权码@jenkins IP:8080/generic-webhook-trigger/invoke?token=触发器名称 jenkins登录名和token在\u0026quot;账号-设置-API Token-Show API Token\u0026hellip;\u0026ldquo;里面能看到,找出来之后填到上面去就可以.\n最后一个token参数其实就是\u0026quot;构建触发器\u0026quot;中\u0026quot;触发远程构建\u0026quot;的参数,建议使用job名字.这里的配置大概是这样的:\n最后我们还需要在jenkins全局安全设置中取消勾选“防止跨站点请求伪造（Prevent Cross Site Request Forgery exploits)\u0026ldquo;选项,这样阿里云webhook才能过得来.\n手动在浏览器中访问一下http://jenkins登录用户名:token授权码@jenkins IP:8080/generic-webhook-trigger/invoke?token=触发器名称 如果对应的jenkins Job能正常开始执行,说明整个流程已经ok了.\n最后我们回到上面\u0026quot;阿里云-容器镜像服务-对应镜像仓库-webhook-添加记录\u0026rdquo; PS:webhook名称不要带特殊字符or \u0026ldquo;-\u0026ldquo;之类的,不然一直保存失败而且还不会提示你是因为名字不合法,下午被这个坑了半个小时.\n到这里,我们基本大功告成了.\n最后我们再改一下jenkins的脚本,不在本地build docker了,直接拿\b阿里云镜像服务构建出来的镜像跑就可以.\n1 2 3 4 5 6 7 # 停止之前的docker container docker stop house-web; # 删除这个container docker rm house-web; docker pull 你的阿里云镜像地址; # 把刚刚build出来的镜像跑起来 docker run --restart=always --name 你的contianer名称 你的阿里云镜像地址; 总结一下我们做了什么 搭建jenkins 编写Dockerfile文件,直接编译发布+打包成docker镜像+部署脚本 \b\b\b使用阿里云-容器构建服务构建docker镜像,\b构建成功后使用webhook通知jenkins \b配置jenkins webhook触发器,触发部署脚本 其他项目/语言其实也基本一样的操作,区别只在于\bDockerfile的编写 完事\u0026hellip; ","date":"2018-05-08T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8jenkins%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83dotnet-core%E7%BD%91%E7%AB%99/","title":"手把手教你用Jenkins自动发布dotnet core网站"},{"content":"老早之前就在 v2ex 发过帖子介绍自己的工具啦。\n老早之前做的\u0026quot;地图搜租房(https://house-map.cn)\u0026ldquo;上线了新交互，欢迎大家轻拍砖\n发现好多人都在\u0026quot;城市\u0026quot;这个主题下发转租/租房帖子,索性抓了一波到\u0026quot;地图搜租房\u0026quot;里面\n又是一个广告帖子+\u0026ldquo;地图搜租房\u0026quot;前端大改版 + 小程序上线了\n地图搜租房-多平台房源爬虫 + 高德地图强力驱动,帮助你迅速找到合适房源。\n假新闻开始 PS：上面是个假新闻，这次来真的。\n再之前的小程序因为资质的问题通过不了。\n大概是年前拉着学弟一起来做这个“地图搜租房”小程序了。\n大体做了下面的一些功能。\n功能介绍 城市房源 不同平台单独展示 条件过滤查询 房源详情 + 地图 收藏 + 反馈 神一样现在才写更新内容 明显，现在 Beta9 嘛，凑和能用的程度。\n更新列表：\n支持了城市的行政区筛选，没有行政区的直接归为当前城市 支持了 XX 天内的数据筛选 支持了房源类型的筛选 上面组合 + 价格筛选也做啦 列表页支持了房源发布时间，更加直观展示 一些 Bug 的修复和引入了新的 Bug 优化加载速度，新增数据缓存 加了“广告”位\u0026hellip; 广告位的说明 反正也收不到多少钱，\n这两三年的项目收入是-10000 左右。\n2333\u0026hellip;\n最后，献上地址。\n微信公众号搜索“人生删除指南”\n或者扫描下面的二维码都可以关注后获取微信小程序。\nPS：当然是跪求关注啦。\n小程序码 撒时候还套路 v2ex 老哥嘛。有必要吗？\n拿去拿去！\n最后说几句 小程序刚上线没多久，Bug 多多，多体谅体谅，李姐万岁！ 有什么建议和想法欢迎公众号交流，邮件我也行！ 求轻喷，别打脸 ","date":"2018-03-22T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%9C%B0%E5%9B%BE%E6%90%9C%E7%A7%9F%E6%88%BF-%E5%B0%8F%E7%A8%8B%E5%BA%8F%E7%89%88%E6%9C%AC%E4%B8%8A%E7%BA%BF/","title":"地图搜租房-小程序版本上线"},{"content":".NET Core中使用RabbitMQ正确方式 首先甩官网:http://www.rabbitmq.com/\n然后是.NET Client链接:http://www.rabbitmq.com/dotnet.html\nGitHub仓库:https://github.com/rabbitmq/rabbitmq-dotnet-client\n下面直接进入正文,一共是两个主题:消费者怎么写?生产者怎么写?\n消费者 在dotnet core mvc中,消费者肯定不能通过API或者其他的东西启动,理应是跟着程序一起启动的.\n所以\u0026hellip;\n在dotnet core 2.0以上版本,我们直接用 IHostedService 接口实现.\n.NET Core 中基于 IHostedService 实现后台定时任务\nImplementing background tasks in .NET Core 2.x webapps or microservices with IHostedService and the BackgroundService class\n直接上代码.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 // RabbitListener.cs 这个是基类,只实现注册RabbitMQ后到监听消息,然后每个消费者自己去重写RouteKey/QueueName/消息处理函数Process using System; using System.Text; using System.Threading; using System.Threading.Tasks; using Microsoft.Extensions.DependencyInjection; using Microsoft.Extensions.Hosting; using Microsoft.Extensions.Logging; using Microsoft.Extensions.Options; using RabbitMQ.Client; using RabbitMQ.Client.Events; namespace Test.Listener { public class RabbitListener : IHostedService { private readonly IConnection connection; private readonly IModel channel; public RabbitListener(IOptions\u0026lt;AppConfiguration\u0026gt; options) { try { var factory = new ConnectionFactory() { // 这是我这边的配置,自己改成自己用就好 HostName = options.Value.RabbitHost, UserName = options.Value.RabbitUserName, Password = options.Value.RabbitPassword, Port = options.Value.RabbitPort, }; this.connection = factory.CreateConnection(); this.channel = connection.CreateModel(); } catch (Exception ex) { Console.WriteLine($\u0026#34;RabbitListener init error,ex:{ex.Message}\u0026#34;); } } public Task StartAsync(CancellationToken cancellationToken) { Register(); return Task.CompletedTask; } protected string RouteKey; protected string QueueName; // 处理消息的方法 public virtual bool Process(string message) { throw new NotImplementedException(); } // 注册消费者监听在这里 public void Register() { Console.WriteLine($\u0026#34;RabbitListener register,routeKey:{RouteKey}\u0026#34;); channel.ExchangeDeclare(exchange: \u0026#34;message\u0026#34;, type: \u0026#34;topic\u0026#34;); channel.QueueDeclare(queue:QueueName, exclusive: false); channel.QueueBind(queue: QueueName, exchange: \u0026#34;message\u0026#34;, routingKey: RouteKey); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u0026gt; { var body = ea.Body; var message = Encoding.UTF8.GetString(body); var result = Process(message); if (result) { channel.BasicAck(ea.DeliveryTag, false); } }; channel.BasicConsume(queue: QueueName, consumer: consumer); } public void DeRegister() { this.connection.Close(); } public Task StopAsync(CancellationToken cancellationToken) { this.connection.Close(); return Task.CompletedTask; } } } // 随便贴一个子类 using System; using System.Text; using Microsoft.Extensions.Options; using Newtonsoft.Json.Linq; using RabbitMQ.Client; using RabbitMQ.Client.Events; using Microsoft.Extensions.DependencyInjection; using Microsoft.EntityFrameworkCore; using Microsoft.Extensions.Logging; namespace Test.Listener { public class ChapterLister : RabbitListener { private readonly ILogger\u0026lt;RabbitListener\u0026gt; _logger; // 因为Process函数是委托回调,直接将其他Service注入的话两者不在一个scope, // 这里要调用其他的Service实例只能用IServiceProvider CreateScope后获取实例对象 private readonly IServiceProvider _services; public ChapterLister(IServiceProvider services, IOptions\u0026lt;AppConfiguration\u0026gt; options, ILogger\u0026lt;RabbitListener\u0026gt; logger) : base(options) { base.RouteKey = \u0026#34;done.task\u0026#34;; base.QueueName = \u0026#34;lemonnovelapi.chapter\u0026#34;; _logger = logger; _services = services; } public override bool Process(string message) { var taskMessage = JToken.Parse(message); if (taskMessage == null) { // 返回false 的时候回直接驳回此消息,表示处理不了 return false; } try { using (var scope = _services.CreateScope()) { var xxxService = scope.ServiceProvider.GetRequiredService\u0026lt;XXXXService\u0026gt;(); return true; } } catch (Exception ex) { _logger.LogInformation($\u0026#34;Process fail,error:{ex.Message},stackTrace:{ex.StackTrace},message:{message}\u0026#34;); _logger.LogError(-1, ex, \u0026#34;Process fail\u0026#34;); return false; } } } } 然后,记住\u0026hellip;.\n注入到Startup.cs的时候,使用AddHostedService\n1 services.AddHostedService\u0026lt;ChapterLister\u0026gt;(); 消费者就这样玩了.\n生产者咋玩呢? 这个其实更简单.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 using System; using System.Net; using Newtonsoft.Json.Linq; using RestSharp; using Microsoft.Extensions.Logging; using Microsoft.Extensions.Options; using RabbitMQ.Client; using Newtonsoft.Json; using System.Text; namespace Test.SDK { public class RabbitMQClient { private readonly IModel _channel; private readonly ILogger _logger; public RabbitMQClient(IOptions\u0026lt;AppConfiguration\u0026gt; options, ILogger\u0026lt;RabbitMQClient\u0026gt; logger) { try { var factory = new ConnectionFactory() { HostName = options.Value.RabbitHost, UserName = options.Value.RabbitUserName, Password = options.Value.RabbitPassword, Port = options.Value.RabbitPort, }; var connection = factory.CreateConnection(); _channel = connection.CreateModel(); } catch (Exception ex) { logger.LogError(-1, ex, \u0026#34;RabbitMQClient init fail\u0026#34;); } _logger = logger; } public virtual void PushMessage(string routingKey, object message) { _logger.LogInformation($\u0026#34;PushMessage,routingKey:{routingKey}\u0026#34;); _channel.QueueDeclare(queue: \u0026#34;message\u0026#34;, durable: false, exclusive: false, autoDelete: false, arguments: null); string msgJson = JsonConvert.SerializeObject(message); var body = Encoding.UTF8.GetBytes(msgJson); _channel.BasicPublish(exchange: \u0026#34;message\u0026#34;, routingKey: routingKey, basicProperties: null, body: body); } } } 切记注入实例的时候用单例模式.\nservices.AddSingleton\u0026lt;RabbitMQClient, RabbitMQClient\u0026gt;();\n全文完\u0026hellip;\n","date":"2018-01-15T00:00:00Z","permalink":"https://liguobao.github.io/p/.net-core%E4%B8%AD%E4%BD%BF%E7%94%A8rabbitmq%E6%AD%A3%E7%A1%AE%E6%96%B9%E5%BC%8F/","title":".NET Core中使用RabbitMQ正确方式"},{"content":"Linux运维相关软件安装配置备忘 端口占用相关 1 2 3 4 5 6 //查找端口占用情况 $ netstat -anp | grep \u0026#34;5000\u0026#34; //干掉某个进程 $ kill -9 2553 //后台运行 $ nohup command \u0026amp; 安装SS 1 2 3 4 5 6 $ apt-get update //安装ss $ apt-get install python-pip $ pip install shadowsocks //运行ss服务端 $ nohup ssserver -s ip地址 -k 密码 \u0026amp; 安装MySQL5.7 1 2 3 4 5 6 7 8 9 10 11 12 13 14 http://tecadmin.net/install-mysql-5-on-ubuntu/ $ sudo apt-get install software-properties-common $ sudo add-apt-repository -y ppa:ondrej/mysql-5.7 $ sudo apt-get update $ sudo apt-get install mysql-server //编辑此处，允许远程登录 /etc/mysql/my.cnf bind-address\t= 0.0.0.0 //重启MySQL $ /etc/init.d/mysql restart MySQL添加用户 1 2 3 4 5 6 7 8 9 10 //新增用户 grant all privileges on *.* to root@\u0026#39;%\u0026#39; identified by \u0026#34;root\u0026#34;; //立即生效 flush privileges; grant select,insert,update,delete,create,drop on to joe@10.163.225.87 identified by ‘123′; grant all on xxxDB.* to xxx@\u0026#39;%\u0026#39;; MySQL提示“Checking for tables which need an upgrade, are corrupt or were not closed cleanly” 操作步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 $ sudo service mysql stop $ sudo /etc/init.d/apparmor reload $ sudo service mysql start 或者： down vote This error occurs due to multiple installations of mysql. Run the command: $ ps -A|grep mysql Kill the process by using: $ sudo pkill mysql and then run command: $ ps -A|grep mysqld Also Kill this process by running: $ sudo pkill mysqld Now you are fully set just run the following commands: $ service mysql restart mysql -u root -p 7z相关操作 1 2 3 4 //压缩 $ 7z a -t7z -r manager.7z /home/manager/* //解压 $ 7z X xx.zip 腾讯云修改密码,允许root登录 1 2 3 4 5 $ sudo passwd root $ sudo vi /etc/ssh/sshd_config $ sudo service ssh restart 开机启动相关 1 2 3 4 5 //查看开机启动相关程序 $ ls /etc/rc* //安装sysv-rc-conf $ sudo apt-get install sysv-rc-conf $ sudo sysv-rc-conf ","date":"2017-03-25T00:00:00Z","permalink":"https://liguobao.github.io/p/linux%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%A4%87%E5%BF%98/","title":"Linux运维相关软件安装配置备忘"},{"content":"用Visual Studio Code Debug世界上最好的语言 Mac用户看这里:用Visual Studio Code Debug世界上最好的语言(Mac篇)\n前言 这阵子因缘巧合接手了一个辣鸡项目，是用世界上最好的拍黄片写的，项目基本是另一个小伙伴在撸码，我就兼职打杂和发布做点运维的工作。\n然后昨天项目上了测试版之后，一用起来Error满天飞了。让小伙伴查了很久都没有头绪，实在尴尬，只好自己动手了\u0026hellip;\n作为一个后端狗，虽然知道PHP大体原理和框架，看着项目的业务逻辑也大体知道个所以然，在此之前还是没撸过代码的。\n看代码基本是Visual Studio Code或者HBuilder工具，本地跑代码很白痴的在用phpStudy。\nError出来了，第一反应就是debug咯\u0026hellip;然后问了下小伙伴他以前怎么玩的，答曰：echo。\n一口老血都\u0026hellip;\n查了下谷歌发现，Visual Studio Code + 插件是完全可以用来调试PHP的，所以就撸起了。\nVisual Studio Code + php-debug插件 + phpStudy + xdebug 安装Visual Studio Code 首先肯定是先下载Visual Studio Code 咯。\n安装好之后，随便在一个文件夹内鼠标“右键”，都能看到Open with code，打开之后如下图：\n安装Visual Studio Code php-debug插件 装好VS Code之后，接下来是安装一下PHP-Debug插件了。我们在插件商城搜索一下php，排名第二的PHP Debug就是我们要的插件了。 如下图： 装好了之后重启一下vs code即可。\nphpStudy 对于我这种懒人来说，去配置什么PHP运行环境肯定是不愿意的，那么类似的集成环境有么？\n小伙伴和我说，你下个phpStudy撸就算了，别去倒腾什么版本了。\n然后\u0026hellip;\n下载好了安装完了，打开程序如下图：\n看了下功能，其实这个软件就是集成了各种版本的PHP，可以方便切换PHP版本；同时自带一个Apache和MySQL，各种配置管理起来也挺方便的。 （感觉dalao们应该不怎么会用这么白痴的东西，233\u0026hellip;\n装好之后，启动一下服务，点击一下phpMyAdmin，看看它打开的网站是否能登录到本地的MySQL数据库。\n如果可以，说明PHP环境应该是正常的了；如果有问题，请自行谷歌了\u0026hellip;\n接着切换PHP版本到意向版本，点击一下运行模式旁边的“切换版本”就可以选择版本了。\nxdebug设置 xdebug是什么呢？\n1 2 3 4 5 6 7 8 Xdebug作为PHP调试工具，提供了丰富的调试函数， 也可将Xdebug安装配置为zend studio、editplus调试PHP的第三方插件， 通过开启自动跟踪(auto_trace)和分析器功能，可以直观的看到PHP源代码的性能数据， 以便优化PHP代码。 引用自：[PHP调试工具Xdebug安装配置教程] (http://www.cnblogs.com/qiantuwuliang/archive/2011/01/23/1942382.html) 我们可以在xdebug.org（自备梯子）上面下载到PHP各个版本的xdebug dll使用。\n不过当我打开phpStudy的php-ini打算手动开启debug的时候，非常高兴得发现已经phpStudy已自带了对应版本的xdebug，而且路径都配好了。\nphpStudy的php.ini在“其他选项-打开配置文件-php-ini”，如下图：\n把文档拉到最后，看得到xdebug的配置如下：\nphpStudy已经帮我们配置好xdebug dll的路径了，我们只需要手动在zend_extension上面添加远程调试和自动启动配置即可，代码如下：\n1 2 3 xdebug.remote_enable = 1 xdebug.remote_autostart= 1 完整配置如下：\n1 2 3 4 5 6 7 [XDebug] ;xdebug.profiler_output_dir=\u0026#34;C:\\phpStudy\\tmp\\xdebug\u0026#34; ;xdebug.trace_output_dir=\u0026#34;C:\\phpStudy\\tmp\\xdebug\u0026#34; xdebug.remote_enable = 1 xdebug.remote_autostart= 1 ;你的PHP版本的php_xdebug.dll，phpStudy自动设置的 zend_extension=\u0026#34;C:\\phpStudy\\php\\php-5.5.38\\ext\\php_xdebug.dll\u0026#34; 保存文件，重启一下phpStudy服务。\nVisual Studio Code 设置用户配置和调试配置 这个时候，我们随便在PHP文件夹中打开vs code，vs code会自动提示我们：Cannot validate since no PHP executable is set. Use the setting \u0026lsquo;php.validate.executablePath\u0026rsquo; to configure the PHP executable.\n嗯，没有设置PHP执行文件，可以通过设置php.validate.executablePath属性来配置它。\n这个在哪配置呢？在“文件-首选项-设置”，打开之后如下图：\n这个php.validate.executablePath对应就是当前phpStudy中运行的php.exe的路径，可以在phpStudy-其他选项菜单-打开文件位置-PHP中找到此路径。\n保存好了之后，回到Visual Studio Code界面，转到Debug，选择添加配置，之后选择PHP，生成如下图的launch.json：\n不用改任何东西，直接开撸\u0026hellip;\n开启Debug 确保phpStudy启动了，网站也正常运行起来了,然后在Visual Studio Code中启动调试，打上要的断点，接着启动调试。\n如下图：\n接着访问你要调试的页面对应的PHP代码，打上你的断点，华丽丽的Debug出来了\u0026hellip;\nF10单步调试，F11跳入函数，F5直接运行之类的快捷键自己玩吧。\n其他运行环境下的配置 基本没什么区别，配置php.ini，下载到对应版本的xdebug.dll，php.validate.executablePath配置正确就完事。\n其他参考链接：\n如何使用XDebug调试php\nXAMPP环境下用phpStorm+XDebug进行断点调试的配置\nPHPStorm下XDebug配置\nPS:果然是世界上最好的语言\u0026hellip;(逃 ","date":"2017-03-17T00:00:00Z","permalink":"https://liguobao.github.io/p/%E7%94%A8visual-studio-code-debug%E4%B8%96%E7%95%8C%E4%B8%8A%E6%9C%80%E5%A5%BD%E7%9A%84%E8%AF%AD%E8%A8%80/","title":"用Visual Studio Code Debug世界上最好的语言"},{"content":"手把手教你用.NET Core写爬虫 写在前面 自从上一个项目58HouseSearch从.NET迁移到.NET core之后，磕磕碰碰磨蹭了一个月才正式上线到新版本。 然后最近又开了个新坑，搞了个Dy2018Crawler用来爬dy2018电影天堂上面的电影资源。这里也借机简单介绍一下如何基于.NET Core写一个爬虫。 PS：如有偏错，敬请指明\u0026hellip; PPS:该去电影院还是多去电影院，毕竟美人良时可无价。\n准备工作（.NET Core准备） 首先，肯定是先安装.NET Core咯。下载及安装教程在这里：.NET - Powerful Open Source Development。无论你是Windows、linux还是mac，统统可以玩。\n我这里的环境是：Windows10 + VS2015 community updata3 + .NET Core 1.1.0 SDK + .NET Core 1.0.1 tools Preview 2.\n理论上，只需要安装一下 .NET Core 1.1.0 SDK 即可开发.NET Core程序，至于用什么工具写代码都无关紧要了。\n安装好以上工具之后，在VS2015的新建项目就可以看到.NET Core的模板了。如下图：\n为了简单起见，我们创建的时候，直接选择VS .NET Core tools自带的模板。\n一个爬虫的自我修养 分析网页 写爬虫之前，我们首先要先去了解一下即将要爬取的网页数据组成。\n具体到网页的话，便是分析我们要抓取的数据在HTML里面是用什么标签抑或有什么样的标记，然后使用这个标记把数据从HTML中提取出来。在我这里的话，用的更多的是HTML标签的ID和CSS属性。\n以本文章想要爬取的dy2018.com为例,简单描述一下这个过程。dy2018.com主页如下图：\n在chrome里面，按F12进入开发者模式，接着如下图使用鼠标选择对应页面数据，然后去分析页面HTML组成。\n接着我们开始分析页面数据:\n经过简单分析HTML，我们得到以下结论：\nwww.dy2018.com首页的电影数据存储在一个class为co_content222的div标签里面\n电影详情链接为a标签，标签显示文本就是电影名称，URL即详情URL\n那么总结下来，我们的工作就是：找到class=\u0026lsquo;co_content222\u0026rsquo; 的div标签，从里面提取所有的a标签数据。\n开始写代码\u0026hellip; 之前在写58HouseSearch项目迁移到asp.net core简单提过AngleSharp库，一个基于.NET（C#）开发的专门为解析xHTML源码的DLL组件。\nAngleSharp主页在这里：https://anglesharp.github.io/，\n博客园文章：解析HTML利器AngleSharp介绍，\nNuget地址:Nuget AngleSharp 安装命令：Install-Package AngleSharp\n获取电影列表数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 private static HtmlParser htmlParser = new HtmlParser(); private ConcurrentDictionary\u0026lt;string, MovieInfo\u0026gt; _cdMovieInfo = new ConcurrentDictionary\u0026lt;string, MovieInfo\u0026gt;(); private void AddToHotMovieList() { //此操作不阻塞当前其他操作，所以使用Task // _cdMovieInfo 为线程安全字典，存储了当期所有的电影数据 Task.Factory.StartNew(()=\u0026gt; { try { //通过URL获取HTML var htmlDoc = HTTPHelper.GetHTMLByURL(\u0026#34;http://www.dy2018.com/\u0026#34;); //HTML 解析成 IDocument var dom = htmlParser.Parse(htmlDoc); //从dom中提取所有class=\u0026#39;co_content222\u0026#39;的div标签 //QuerySelectorAll方法接受 选择器语法 var lstDivInfo = dom.QuerySelectorAll(\u0026#34;div.co_content222\u0026#34;); if (lstDivInfo != null) { //前三个DIV为新电影 foreach (var divInfo in lstDivInfo.Take(3)) { //获取div中所有的a标签且a标签中含有\u0026#34;/i/\u0026#34;的 //Contains(\u0026#34;/i/\u0026#34;) 条件的过滤是因为在测试中发现这一块div中的a标签有可能是广告链接 divInfo.QuerySelectorAll(\u0026#34;a\u0026#34;).Where(a =\u0026gt; a.GetAttribute(\u0026#34;href\u0026#34;).Contains(\u0026#34;/i/\u0026#34;)).ToList().ForEach( a =\u0026gt; { //拼接成完整链接 var onlineURL = \u0026#34;http://www.dy2018.com\u0026#34; + a.GetAttribute(\u0026#34;href\u0026#34;); //看一下是否已经存在于现有数据中 if (!_cdMovieInfo.ContainsKey(onlineURL)) { //获取电影的详细信息 MovieInfo movieInfo = FillMovieInfoFormWeb(a, onlineURL); //下载链接不为空才添加到现有数据 if (movieInfo.XunLeiDownLoadURLList != null \u0026amp;\u0026amp; movieInfo.XunLeiDownLoadURLList.Count != 0) { _cdMovieInfo.TryAdd(movieInfo.Dy2018OnlineUrl, movieInfo); } } }); } } } catch(Exception ex) { } }); } 获取电影详细信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 private MovieInfo FillMovieInfoFormWeb(AngleSharp.Dom.IElement a, string onlineURL) { var movieHTML = HTTPHelper.GetHTMLByURL(onlineURL); var movieDoc = htmlParser.Parse(movieHTML); //http://www.dy2018.com/i/97462.html 分析过程见上，不再赘述 //电影的详细介绍 在id为Zoom的标签中 var zoom = movieDoc.GetElementById(\u0026#34;Zoom\u0026#34;); //下载链接在 bgcolor=\u0026#39;#fdfddf\u0026#39;的td中，有可能有多个链接 var lstDownLoadURL = movieDoc.QuerySelectorAll(\u0026#34;[bgcolor=\u0026#39;#fdfddf\u0026#39;]\u0026#34;); //发布时间 在class=\u0026#39;updatetime\u0026#39;的span标签中 var updatetime = movieDoc.QuerySelector(\u0026#34;span.updatetime\u0026#34;); var pubDate = DateTime.Now; if(updatetime!=null \u0026amp;\u0026amp; !string.IsNullOrEmpty(updatetime.InnerHtml)) { //内容带有“发布时间：”字样，replace成\u0026#34;\u0026#34;之后再去转换，转换失败不影响流程 DateTime.TryParse(updatetime.InnerHtml.Replace(\u0026#34;发布时间：\u0026#34;, \u0026#34;\u0026#34;), out pubDate); } var movieInfo = new MovieInfo() { //InnerHtml中可能还包含font标签，做多一个Replace MovieName = a.InnerHtml.Replace(\u0026#34;\u0026lt;font color=\\\u0026#34;#0c9000\\\u0026#34;\u0026gt;\u0026#34;,\u0026#34;\u0026#34;).Replace(\u0026#34;\u0026lt;font color=\\\u0026#34;\t#0c9000\\\u0026#34;\u0026gt;\u0026#34;,\u0026#34;\u0026#34;).Replace(\u0026#34;\u0026lt;/font\u0026gt;\u0026#34;, \u0026#34;\u0026#34;), Dy2018OnlineUrl = onlineURL, MovieIntro = zoom != null ? WebUtility.HtmlEncode(zoom.InnerHtml) : \u0026#34;暂无介绍...\u0026#34;,//可能没有简介，虽然好像不怎么可能 XunLeiDownLoadURLList = lstDownLoadURL != null ? lstDownLoadURL.Select(d =\u0026gt; d.FirstElementChild.InnerHtml).ToList() : null,//可能没有下载链接 PubDate = pubDate, }; return movieInfo; } HTTPHelper 这边有个小坑，dy2018网页编码格式是GB2312,.NET Core默认不支持GB2312，使用Encoding.GetEncoding(\u0026ldquo;GB2312\u0026rdquo;)的时候会抛出异常。\n解决方案是手动安装System.Text.Encoding.CodePages包(Install-Package System.Text.Encoding.CodePages),\n然后在Starup.cs的Configure方法中加入Encoding.RegisterProvider(CodePagesEncodingProvider.Instance),接着就可以正常使用Encoding.GetEncoding(\u0026ldquo;GB2312\u0026rdquo;)了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 using System; using System.Net.Http; using System.Net.Http.Headers; using System.Text; namespace Dy2018Crawler { public class HTTPHelper { public static HttpClient Client { get; } = new HttpClient(); public static string GetHTMLByURL(string url) { try { System.Net.WebRequest wRequest = System.Net.WebRequest.Create(url); wRequest.ContentType = \u0026#34;text/html; charset=gb2312\u0026#34;; wRequest.Method = \u0026#34;get\u0026#34;; wRequest.UseDefaultCredentials = true; // Get the response instance. var task = wRequest.GetResponseAsync(); System.Net.WebResponse wResp = task.Result; System.IO.Stream respStream = wResp.GetResponseStream(); //dy2018这个网站编码方式是GB2312, using (System.IO.StreamReader reader = new System.IO.StreamReader(respStream, Encoding.GetEncoding(\u0026#34;GB2312\u0026#34;))) { return reader.ReadToEnd(); } } catch (Exception ex) { Console.WriteLine(ex.ToString()); return string.Empty; } } } } 定时任务的实现 定时任务我这里使用的是Pomelo.AspNetCore.TimedJob。\nPomelo.AspNetCore.TimedJob是一个.NET Core实现的定时任务job库，支持毫秒级定时任务、从数据库读取定时配置、同步异步定时任务等功能。\n由.NET Core社区大神兼前微软MVPAmamiyaYuuko(入职微软之后就卸任MVP\u0026hellip;)开发维护，不过好像没有开源，回头问下看看能不能开源掉。\nnuget上有各种版本，按需自取。地址：https://www.nuget.org/packages/Pomelo.AspNetCore.TimedJob/1.1.0-rtm-10026\n作者自己的介绍文章：Timed Job - Pomelo扩展包系列\nStartup.cs相关代码 我这边使用的话，首先肯定是先安装对应的包：Install-Package Pomelo.AspNetCore.TimedJob -Pre\n然后在Startup.cs的ConfigureServices函数里面添加Service,在Configure函数里面Use一下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // This method gets called by the runtime. Use this method to add services to the container. public void ConfigureServices(IServiceCollection services) { // Add framework services. services.AddMvc(); //Add TimedJob services services.AddTimedJob(); } public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { //使用TimedJob app.UseTimedJob(); if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); app.UseBrowserLink(); } else { app.UseExceptionHandler(\u0026#34;/Home/Error\u0026#34;); } app.UseStaticFiles(); app.UseMvc(routes =\u0026gt; { routes.MapRoute( name: \u0026#34;default\u0026#34;, template: \u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); Encoding.RegisterProvider(CodePagesEncodingProvider.Instance); } Job相关代码 接着新建一个类，明明为XXXJob.cs,引用命名空间using Pomelo.AspNetCore.TimedJob，XXXJob继承于Job，添加以下代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class AutoGetMovieListJob:Job { // Begin 起始时间；Interval执行时间间隔，单位是毫秒，建议使用以下格式，此处为3小时；SkipWhileExecuting是否等待上一个执行完成，true为等待； [Invoke(Begin = \u0026#34;2016-11-29 22:10\u0026#34;, Interval = 1000 * 3600*3, SkipWhileExecuting =true)] public void Run() { //Job要执行的逻辑代码 //LogHelper.Info(\u0026#34;Start crawling\u0026#34;); //AddToLatestMovieList(100); //AddToHotMovieList(); //LogHelper.Info(\u0026#34;Finish crawling\u0026#34;); } } 项目发布相关 新增runtimes节点 使用VS2015新建的模板工程，project.json配置默认是没有runtimes节点的.\n我们想要发布到非Windows平台的时候，需要手动配置一下此节点以便生成。\n1 2 3 4 5 6 7 8 \u0026#34;runtimes\u0026#34;: { \u0026#34;win7-x64\u0026#34;: {}, \u0026#34;win7-x86\u0026#34;: {}, \u0026#34;osx.10.10-x64\u0026#34;: {}, \u0026#34;osx.10.11-x64\u0026#34;: {}, \u0026#34;ubuntu.14.04-x64\u0026#34;: {} } 删除/注释scripts节点 生成时会调用node.js脚本构建前端代码，这个不能确保每个环境都有bower存在\u0026hellip;注释完事。\n1 2 3 4 5 //\u0026#34;scripts\u0026#34;: { // \u0026#34;prepublish\u0026#34;: [ \u0026#34;bower install\u0026#34;, \u0026#34;dotnet bundle\u0026#34; ], // \u0026#34;postpublish\u0026#34;: [ \u0026#34;dotnet publish-iis --publish-folder %publish:OutputPath% --framework %publish:FullTargetFramework%\u0026#34; ] //}, 删除/注释dependencies节点里面的type 1 2 3 4 5 \u0026#34;dependencies\u0026#34;: { \u0026#34;Microsoft.NETCore.App\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.1.0\u0026#34; //\u0026#34;type\u0026#34;: \u0026#34;platform\u0026#34; }, project.json的相关配置说明可以看下这个官方文档：Project.json-file, 或者张善友老师的文章.NET Core系列 ： 2 、project.json 这葫芦里卖的什么药\n开发编译发布 1 2 3 4 5 //还原各种包文件 dotnet restore; //发布到C:\\code\\website\\Dy2018Crawler文件夹 dotnet publish -r ubuntu.14.04-x64 -c Release -o \u0026#34;C:\\code\\website\\Dy2018Crawler\u0026#34;; 最后，照旧开源\u0026hellip;\u0026hellip;以上代码都在下面找到：\nGayhub地址：https://github.com/liguobao/Dy2018Crawler\n在线地址：http://codelover.win/\nPS:回头写个爬片大家滋持不啊\u0026hellip;\n","date":"2016-12-04T00:00:00Z","permalink":"https://liguobao.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E7%94%A8.net-core%E5%86%99%E7%88%AC%E8%99%AB/","title":"手把手教你用.NET Core写爬虫"},{"content":"自动同步git repository脚本 由于平时偶尔需要merge不同分支代码到正式版本用于发布版本，merge前就需要先把各种分支代码更新到最新，接着再去做merge工作。\n经常使用的分支其实不算太多，不过仓库倒是有好几个。来来去去写命令行或者GUI操作多了觉得有点繁琐，就琢磨来写个脚本做吧。\nPS：偷懒是人类进步的动力\u0026hellip;\n找了下资料，无外乎就是bat/sh脚本调用git cmd,之前写过bat命令，所以一开始是走这个思路的。\n不料在PATH上配置好了git bin的路径之后，使用git命令没问题了，不过pull rebase的时候提示publickey无效。可是我的publickey一直都在.ssh里面,不存在无效的问题\u0026hellip;\n懒得纠结，换shell吧。\n参考资料：\n请问如何写一个批处理自动打开 gitbash，然后自动执行一系列git命令（windows平台）？\nShow Code 使用shell就更好玩了，直接把git bash运行的命令扔到.sh文件里面就完事了。所以\u0026hellip;如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 printf \u0026#34;Start rebase 58HouseSearch. \\r\\n\u0026#34; cd ./58HouseSearch; git checkout master; git pull --rebase origin master; printf \u0026#34;Finish Pull Rebase 58HouseSearch release and master.\\r\\n\u0026#34; read -p \u0026#34;Press any key to continue.\u0026#34;; cd ..; printf \u0026#34;Start rebase hexoforblog;\\r\\n\u0026#34; cd ./hexoforblog; git checkout master; git pull --rebase origin master; git checkout master; printf \u0026#34;Finish Pull Rebase hexoforblog.\\r\\n\u0026#34; read -p \u0026#34;Press any key to continue.\u0026#34;; cd ..; 说明：\nprintf 为打印函数，就像C语言那样用就好； read -p \u0026ldquo;Press any key to continue.\u0026rdquo;; 这个是接受输入，结合起来可以做更复杂的行为咯。 输出内容和我们在git bash里面操作是一致的。 ","date":"2016-11-25T00:00:00Z","permalink":"https://liguobao.github.io/p/%E8%87%AA%E5%8A%A8%E5%90%8C%E6%AD%A5git-repository%E8%84%9A%E6%9C%AC/","title":"自动同步git repository脚本"},{"content":"ASP.NET MVC 微信JS-SDK认证 写在前面 前阵子因为有个项目需要做微信自定义分享功能，因而去研究了下微信JS-SDK相关知识。\n此文做个简单的记(tu)录(cao)\u0026hellip;\n开始 所有的东西都从文档开始:微信JSSDK说明文档\n项目需要用到的是分享接口 不过使用微信JS-SDK之前，需要做JS接口认证。\n认证如下：\n步骤一：绑定域名\n步骤二：引入JS文件\n步骤三：通过config接口注入权限验证配置\n步骤四：通过ready接口处理成功验证\n步骤五：通过error接口处理失败验证\n步骤一中允许使用域名/子域名，只要xx.com/xxx.txt或者xx.com/mp/xxx.txt能访问就好。域名认证通过之后，此域名下的所有端口的网站都可以使用JS-SDK。\n步骤二没什么问题，略过。\n步骤三最磨人，下面单独讲解。\nconfig接口注入权限验证配置 先来一段说明：\n所有需要使用JS-SDK的页面必须先注入配置信息，否则将无法调用 （同一个url仅需调用一次，对于变化url的SPA的web app可在每次url变化时进行调用, 目前Android微信客户端不支持pushState的H5新特性， 所以使用pushState来实现web app的页面会导致签名失败，此问题会在Android6.2中修复）。\n1 2 3 4 5 6 7 8 9 wx.config({ debug: true, // 开启调试模式,调用的所有api的返回值会在客户端alert出来， //若要查看传入的参数，可以在pc端打开，参数信息会通过log打出，仅在pc端时才会打印。 appId: \u0026#39;\u0026#39;, // 必填，公众号的唯一标识 timestamp: , // 必填，生成签名的时间戳 nonceStr: \u0026#39;\u0026#39;, // 必填，生成签名的随机串 signature: \u0026#39;\u0026#39;,// 必填，签名，见附录1 jsApiList: [] // 必填，需要使用的JS接口列表，所有JS接口列表见附录2 }); 看到这里肯定懵逼了，这是都什么鬼\u0026hellip;怎么玩啊。\n提示我们去看附录1\u0026hellip;看完之后总结如下：\n使用config接口注入权限验证配置，重点是生成合法的signatrue 生成signature需要通过appid和secret获取token 时间戳和调用接口URL必不可少 此操作需要服务端完成，不能使用客户端实现 整个过程变成：\n通过appid和secret获取access_token，接着使用token获取jsapi_ticket；\n拿到jsapi_ticket之后，把jsapi_ticket、时间戳、随机字符串、接口调用页面URL 拼接成完整字符串，使用sha1算法加密得到signature。\n最后返回至页面，在wx.config里面填入appid，上一步的时间戳timestamp，上一部的随机字符串、sha1拿到的signature，想要使用的JS接口。\n废话少说，直接上代码吧。\n代码时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 public class WeiXinController : Controller { public static readonly string appid = System.Web.Configuration.WebConfigurationManager.AppSettings[\u0026#34;wxappid\u0026#34;]; public static readonly string secret = System.Web.Configuration.WebConfigurationManager.AppSettings[\u0026#34;wxsecret\u0026#34;]; public static readonly bool isDedug = System.Web.Configuration.WebConfigurationManager.AppSettings[\u0026#34;IsDebug\u0026#34;] ==\u0026#34;true\u0026#34;; public static string _ticket = \u0026#34;\u0026#34;; public static DateTime _lastTimestamp; public ActionResult Info(string url,string noncestr) { if (string.IsNullOrEmpty(_ticket) || _lastTimestamp == null || (_lastTimestamp - DateTime.Now).Milliseconds \u0026gt; 7200) { var resultString = HTTPHelper.GetHTMLByURL(\u0026#34;https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential\u0026amp;appid=\u0026#34; + appid + \u0026#34;\u0026amp;secret=\u0026#34; + secret); dynamic resultValue = JsonConvert.DeserializeObject\u0026lt;dynamic\u0026gt;(resultString); if (resultValue == null || resultValue.access_token == null || resultValue.access_token.Value == null) { return Json(new { issuccess = false, error = \u0026#34;获取token失败\u0026#34; }); } var token = resultValue.access_token.Value; resultString = HTTPHelper.GetHTMLByURL (\u0026#34;https://api.weixin.qq.com/cgi-bin/ticket/getticket?access_token=\u0026#34; + token + \u0026#34;\u0026amp;type=jsapi\u0026#34;); dynamic ticketValue = JsonConvert.DeserializeObject\u0026lt;dynamic\u0026gt;(resultString); if (ticketValue == null || ticketValue.errcode == null || ticketValue.errcode.Value != 0 || ticketValue.ticket == null) return Json(new { issuccess = false, error = \u0026#34;获取ticketValue失败\u0026#34; }); _ticket = ticketValue.ticket.Value; _lastTimestamp = DateTime.Now; var timestamp = GetTimeStamp(); var hexString = string.Format(\u0026#34;jsapi_ticket={0}\u0026amp;noncestr={3}\u0026amp;timestamp={1}\u0026amp;url={2}\u0026#34;, _ticket, timestamp, url,noncestr); return Json(new { issuccess = true, sha1value = GetSHA1Value(hexString), timestamp = timestamp, url = url, appid = appid, debug=isDedug, tiket=_ticket }); } else { var timestamp = GetTimeStamp(); var hexString = string.Format(\u0026#34;jsapi_ticket={0}\u0026amp;noncestr=1234567890123456\u0026amp;timestamp={1}\u0026amp;url={2}\u0026#34;, _ticket, timestamp, url); return Json(new { issuccess = true, sha1value = GetSHA1Value(hexString), timestamp = timestamp, url = url, appid = appid, debug = isDedug,tiket = _ticket }); } } private string GetSHA1Value(string sourceString) { var hash = SHA1.Create().ComputeHash(Encoding.UTF8.GetBytes(sourceString)); return string.Join(\u0026#34;\u0026#34;, hash.Select(b =\u0026gt; b.ToString(\u0026#34;x2\u0026#34;)).ToArray()); } private static string GetTimeStamp() { TimeSpan ts = DateTime.Now - new DateTime(1970, 1, 1, 0, 0, 0, 0); return Convert.ToInt64(ts.TotalSeconds).ToString(); } } public class HTTPHelper { public static string GetHTMLByURL(string url) { string htmlCode = string.Empty; try { HttpWebRequest webRequest = (System.Net.HttpWebRequest)System.Net.WebRequest.Create(url); webRequest.Timeout = 30000; webRequest.Method = \u0026#34;GET\u0026#34;; webRequest.UserAgent = \u0026#34;Mozilla/4.0\u0026#34;; webRequest.Headers.Add(\u0026#34;Accept-Encoding\u0026#34;, \u0026#34;gzip, deflate\u0026#34;); HttpWebResponse webResponse = (System.Net.HttpWebResponse)webRequest.GetResponse(); //获取目标网站的编码格式 string contentype = webResponse.Headers[\u0026#34;Content-Type\u0026#34;]; Regex regex = new Regex(\u0026#34;charset\\\\s*=\\\\s*[\\\\W]?\\\\s*([\\\\w-]+)\u0026#34;, RegexOptions.IgnoreCase); if (webResponse.ContentEncoding.ToLower() == \u0026#34;gzip\u0026#34;)//如果使用了GZip则先解压 { using (System.IO.Stream streamReceive = webResponse.GetResponseStream()) { using (var zipStream = new System.IO.Compression.GZipStream(streamReceive, System.IO.Compression.CompressionMode.Decompress)) { //匹配编码格式 if (regex.IsMatch(contentype)) { Encoding ending = Encoding.GetEncoding (regex.Match(contentype).Groups[1].Value.Trim()); using (StreamReader sr = new System.IO.StreamReader(zipStream, ending)) { htmlCode = sr.ReadToEnd(); } } else { using (StreamReader sr = new System.IO.StreamReader(zipStream, Encoding.UTF8)) { htmlCode = sr.ReadToEnd(); } } } } } else { using (System.IO.Stream streamReceive = webResponse.GetResponseStream()) { var encoding = Encoding.Default; if (contentype.Contains(\u0026#34;utf\u0026#34;)) encoding = Encoding.UTF8; using (System.IO.StreamReader sr = new System.IO.StreamReader(streamReceive, encoding)) { htmlCode = sr.ReadToEnd(); } } } return htmlCode; } catch (Exception ex) { return \u0026#34;\u0026#34;; } } } PS：这里要注意缓存一下_ticket（即access_token），照微信文档说的，access_token两个小时内有效，不需要频繁调用。而且获取access_token的接口有调用次数的限制，如果超过了次数，就不允许调用了。\nPPS:建议noncestr和URL由前台传入比较适合，使用 var theWebUrl = window.location.href.split(\u0026rsquo;#\u0026rsquo;)[0] 获取URL，noncestr就随意了。\nPPPS:遇到诡异的invalid signature的时候，首先检查url参数，然后检查noncestr，再不行重启一下程序获取一个新的token回来继续玩。\n","date":"2016-11-01T00:00:00Z","permalink":"https://liguobao.github.io/p/asp.net-mvc-%E5%BE%AE%E4%BF%A1js-sdk%E8%AE%A4%E8%AF%81/","title":"ASP.NET MVC 微信JS-SDK认证"},{"content":"写在前面 最早接触javascript的时候，javascript代码直接扔在script标签里面就完事了。\n反正代码不多，交互简单，逻辑不难，和HTML混在一起也未尝不可。\n后来交互越来越复杂，代码越多越多了，我们就开始把JS代码独立到了单独的JS文件中。\n公共的库引用在前，自己的逻辑代码引用在后，全局变量定义在HTML内部，在独立JS文件中直接使用变量就好。\n我们会经常看到下面这种代码：\n1 2 3 4 5 6 \u0026lt;script src=\u0026#34;1.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;2.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;3.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;4.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;5.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;6.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 通过script标签顺序去js管理依赖关系。\n阮一峰老师在Javascript模块化编程（三）：require.js的用法 一文中总结了这样写法的缺点：\n1 2 3 4 5 首先，加载的时候，浏览器会停止网页渲染，加载文件越多，网页失去响应的时间就会越长； 其次，由于js文件之间存在依赖关系，因此必须严格保证加载顺序（比如上例的1.js要在2.js的前面），依赖性最大的模块一定要放到最后加载. 当依赖关系很复杂的时候，代码的编写和维护都会变得困难。 而requirejs的诞生便是为了解决这个问题。\nrequirejs 在官网把requirejs 下载回来之后。使用一般的方法引入：\n1 \u0026lt;script src=\u0026#34;js/require.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 但是这样的方法，还是可能在加载require.js的时候导致网页失去响应。解决方案一般有两种：\n把上面的代码放到网页底部\n使用异步的方法加载，如下：\n1 \u0026lt;script src=\u0026#34;js/require.js\u0026#34; defer async=\u0026#34;true\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; async属性 表明这个文件需要异步加载，避免网页失去响应。\n不过IE下不支持这个属性，只支持defer，所以可以把defer也写上。\n加载主模块 在上一步，我们已经引入了require了，那么require怎么知道我们究竟要加载什么东西呢？答案是使用data-main属性。 假设我们的主模块为js/home.js,引入代码应该如下：\n1 2 \u0026lt;script src=\u0026#34;js/require.js\u0026#34; data-main=\u0026#34;js/home\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; //require.js默认文件后缀为js，所以home.js可以写成home。 接下来我使用58HouseSearch 的代码来讲解重构过程。\n在此项目里面，重构前大概就是JS变量漫天飞，js文件里面各种函数到处乱放。一开始用起来还没什么，后来加入了更多功能的时候，JS代码维护起来就疼不欲生了。因此托了个小伙伴帮忙使用模块化思想重构了一下JS代码。\n上面说了，我们首先需要创建我们的模块，在这个项目里面，主模块叫home.js。\nhome.js中我们需要配置一下require.config.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 require.config({ baseUrl: \u0026#39;/DomainJS/\u0026#39;, paths: { jquery: \u0026#34;lib/jquery-1.11.3.min\u0026#34;, \u0026#34;AMUI\u0026#34;: \u0026#34;lib/amazeui.2.7.1.min\u0026#34;, \u0026#34;jquery.range\u0026#34;: \u0026#34;lib/jquery.range\u0026#34;, \u0026#34;es5\u0026#34;: \u0026#34;lib/es5\u0026#34;, \u0026#34;mapController\u0026#34;: \u0026#34;mapController\u0026#34;, \u0026#34;addToolbar\u0026#34;: \u0026#34;addToolbar\u0026#34;, }, shim: { \u0026#34;addToolbar\u0026#34;: { deps: [\u0026#34;jquery\u0026#34;] }, \u0026#34;jquery.range\u0026#34;: { deps: [\u0026#34;jquery\u0026#34;] } } }); 在这里我主要配置了一下baseURL(所有模块的查找根路径)，paths(名称映射)，shim( 为那些没有使用define()来声明依赖关系、设置模块的\u0026quot;浏览器全局变量注入\u0026quot;型脚本做依赖和导出配置。)\n关于require.config的详细内容可以看下下面这些文章：\nRequireJS进阶:配置文件的学习 RequireJS进阶:模块的优化及配置的详解 配置做完了，我们也可以开始真正写我们的逻辑代码了,我们使用require来加载我们需要的库。 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 require([\u0026#39;domready!\u0026#39;, \u0026#39;jquery\u0026#39;, \u0026#39;AMUI\u0026#39;, \u0026#39;mapController\u0026#39;, \u0026#39;city\u0026#39;, \u0026#39;commuteGo\u0026#39;], function (doc, $, AMUI, mapController, city, commuteGo) { city.initAllCityInfo(); mapController.init(); $(\u0026#34;input[name=\u0026#39;locationType\u0026#39;]\u0026#34;).bind(\u0026#39;click\u0026#39;, mapController.locationMethodOnChange) $(\u0026#34;input[name=\u0026#39;vehicle\u0026#39;]\u0026#34;).bind(\u0026#39;click\u0026#39;, commuteGo.go) $(\u0026#39;#Get58Data\u0026#39;).bind(\u0026#39;click\u0026#39;, function(e) { e.preventDefault(); mapController.Get58DataClick(); e.stopPropagation(); }); $.ajax({ type: \u0026#34;post\u0026#34;, url: \u0026#34;../Commom/GetPVCount\u0026#34;, data: { }, success: function (result) { if (result.IsSuccess){ $(\u0026#34;#lblPVCount\u0026#34;).text(result.PVCount); }else { $(\u0026#34;#lblPVCount\u0026#34;).text(0); console.log(result.Error); } } }); $(\u0026#39;#search-offcanvas\u0026#39;).offCanvas({ effect: \u0026#39;overlay\u0026#39; }); $(\u0026#34;.amap-sug-result\u0026#34;).css(\u0026#34;z-index\u0026#34;, 9999); }) 忽略function里面的具体逻辑，加载如下：\n1 2 3 4 5 6 require([\u0026#39;domready!\u0026#39;, \u0026#39;jquery\u0026#39;, \u0026#39;AMUI\u0026#39;, \u0026#39;mapController\u0026#39;, \u0026#39;city\u0026#39;, \u0026#39;commuteGo\u0026#39;], function (doc, $, AMUI, mapController, city, commuteGo){ //todo }); 第一个参数为一个数组，表示所依赖的模块，此处为[\u0026lsquo;domready!\u0026rsquo;, \u0026lsquo;jquery\u0026rsquo;, \u0026lsquo;AMUI\u0026rsquo;, \u0026lsquo;mapController\u0026rsquo;, \u0026lsquo;city\u0026rsquo;, \u0026lsquo;commuteGo\u0026rsquo;]；\n第二个参数为回调函数，当前面指定的模块都全部加载成功之后，便调用此函数。加载的模块会以参数形式传入此函数，从而在回调函数内部就可以使用这些模块啦。\nrequire()异步加载所需模块的时候，此时浏览器并不会失去响应；当前面的模块加载成功之后，执行回调函数才会运行我们的逻辑代码，因此解决了依赖性问题。\n讲完了模块加载，我们下面讲一下模块编写。\nAMD模块编写 require.js加载的模块的采用的AMD规范。所以我们的模块必须按照AMD的规定来写。\n关于AMD规范详情可以看这个文章：Javascript模块化编程（二）：AMD规范\n模块有两个情况，不依赖其他模块和依赖其他模块。\n不依赖其他模块 直接define定义，使用function回调。\n58HouseSearch/DomainJS/helper.js\n1 2 3 4 5 6 7 8 9 10 11 12 define(function () { //获取URL中的参数 var getQueryString= function (name) { var reg = new RegExp(\u0026#34;(^|\u0026amp;)\u0026#34; + name + \u0026#34;=([^\u0026amp;]*)(\u0026amp;|$)\u0026#34;); var r = window.location.search.substr(1).match(reg); if (r != null) return unescape(r[2]); return null; } return { getQueryString: getQueryString, }; }) 依赖其他模块 define中如同require一样，用数组表明需要加载的模块，function回调。\n58HouseSearch/DomainJS/marker.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 define([\u0026#39;mapSignleton\u0026#39;, \u0026#39;city\u0026#39;, \u0026#39;transfer\u0026#39;], function(mapSignleton, city, transfer) { var _map = mapSignleton.map; var _workMarker = null; var _markerArray = []; var load = function(x, y, locationName) { _workMarker = new AMap.Marker({ map: _map, title: locationName, icon: \u0026#39;http://webapi.amap.com/theme/v1.3/markers/n/mark_r.png\u0026#39;, position: [x, y] }); } var add = function(address, rent, href, markBG) { new AMap.Geocoder({ city: city.name, radius: 1000 }).getLocation(address, function(status, result) { if (status === \u0026#34;complete\u0026#34; \u0026amp;\u0026amp; result.info === \u0026#39;OK\u0026#39;) { var geocode = result.geocodes[0]; var rentMarker = new AMap.Marker({ map: _map, title: address, icon: markBG ? \u0026#39;IMG/Little/\u0026#39; + markBG : \u0026#39;http://webapi.amap.com/theme/v1.3/markers/n/mark_b.png\u0026#39;, position: [geocode.location.getLng(), geocode.location.getLat()] }); _markerArray.push(rentMarker); rentMarker.content = \u0026#34;\u0026lt;div\u0026gt;\u0026lt;a target = \u0026#39;_blank\u0026#39; href=\u0026#39;\u0026#34; + href + \u0026#34;\u0026#39;\u0026gt;房源：\u0026#34; + address + \u0026#34; 租金：\u0026#34; + rent + \u0026#34;\u0026lt;/a\u0026gt;\u0026lt;div\u0026gt;\u0026#34; rentMarker.on(\u0026#39;click\u0026#39;, function(e) { transfer.add(e, address); }); } }) }; var clearArray = function() { if (_markerArray \u0026amp;\u0026amp; _markerArray.length \u0026gt; 0) _map.remove(_markerArray); _markerArray = []; } var clear = function() { if (_workMarker) { _map.remove(_workMarker); } } return { load: load, add: add, clearArray: clearArray, clear: clear }; }); 这样的话，一个供require调用的模块也就写好了。\n最后感谢小伙伴Larry Sean 帮忙重构代码。\n全文完。\n","date":"2016-10-22T00:00:00Z","permalink":"https://liguobao.github.io/p/%E4%BD%BF%E7%94%A8requirejs%E7%BC%96%E5%86%99%E6%A8%A1%E5%9D%97%E5%8C%96%E4%BB%A3%E7%A0%81/","title":"使用requirejs编写模块化代码"},{"content":"ctrl+s 保存（这个确实很简单，要说常用，这玩意绝对排名第一）\nctrl+Shift+S 保存所有VS中打开的所有文件\nctrl+O 打开新文件\nctrl+Shift+O 打开项目\nctrl+Shift+A 当前项目中添加新建项\nctrl+F4 关闭当前打开页\nctrl+F6 跳到下一个窗口\nctrl+Shift+F6 跳到前一个打开的窗口\nF12 转到函数定义实现处，或者转到变量定义处（一堆代码中使用这个键确实逻辑会更清晰一点）\nctrl+- 这个相对来说跟F12是配套使用的，F12到函数定义，然后返回原代码中继续查看\nshift+ctrl+- 相对于上一个步骤，这个可以再次转到函数定义的地方\nctrl+tab 页面切换，打开页面过多的话，切换用的还是比较多的\nctrl+F 搜索，查找，功能简单粗暴有的时候比很高效\nctrl+F3 在选中区域搜索\nctrl+K，ctrl+D 整个文档格式化\nctrl+K,ctrl+F 格式化选中部分代码\nctrl+K，ctrl+C 代码注释\nctrl+K，ctrl+U 取消代码注释\nctrl+L 删除，删除当前行或者删除选中行\nShift+Alt+Enter 当前代码区域全屏，再按一次取消全屏\nctrl+M，ctrl+M 写代码都喜欢折叠，折叠之后还是还要打开的，可以试试这个快捷键\nctrl+space 代码补全\nctrl+Enter 假如现在当前行上面添加代码光标跳到当前行的上一行\nctrl+Shift+Enter假如现在当前行下面添加代码光标跳到当前行的下一行\nShift+F12 查找函数或者变量的所有引用\nctrl+g 查找行，跳转到你想要跳转的行数\nctrl+Shift+↑ 向上查找引用\nctrl+Shift+↓ 向下查找引用\nShift+Alt+↑ 向上画一条直线，通常如果拷贝代码的时候有行号可以这样去除\nShift+Alt+↓ 向下画一条直线，同上\nShift+↑ 向上选中代码区域\nShift+↓ 向下选中代码区域\n","date":"2016-10-14T00:00:00Z","permalink":"https://liguobao.github.io/p/vs%E5%BF%AB%E6%8D%B7%E9%94%AE/","title":"VS快捷键"},{"content":"58HouseSearch项目迁移到asp.net core 58HouseSearch这个项目原本是基于ASP.NET MVC 4写的，开发环境是Windows+VS2015，发布平台是linux+mono+jexus，这样看来整个项目基本已经满足跨平台的需求。\n这样一来，本来我是没什么动力去做迁移的，好好的东西闲着没事干才迁移呢。\n不过，这不国庆了么？穷人不是在家穷游天下么？所以\u0026hellip;真的有点闲着没事干了。\n迁移可行性探讨 项目迁移前，我们还是先来讨论一下迁移可行性。为嘛要进行可行性探讨呢？原因是.NET CORE是一个跨平台的框架，和上一代的.NET存在不兼容。\n个人总结一下，迁移的主要的问题在于：代码不兼容、类库不兼容、严重依赖Windows API或者COM组件等。\n代码不兼容 代码不兼容其实不算麻烦。毕竟代码是活的，你我也是活的，不就是一个改字罢了。花点时间慢慢改，总是能搞掂的。\n类库不兼容,要不就弃用，要不就找替代品。\n严重依赖Windows API或者COM组件\n额？找替代品，找不到可用替代品的话。放弃吧，这个项目别考虑迁移了。\n这个故事告诉我们，做跨平台项目的时候，少点用系统API或者组建。\n回到58HouseSearch项目上面。\n这个项目的代码基本都是我写的，所以重写代码没什么问题。 依赖的类库有下面几个:\nAngleSharp\nNewtonsoft.Json\nlog4net\nAngleSharp是用来解析HTML的类库，用linq的方式来操作HTML，用起来实在爽快。\n如果这货在.net core上不能跑，我应该立马放弃了。 不过，这个实在给力\u0026hellip;\nNewtonsoft.Json\n在这个项目里面主要是用来记录PV数据的，非核心功能，可有可无。不过看了下nuget上的介绍，也是支持.net core的。\n剩下log4net\u0026hellip;嗯，并不支持log4net。不过这个就更加是非核心内容了，直接丢了。 PS:考虑后期加入Nlog替代log4net。\n至于依赖Windows API之类的，在这个项目里面基本没有，所以略过\u0026hellip;\n准备工作 Visual Studio Community 2015 with Update 3 – Free .NET Core SDK .NET Core .NET Core 1.0.1 - VS 2015 Tooling Preview 2 友情提示：\nVisual Studio Community 2015 with Update 3 下载镜像来安装。 错误操作如下： 正确打开方式：\n安装.NET Core SDK和.NET Core之后再安装.NET Core 1.0.1 - VS 2015 Tooling Preview 2\n安装.NET Core 1.0.1 - VS 2015 Tooling Preview 2 这货的可能会报错0x80072f8a未指定的错误\n解决方案见下图：\n详细见链接：安装DotNetCore.1.0.1-VS2015Tools.Preview2.0.2出现0x80072f8a未指定的错误\n上面都弄好之后，理论上在VS2O15-新建项目里面可以看到ASP.NET CORE的模板了。如下图： 项目迁移 新建空白ASP.NET CORE项目 新建好了之后如下图：\nNuget获取引用 https://www.nuget.org/packages/AngleSharp/\nhttps://www.nuget.org/packages/Newtonsoft.Json\n添加Controllers文件夹 然后把之前项目的Controllers拷贝过来，改掉命名空间，去掉无用代码，添加相应引用。\n添加Views文件夹 本项目直接把之前项目的Views拷贝过来是完全没有问题的。\n静态文件处理 asp.net core MVC中的文件结构和asp.net mvc的文件结构略有不同。\nasp.net core MVC在view中“IMG/Little/PaleGreen.png”对应的文件对应于“项目路径/webroot/IMG/Little/PaleGreen.png”；\n而asp.net mvc中，对应路径为“项目/IMG/Little/PaleGreen.png”。\n因而，我们的所有静态文件都应该放到：webroot文件夹下。\n上面的都做完了之后，项目结构如下：\n接下来就是改代码了。\n代码迁移 Startup.cs添加MVC 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class Startup { // This method gets called by the runtime. Use this method to add services to the container. // For more information on how to configure your application, visit http://go.microsoft.com/fwlink/?LinkID=398940 public void ConfigureServices(IServiceCollection services) { //添加MVC框架 services.AddMvc(); } // This method gets called by the runtime. Use this method to configure the HTTP request pipeline. public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { loggerFactory.AddConsole(); if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } //启用静态文件中间件 app.UseStaticFiles(); //启动MVC路由 app.UseMvcWithDefaultRoute(); //设置默认页面 app.UseMvc(routes =\u0026gt; { routes.MapRoute( name: \u0026#34;default\u0026#34;, template: \u0026#34;{controller=House}/{action=Index}/{id?}\u0026#34;); }); } } 改写GetHTMLByURL方法 之前的方法：\n.net core重写了HttpWebRequest，变成了WebRequest,所以上面的代码废了。\n重写如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public static string GetHTMLByURL(string Url, string type = \u0026#34;UTF-8\u0026#34;) { try { Url = Url.ToLower(); System.Net.WebRequest wReq = System.Net.WebRequest.Create(Url); // Get the response instance. System.Net.WebResponse wResp = wReq.GetResponseAsync().Result; System.IO.Stream respStream = wResp.GetResponseStream(); using (System.IO.StreamReader reader = new System.IO. StreamReader(respStream, Encoding.GetEncoding(type))) { return reader.ReadToEnd(); } } catch (System.Exception ex) { return string.Empty; } } 改写Controller代码 嗯，换了命名空间，别的一句都没改直接拉过来了\u0026hellip;略过。\n发布到ubuntu Install for Ubuntu 14.04, 16.04 \u0026amp; Linux Mint 17\n第一步\n1 2 3 4 5 6 7 8 9 10 //Ubuntu 14.04 / Linux Mint 17 sudo sh -c \u0026#39;echo \u0026#34;deb [arch=amd64] https://apt-mo.trafficmanager.net/repos/dotnet-release/ trusty main\u0026#34; \u0026gt; /etc/apt/sources.list.d/dotnetdev.list\u0026#39; sudo apt-key adv --keyserver apt-mo.trafficmanager.net --recv-keys 417A0893 sudo apt-get update //Ubuntu 16.04 sudo sh -c \u0026#39;echo \u0026#34;deb [arch=amd64] https://apt-mo.trafficmanager.net/repos/dotnet-release/ xenial main\u0026#34; \u0026gt; /etc/apt/sources.list.d/dotnetdev.list\u0026#39; sudo apt-key adv --keyserver apt-mo.trafficmanager.net --recv-keys 417A0893 sudo apt-get update 第二步\n1 sudo apt-get install dotnet-dev-1.0.0-preview2-003131 安装好了之后，输入 dotnet -v 应该能看到版本信息，如下图：\n这样的下，一句完成了ubuntu 运行asp.net core的环境搭建了。\nproject.json里面隐藏的坑 dependencies NET Core 1.0.1 - VS 2015 Tooling Preview 2模板的asp.net core 版本和ubuntu 的asp.net core 版本不一致。\n根据微软爸给的教程，我们在ubuntu上安装的.NET Core 1.0.0，见上图。\n然而我们创建项目的模板是.NET Core 1.0.1，见下图:\n怎么办？要不升级ubuntu的asp.net core，要不降级。\n由于没找到.NET Core 1.0.1 ubuntu的安装包，所以我选择了降级到.NET Core 1.0.0.\n其中需要把Microsoft.NETCore.App version 、Microsoft.AspNetCore.Server.Kestrel、Microsoft.AspNetCore.Mvc 这三个节点都改成“1.0.0”。如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026#34;dependencies\u0026#34;: { \u0026#34;Microsoft.NETCore.App\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.0.1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;platform\u0026#34; }, \u0026#34;Microsoft.AspNetCore.Diagnostics\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;Microsoft.AspNetCore.Server.IISIntegration\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;Microsoft.AspNetCore.Server.Kestrel\u0026#34;: \u0026#34;1.0.1\u0026#34;, \u0026#34;Microsoft.Extensions.Logging.Console\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;Microsoft.AspNetCore.Mvc\u0026#34;: \u0026#34;1.0.1\u0026#34;, \u0026#34;Microsoft.AspNetCore.StaticFiles\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;Newtonsoft.Json\u0026#34;: \u0026#34;9.0.1\u0026#34;, \u0026#34;AngleSharp\u0026#34;: \u0026#34;0.9.8.1\u0026#34; }, publishOptions 发布输出包括Views文件夹\n1 2 3 4 5 6 7 \u0026#34;publishOptions\u0026#34;: { \u0026#34;include\u0026#34;: [ \u0026#34;wwwroot\u0026#34;, \u0026#34;web.config\u0026#34;, \u0026#34;Views\u0026#34; ] }, runtimes runtimes 配置为模板运行平台。 详细见链接：https://docs.nuget.org/ndocs/schema/project.json\n1 \u0026#34;runtimes\u0026#34;: { \u0026#34;ubuntu.14.04-x64\u0026#34;: {} } 上面都弄好之后，跑一下看,如下图：\n1 2 3 dotnet restore dotnet run 来个请求看看：\njexus转发/反向代理 ASP.NET Core \u0026ldquo;完整发布,自带运行时\u0026rdquo; 到jexus\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/58housesearch%E9%A1%B9%E7%9B%AE%E8%BF%81%E7%A7%BB%E5%88%B0asp.net-core/","title":"58HouseSearch项目迁移到asp.net core"},{"content":"58同城高德搜房项目JS相关知识 在线地址：58同城品牌公寓高德搜房\nGithub地址：https://github.com/liguobao/58HouseSearch\n知乎专栏(点赞用的)：高德API+Python解决租房问题(.NET版)\n经过了一个星期的修补补，以及小伙伴风险的代码，整个项目基本处于基本稳定运行的状态。\n同时加入了一下新功能：\nIP定位：调用高德地图IP定位功能实现 移动地图中心定位：调用高德地图移动地图定位实现 定位城市名转58同城城市名以获得准确58同城城市域名：抓取58同城城市分类信息 优化数据源、去除广告数据：小伙伴奉献代码 今天主要简单讲解一下其中使用的一些高德地图API接口。\n高德地图JavaScript API 主体为map对象，基本所有的操作都是通过map对象来实现的。 map对象实例化是通过 Amap类来做的。如以下代码：\n1 2 3 4 5 6 map = new AMap.Map(\u0026#34;container\u0026#34;, { resizeEnable: true, zoomEnable: true, center: [121.297428, 31.1345],//经纬度，此处为上海 zoom: 11 }); IP定位 调用Map.CitySearch()获得当前IP所在城市，直接将地图显示成当前城市。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 function showCityInfo(map) { //实例化城市查询类 var citysearch = new AMap.CitySearch(); //自动获取用户IP，返回当前城市 citysearch.getLocalCity(function (status, result) { if (status === \u0026#39;complete\u0026#39; \u0026amp;\u0026amp; result.info === \u0026#39;OK\u0026#39;) { if (result \u0026amp;\u0026amp; result.city \u0026amp;\u0026amp; result.bounds) { var cityinfo = result.city;//获得XX市 var citybounds = result.bounds;//用于设置地图显示位置的实例 cityName = cityinfo.substring(0, cityinfo.length - 1);//去掉市这个字 ConvertCityCNNameToShortCut();//城市名转换成58同城城市域名字母，如上海-\u0026gt;sh,苏州-\u0026gt;su, //下面会有实现代码 document.getElementById(\u0026#39;IPLocation\u0026#39;).innerHTML = \u0026#39;您当前所在城市：\u0026#39; + cityName; //地图显示当前城市 map.setBounds(citybounds); } } else { document.getElementById(\u0026#39;IPLocation\u0026#39;).innerHTML = result.info; } }); } 移动地图自动中心定位 之前有一版是让用户输入城市名，然后直接定位到输入的城市的。 这个功能卡在了设置地图显示位置上，如果是使用高德地图提供的搜索控件的话，又存在输入结果之后搜索结果可能是多个的问题。而且这点我只是要取到用户想要定位的城市而已，感觉没必要做得太复杂。 昨晚在看高德地图API的时候发现，有一个移动地图获得地图中心所在位置的样例，马上眼前一亮了。这个功能比我想要的还要好\u0026hellip;果断上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function MapMoveToLocationCity() { map.on(\u0026#39;moveend\u0026#39;, getCity); function getCity() { map.getCity(function (data) { if (data[\u0026#39;province\u0026#39;] \u0026amp;\u0026amp; typeof data[\u0026#39;province\u0026#39;] === \u0026#39;string\u0026#39;) { var cityinfo = (data[\u0026#39;city\u0026#39;] || data[\u0026#39;province\u0026#39;]); cityName = cityinfo.substring(0, cityinfo.length - 1); ConvertCityCNNameToShortCut();//城市名转58同城地区域名 document.getElementById(\u0026#39;IPLocation\u0026#39;).innerHTML = \u0026#39;地图中心所在城市：\u0026#39; + cityName; } }); } } 整个代码的意思是，给map绑定一下移动时间，移动完了之后，调用getCity的方法获取当前地图中心所在城市信息。\n这个时候要注意，城市名可能在city对象里面，也可能在province里面。\n原因很简单：普通城市等级就是城市，我国还存在一个和省份一个等级的城市：直辖市。因此直辖市的城市名是在province里面的。\n城市名匹配58同城地区域名 这个是上个版本(两三天前)的一个bug引出来的新功能。\n上个版本是让用户输入城市名，然后提取城市名的中文拼音首字母作为58同城地区域名。如上海 =sh，广州=gz，北京=bj，成都=cd。\n这个功能使用的是网上别人写的一个JS库，通过汉字匹配实现的。转换出来的数据没什么问题，不过我国汉字实在奥妙。\n广州=gz，赣州=gz； 遂宁=sn；绥宁=sn； 惠州=hz，杭州=hz。\n这样一来，上面这个做法就没法玩了。\n想了下怎么解决这个问题，灵机一动。反正是在爬58的数据，这个城市名和城市域名数据58同城肯定有啊，然后找到了这个。 58同城城市分类导航\n很明显，我要的所有城市名和城市域名都是里面了。\n晚上和衣衣说了下，衣衣一大早就把处理好的json数据给我了。\n于是来了下面一段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //加载json文件 $.getJSON(\u0026#34;DomainJS/city.json\u0026#34;, function (data) { allCityInfo = data; }); function ConvertCityCNNameToShortCut() { var filterarray = $.grep(allCityInfo, function (obj) { return obj.cityName == cityName; });//找到当前城市名对应的json对象 //获取json对象的地区域名 cityNameCNPY = filterarray instanceof Array ? filterarray[0].shortCut : filterarray != null ? filterarray.shortCut : \u0026#34;\u0026#34;; } 高德地图自动补全功能 1 2 3 \u0026lt;div class=\u0026#34;control-input\u0026#34;\u0026gt; \u0026lt;input id=\u0026#34;work-location\u0026#34; type=\u0026#34;text\u0026#34; style=\u0026#34;width:60%\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; 1 2 3 4 5 var auto = new AMap.Autocomplete({ input: \u0026#34;work-location\u0026#34; }); AMap.event.addListener(auto, \u0026#34;select\u0026#34;, workLocationSelected); 看方法前面也知道，其实这就是把ID为work-location的input初始化为地图插件，然后给Amap增加了一个监听事件。 当其中选中某一个数据的时候，触发workLocationSelected函数。效果如下：\n在这里locationSelected是定位到所选位置，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 function workLocationSelected(e) { workAddress = e.poi.name; loadWorkLocation(); } function loadWorkLocation() { delWorkLocation(); var geocoder = new AMap.Geocoder({ city: cityName, radius: 1000 }); geocoder.getLocation(workAddress, function (status, result) { if (status === \u0026#34;complete\u0026#34; \u0026amp;\u0026amp; result.info === \u0026#39;OK\u0026#39;) { var geocode = result.geocodes[0]; x = geocode.location.getLng(); y = geocode.location.getLat(); loadWorkMarker(x, y); loadWorkRange(x, y, 60, \u0026#34;#3f67a5\u0026#34;, vehicle); map.setZoomAndCenter(12, [x, y]); } }) } 至于导航功能代码我没怎么动，没去研究就不献丑了\u0026hellip;\n最后来个效果图。\n北京 成都 苏州 深圳 ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/58%E5%90%8C%E5%9F%8E%E9%AB%98%E5%BE%B7%E6%90%9C%E6%88%BF%E9%A1%B9%E7%9B%AEjs%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/","title":"58同城高德搜房项目JS相关知识"},{"content":"在大神的带领下体验了一下asp.net core，感觉很不错，简单写个手把手教程。\n环境要求：VS2015 update2，版本不限。\n首先到这里：https://www.microsoft.com/net/download\n下载.NET Core Install 和SDK Install。\n如下图： 接着无脑安装。 两个都装完之后环境已经搭好了。不过在VS中还没对应的.NET Core模板。 我们还需要去下载一个 .NET Core Tooling Preview 1 for Visual Studio 2015\n这个安装略慢，稍等。\n上面的都安装好了之后，打开VS，新建项目，选中web，即可看到asp.net core. 如下图： 完事\u0026hellip;. 下次再来聊asp.net core项目\u0026hellip;\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/asp.net-core-%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"ASP.NET core 初体验"},{"content":"在ASP.NET 时代，一般来说我们很少会用到HttpModule/HttpHandler，然而有些场景我们使用HttpModule/HttpHandler倒方便快捷完成我们的需求。有兴趣了解HttpModule/HttpHandler以及使用场景的话，可以看下面这个链接的内容。\n选择HttpHandler还是HttpModule？\n来到ASP.NET Core时代，类似功能的内容可能我们看得就要多得多了。因为在ASP.NET Core时代，微软将HttpModule“变更”之后，并为它授予了更灵活应用场景。\n这就是这个文章要介绍的主角：Middleware（中间件）。 Middleware 为了使用跨平台，ASP.NET Core整个架构和代码都重写了一遍，所以 HttpModule 自然也就不存在了。但是相似的功能还是有的，它的名字叫： Middleware。和以前不同，在ASP.NET Core中我们将会经常看到 Middleware的存在，因为现在的每一个服务都是用Middleware的方式呈现在ASP.NET Core 管道中。不仅如此，meddleware比起之前的HttpModule也更弹性易用了。\n首先先来看看什么是middleware。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { loggerFactory.AddConsole(Configuration.GetSection(\u0026#34;Logging\u0026#34;)); loggerFactory.AddDebug(); app.UseStaticFiles(); app.UseMvc(routes =\u0026gt; { routes.MapRoute(\u0026#34;default\u0026#34;, \u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); } 看过ASP.NET Core项目的话，相信大家对Satarup.cs并不会陌生。在Starup.cs里面便有一个Configure()函数用于定义项目需要使用哪些middleware。\n上面的例子使用了两个middleware，一个是 UseStaticFiles，另一个是 UseMvc。这两个都是core自带的middleware，所以我们可以直接使用。UseStaticFiles 是为HTTP Request提供存取网站的文件，简单理解就是使得网站上的静态文件可访问，而UseMvc就是启用MVC routing机制。有了这两个middleware，我们的的网站就有了MVC routing和读取静态文件的功能。\n如果我们把UseMvc去掉，那么MVC routing也就不存在了，我们输入 http://website/[Controller]/[Action] 类似的地址也就无效了。\n和HttpModule的不同之处 在使用HttpModule的时候，我们是在实现/重写接口，这个时候就要求我们在适当的地方做适当的事情。例如，要做 authorization 的话就最好在 HttpModule 定义好的 Authorization 事件 (AuthorizatRequest) 中完成这个功能。在 ASP.NET life cycle 的文件里我们可以查到 HttpModule 定义了那些事件，每一個事件都有哪些特別的功能。因此我们需要全面了解之后再来选择实现/重写我们需要的事件。而在Middleware中，完全没有这样的限制，也不存在这样的事件，我们可以自行设计实现我们的机制。\nMiddleware 流程 https://docs.asp.net/en/latest/fundamentals/middleware.html 这个文章中说明了基本的middleware概念。目前asp.net docs里面有不少的内容都是开源社区开发者贡献的\n在这个文章里面有一个简单的流程图说明了ASP.NET runtime中middleware的执行过程。\n在 middleware 里面一定要定义 Invoke()函数，因为这是让 engine 默认调用 middleware 的Incoke函数。Middleware 里面所需要做什么事情就放在 Invoke() 里面，同时 Invoke() 里面还需要调用下一个 middleware。因此执行内容就如上图所示。Middleware 之间除了必须传送 HttpContext之外，也可以自定义传入其他的参数，这比以前的HttpModule方便多了。\n所以当 HTTP request 进来之后，engine 便会呼叫第一个 middleware 的 Invoke()，同时把传入HttpContext，然后第一个 middleware 可以再接着呼叫第二个 middleware 的 Invoke()，同时再把 HttpContext 继续传入，一直到最后一个middleware 的 Invoke() 结束之后，整个 HttpContext 的內容可能在 middleware 里面新增或被改变了，最后再按照整個原先的 call stack 从最后一个 middleware 回到第一个 middleware，再通过 engine 回传到client 端，完成request.\n下来通过一个例子我们一起来了解一下Middleware。\n编写简单的 Middleware 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class SampleMiddleware { private readonly RequestDelegate _next; public SampleMiddleware(RequestDelegate next) { _next = next; } public async Task Invoke(HttpContext context) { if (string.IsNullOrEmpty(context.User.Identity.Name)) { context.Response.Redirect(\u0026#34;/NoName.html\u0026#34;); return; } await _next.Invoke(context); } } 这一个middleware的名字叫SampleMiddleware。它有一个构造函数以及Invoke函数，而Invoke()只接收一个参数HttpContext。\n_next是一个叫 RequestDelegate类型，换言之这就是一个delegate，用于代表下一个middleware是谁。所以在构造函数中要把下一个middleware delegate传入。看到这里或许会觉得奇怪，我们的middleware在执行过程中怎么会知道下一个middleware是谁？这一部分稍后解释。\n在 Invoke() 里面，在 await _next.Invoke() 之前都是当前middleware的逻辑代码，从上面流程图来看的话就是由左自右的方向． await _next.Invoke() 之后的代码是就是流程图上由右至右的方向，因此，透過这样简单的设计，开发者就能很明确地控制什么样逻辑要先做或后做了。\n在 SampleMiddleware 之中，这里只做了一個很简单的动作，如果 username 是空白的话，就将该连接重定向到到 NoName.html 然后中断 middleware 的执行。\n为了能让这个middleware作为 ApplicationBuilder来使用，我们另外需要写一个扩展方法。代码如下：\n1 2 3 4 5 6 7 8 9 public static partial class MiddlewareExtensions { public static IApplicationBuilder UseSampleMiddleware( this IApplicationBuilder builder) { return builder.UseMiddleware\u0026lt;SampleMiddleware\u0026gt;(); } } 这给扩展方法建立了UseSampleMiddleware()，使得我们可以让ApplicationBuilder 去读 SampleMiddleware。\n这是回到Startup.cs中，在 Configure() 里面我们就可以把 SampleMiddleware 加入到我们的 pipeline中了。具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public void Configure(IApplicationBuilder app,IHostingEnvironment env, ILoggerFactory loggerFactory) { loggerFactory.AddConsole(Configuration.GetSection(\u0026#34;Logging\u0026#34;)); loggerFactory.AddDebug(); app.UseStaticFiles(); app.UseSampleMiddleware(); // \u0026lt;-- SampleMiddleware app.UseMvc(routes =\u0026gt; { routes.MapRoute(\u0026#34;default\u0026#34;, \u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); } 把 SampleMiddleware 放在 UseStaticFiles 和 UseMvc 之间，也就是说在 http request 还沒进入到 MVC routing 之前，就会先检查 HttpContext 里面是不是有空白的 username。很显然username肯定是空白的，因为我并沒有加入任何使用者验证代码这里面，所以利用 dotnet run 來运行这个项目的时候，你就会看到 Http code 302 出現，它的意思就是 http redirect，也就是 SampleMiddleware 里面面所做的 redirect 发生作用了。\nMiddleware 的执行顺序很重要 前面解释了 middleware 执行过程是一个接着一个的．不同的 middleware 对 HttpContext 的內容都可能有不同的处理或更改，因此执行舒服便格外重要。举个例子，如果将上面 Configure() 的代码变更如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { loggerFactory.AddConsole(Configuration.GetSection(\u0026#34;Logging\u0026#34;)); loggerFactory.AddDebug(); app.UseSampleMiddleware(); // SampleMiddleware app.UseStaticFiles(); // StaticFiles app.UseMvc(routes =\u0026gt; { routes.MapRoute(\u0026#34;default\u0026#34;,\u0026#34;{controller=Home}/{action=Index}/{id?}\u0026#34;); }); } 我们把SampleMiddleware 放到StaticFiles 之前。这就导致在 SampleMiddleware 里重定向到 NoName.html会失败。\n为什么会失败呢? 因为我们的 ApplicationBuilder 执行到行到 SampleMiddleware 时候重定向到NoName.html，也就是做读取静态页面，而这个功能服务方是在下一个 middleware (StaticFiles) 才会提供的，因此 ApplicationBuilder 无法找到 NoName.html，所以在浏览器上也就看不到 NoName.html 的內容。\nMiddleware 这样的设计带来了很大的方便和弹性，同時我们自己也要小心 middleware 前后相依性的问题。 Middleware 背后原理 现在 ASP.NET Core 已是开源项目了，所以最后说明一下 middleware 原理的基本概念．整個 ASP.NET fundamental 的部份用了许多的 function delegate , task, denepdency injection 的编写方法，所以要看 source code 之前，建议先对这三个东西先行了解，这样对理解 ASP.NET Core源码很有帮助．\n在前面的代码中，我们看到 RequestDelegate, 顾名思义就知道这是一个delegate（委托），它是用来代表 middleware 的 delegate. 它的 source code 在 RequestDelegate.cs\nIApplicationBuilder interface 是一個相当重要的接口，它定义了整個APP要用哪些服务和參數，当然也包含要使用那些 middleware，它的 souce code 在 IApplicationBuilder.cs。\n其中你可以看到 Use()，通过 Use() 的实例就可以把 middleware delegate 注册到 host engine 上。\n另外一个就是 UseMiddlewareExtensions ，前面的代码曾用了 builder.UseMiddleware(); 它会检查你写的 middleware 是不是合法的，比如有沒有 Invoke()，是不是只有一个Invoke()，Invoke() 的参数有沒有一个是 HttpContext type，所有的检查都通过之后便建立出该middleware instance 的 delegate。\n因此，当你的 ASP.NET Core APP刚启动的时候，在 Startup.cs 的 Configure() 就会把所有的 middleware delegate 建立起來，然后依序地放到內部的 stack 结构中。以上面的范例来说， stack 结构第一个元素是 StaticFiles, 然后是 SampleMiddleware 最后是 Mvc。接着每個 middleware 要被建立时是做 stack pop 的操作，所以 Mvc 的 _next 是 engine 里一些內部的 middleware 处理器，然後 pop 出 SampleMiddleware 时，就把 SampleMiddleware 的 _next 指向前面一個 pop 出來的 Mvc。依照着这样的逻辑一直到最前面的 middleware。所以在 host engine 在 Build() 之前这些动作都会完成，然后 host engine 才能执行Run()。有关 host engine 可參考 WebHostBuilder.cs\n全文完。\n本文整理于https://dotblogs.com.tw/aspnetshare/2016/03/20/201603191并已征得作者同意。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/asp.net-core-%E7%9A%84-middleware/","title":"ASP.NET Core 的 Middleware"},{"content":"ASP.NET Core 启动方式（Hosting） 之前版本的ASP.NET程序必须依赖IIS来启动，而IIS上会为挂载在其中的ASP.NET 注册一个ISAPI filter。每当http请求过来时，IIS则会启动w3wp的worker process来开始整个ASP.NET runtime程序。相信大家都这样的流程都有相应的了解。在.net core之前，ASP.NET的主要场景都是运行在Windows平台的，IIS也就是web server的首选了。虽然也有类似于jexus的linux webserver可用，但是基于mono的.NET 总体还是不够Microsoft 原生的强。\n不过到了现在，一切都不同了。\n新版ASP.NET Core有了.NET Core的支援后已经开始了它的跨平台之旅了，因此ASP.NET Core的启动方式也得开始重新设计以适应新需求了。 1、Kestrel 和 IIS platform handler 在 ASP.NET Core 中，整个runtime都是重写过的，所以它和IIS之间的关系也有所改变。而ASP.NET Core为了跨平台，它现在的执行方式就如一般的Console app一样。ASP.NET Core自带一个高性能的I/O组件 - Kestrel，使得它可以不依赖IIS的存在便启动了runtime。不过Kestrel 也只是一个I/O组件，并没有想IIS提供其它的功能来保护和管理ASP.NET 应用程序。ASP.NET Core同样可以通过IIS进行处理。但是如果通过IIS来进行处理的话，这个时候我们便需要一个“中间人”的角色来负责这个功能了。这个“中间人”的名字叫 Http Platform Handler，主要表现在web.config文档中的设置，其中包括启动ASP.NET Core 程序的的路径和名称，需要传入的参数以及一些其他的设置选项。Http Platform Handler的具体设置例子如下：\n1 2 3 4 5 6 7 8 \u0026lt;system.webServer\u0026gt; \u0026lt;handlers\u0026gt; \u0026lt;add name=\u0026#34;httpPlatformHandler\u0026#34; path=\u0026#34;*\u0026#34; verb=\u0026#34;*\u0026#34; modules=\u0026#34;httpPlatformHandler\u0026#34; resourceType=\u0026#34;Unspecified\u0026#34;/\u0026gt; \u0026lt;/handlers\u0026gt; \u0026lt;httpPlatform processPath=\u0026#34;WebApp.exe\u0026#34; arguments=\u0026#34;\u0026#34; stdoutLogEnabled=\u0026#34;false\u0026#34; startupTimeLimit=\u0026#34;3600\u0026#34;/\u0026gt; \u0026lt;/system.webServer\u0026gt; 关于Http Platform Handler的相关资料可以看这个链接： http://www.iis.net/downloads/microsoft/httpplatformhandler\n从上面的例子可以看出来，ASP.NET Core编译之后便是一个EXE程序，使得你可以直接运行。因此，当HTTP请求进来时，IIS先接受请求，然后根据你设置的web.config的内容将请求转发给WebApp.exe（你的ASP.NET Core程序），然后WebApp.exe开始执行时便会启动Kestrel，接着这个HTTP请求便进入了ASP.NET Core runtime的世界。这样看来，IIS这时候只是一个简单的proxy/forwarder角色。\nPS：在我翻译整理这个文章的时候，世界已经发生了变化：下个版本的asp.net core 将会有全新的IIS module来取代Http Platform Handler。\n具体详细资料见：https://github.com/aspnet/IISIntegration/issues/105\n2、Main() ASP.NET Core和其他的.NET 程序一样拥有一个static void Main(),这是整个runtime的进入点。下面看一个样例：\n1 2 3 4 5 6 7 8 9 10 11 12 public static void Main(string[] args) { var host = new WebHostBuilder() .UseServer(\u0026#34;Microsoft.AspNetCore.Server.Kestrel\u0026#34;) .UseContentRoot(Directory.GetCurrentDirectory()) .UseDefaultConfiguration(args) .UseIISPlatformHandlerUrl() .UseStartup\u0026lt;Startup\u0026gt;() .Build(); host.Run(); } ASP.NET Core host engine 的建立者是 WebHostBuilder．\n它实质上是一个了 IWebHostBuilder interface，其中 UseServer() 是用于指定使用什么样的 server。\n其中 UseServer() 有一个扩展方法UseServer(string assemblyName)。这样的话我们可以直接传入Kestrel的程序集名称:\u0026ldquo;Microsoft.AspNetCore.Server.Kestrel\u0026rdquo;。当然，这只是其中一种选项。你也可以自己实现一个自己的 server，只要你的 server 实现了 IServerFactory interface 即可。这样的设计提供了一个很大的弹性空间让我们自行选择hosting server（托管服务）。\nUseContentRoot() 这个扩展方法是让我们指定应用程序的工作目录（working directory），如果我们没有指定的话，则会默认为我们的应用（webapp.exe）所在目录为工作目录。 UseDefaultConfiguration() 这个扩展方法使得我们在IWebHostBuilder 建立可以传入一些参数，比如 application key, environment name, server factory location, content root path 等等．因此，当我们在运行 WebApp.exe 的时候，同时可以带入我们需要用到的hosting参数（PS：这样的做法就像运行命令行程序时带入参数，多好玩）。这些参数也可以写在appsettings.json里面通过Configuration来读取。 所以，UseDefaultConfiguration() 也不一定非要存在于 Main() 之中。（？？？个人不是很理解） PS：原作者原话，\u0026ldquo;如果我沒记错的话，在写这个文章的时候，UseDefaultConfiguration() 已经被改为成了UseDefaultHostingConfiguration()．显然这个名称更能清楚明白．\u0026quot;(？？？个人还没实践)\nUseIISPlatofmrHandleUrl() 这个 IWebHostBuilder 的 扩展方法比较特殊。如果你要把 ASP.NET Core 放在 IIS 下，这个扩展方法会读取 IIS http platform handler 的 server port 和 application path，用于作为 ASP.NET Core 的启动位置，如 http://localhost:5000/start．如果你沒用 IIS，这个扩展方法对你来说基本是用不上的． UseStartup\u0026lt;\u0026gt;() 这是 WebHostBuilder 里相当重要的一个扩展方法。它的方法签名如下： 1 2 3 public static IWebHostBuilder UseStartup\u0026lt;TStartup\u0026gt; (this IWebHostBuilder hostBuilder) where TStartup : class 这里你可以很清楚地看到 \u0026lt;\u0026gt; 里面要放的就是一个 class。\n在我们这里的范例中，它的名字是 Startup，里面最重要的就是需要定义要使用那些服务(service)以及要使用那些中间件(middleware)。\n3、Startup 这是一个非常非常重要的class,在ASP.NET Core范例中一般都把它命名成Startup。其实我们把它命名成其他名字也是可以的，或者设定多个Startup。上面的内容可以看到，UseStartup()指定了谁是starup class。然后在Build()便会实例化starup class，之后便执行里面两个重要的方法：ConfigureServices() 和 Configure()。\n我们先來看 Startup 的构造函数.\n1 2 3 4 5 6 7 8 9 public Startup(IHostingEnvironment env) { // Set up configuration sources. var builder = new ConfigurationBuilder() .AddJsonFile(\u0026#34;appsettings.json\u0026#34;) .AddJsonFile($\u0026#34;appsettings.{env.EnvironmentName}.json\u0026#34;, optional: true) .AddEnvironmentVariables(); Configuration = builder.Build().ReloadOnChanged(\u0026#34;appsettings.json\u0026#34;); } Host engine 在被执行 Build()时已经知道 startup type 是 Startup class，所以在 Build() 的时候会先创建期示例。在我们这里的是调用Startup类带参数的构造函数。\n在我们这个例子中选择的是传入IHostingEnvironment示例，它为我们带来了环境变量（EnvironmentName）。\n我们这里主要目的是把Configuration实例化。这是一个蛮重要的基础组件，以后会有文章来说明它。\n在这里我们特别说明一下，上面的示例代码中，我们执行了两次 AddJsonFile()，而且第二个json file的参数和第一个的还不太一样。这样的目的是为了让开发者可以把开发环境使用的环境参数和其他环境使用的参数有所区别。比如，你使用的开发环境用的是appsettings.json，这个文件只存在于你的电脑中。另一个文档是appsettings.production.json，这是正式环境使用的参数设定文档。第二個 AddJsonFile() 第二個参数是 true，也就是可能不存在的意思。所以若遇到重复名称参数时，appsettings.production.json 会覆盖 appsettings.json 的內容。这样使得开发环境和生产环境得以区分。\n接下来，在 IWebHostBuilder 的 Build()里面会执行 host engine 初始化的程序，其中就会去找Startup class里面的两个方法： ConfigureServices() 和 Configure()。\nConfigureSerivces() 是定义了这个 web application 要使用那些服务，然后将这些服务放在 service container (IServiceCollection) 裡面。如下面的样例：\n1 2 3 4 5 6 7 8 9 10 public void ConfigureServices(IServiceCollection services) { // add entity framework services.AddEntityFramework() .AddDbContext\u0026lt;BlogsContext\u0026gt;(o =\u0026gt; o.UseSqlServer(Configuration[\u0026#34;Data1:DefaultConnection:ConnectionString\u0026#34;])) // Add framework services. services.AddMvc(); } 它定义了entity framework和mvc两个服务。这里所谓的服务（services）的意思也就是通过它们带入更庞大的程序代码。这听起来好像有点搞笑，但也真的如此。像Entity framework 里面有这么多的代码，一定都需要带入许多定义好的物件或者参数，而不只是一个程序的进去点而已，所以services 的目的就是在这里。\nConfigure() 主要是定义了中间件（middleware）以及它们的顺序．\n1 2 3 4 5 6 7 8 9 public void Configure(IApplicationBuilder app, IHostingEnvironment env, ILoggerFactory loggerFactory) { loggerFactory.AddConsole(Configuration.GetSection(\u0026#34;Logging\u0026#34;)); loggerFactory.AddDebug(); app.UseStaticFiles(); app.UseMvcWithDefaultRoute(); } 4、Build 和 Run 最后，在IHostWebBuilder里最后的两个动作便是：Build and Run.\nBuild() 这个方法做的工作便是建立 hosting service，把 Startup 中定义的的 services 和 middleware 接收过来，然后确定content root path 和 application name，接着一句前面这些资料再加上Configuration过来的数据来初始化host engine (WebHost.cs)． Run() 这个是启动 host engine 的 扩展方法，它在启动之前加入了一个 CancelKeyPress 的事件．因为在 Run() 方法 中传入入了 CancellationTokenSource() ，让我们有一个方法可以随时中断host engine的执行。 目前的做法就用是 CancelKeyPress 事件，所以你可以按下 Ctrl+C 來中止 host engine 的执行．\n比较特別的是，这一段中止的文字说明居然是用 hard code，參考如下:\nhost.Run(cts.Token, \u0026ldquo;Application started. Press Ctrl+C to shut down.\u0026rdquo;);\n不过这样的话，这里你也不能写中文\u0026hellip;\n全文差不多就这样了，原文在这里：ASP.NET Core 的啟動方式 (Hosting)\n感谢ASP.NET Core 資訊分享。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/asp.net-core-%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8Fhosting/","title":"ASP.NET Core 启动方式（Hosting）"},{"content":"有时候我们会遇到需要把数据加密之后再网络上传输的需求，这样的话一般使用AES256之类的算法，经过运算之后得到一个byte数组，接着转换成string，就扔出去了。对方拿到之后，用密钥解密之后便得到了对应的数据。\n在C#里面，Byte数组转String字符串我们一般用Convert.ToBase64()完成。\n代码如下：\n1 2 3 4 5 6 7 8 9 public string BytesToString(byte[] buff) { return Convert.ToBase64String(buff); } public byte[] StringToBytes(string input) { return Encoding.UTF8.GetBytes(input); } 一般来说这样也没撒问题了，不过，如果这个数据是通过URL的方式给出去的，这时候就要考虑一下特殊字符编码问题了。+、空格、%之类的特殊字符可能会导致切断URL传参的数据，导致得到的数据不一致。这样的话，解密也做不下去了。\n相关资料：\n关于URL编码 URL编码\u0026mdash;-url参数中有+、空格、=、%、\u0026amp;、#等特殊符号的问题解决 不过也好在，C#提供了一个HttpUtility.UrlEncode(input)和HttpUtility.UrlEncode(input)这两个函数，让我们直接把上面的特殊字符转换成URL可识别的转义字符。 数据出去之后先Encode一下，回来之后Decode一下，好像问题都解决了吧。\n然而我们都忘了一件事情，URL到了浏览器之后，自然会对URL里面的东西Decode一次。 我实现的时候，在后台验证的时候又Decode一次,这就出问题了。\n问题在哪呢？一个encode的字符被decode两次，内容已经被改掉了\u0026hellip; 这就导致解密的时候直接挂了\u0026hellip;.\n这样看来， Convert.ToBase64String()这个不够靠谱，出来的数据可能会有特殊字符的问题。 怎么解决呢？那天晚上和老大/CTO都在看这个bug。一下子都没撒好办法\u0026hellip;.\n后来CTO想了一下，说byte不就是最大不久255么？直接转16进制字符就是嘛。 于是有了下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /// \u0026lt;summary\u0026gt; /// byte数组转string /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;bytes\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private static string BytesToString(byte[] bytes) { if (bytes == null) return string.Empty; return string.Join(string.Empty, bytes.Select(b =\u0026gt; string.Format(\u0026#34;{0:x2}\u0026#34;, b)).ToArray()); } /// \u0026lt;summary\u0026gt; /// string转byte数组 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;str\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; private static byte[] StringToBytes(string str) { if (string.IsNullOrEmpty(str)) return null; byte[] bytes = new byte[str.Length / 2]; for (int i = 0; i \u0026lt; str.Length; i += 2) { bytes[i / 2] = Convert.ToByte(\u0026#34;0x\u0026#34; + str[i] + str[i + 1], 16); } return bytes; } 问题解决。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/byte-to-string/","title":"byte to string"},{"content":"Join 连接：内连接、外连接、左连接、右连接。 SQL的Join这里就不多说了， 今天主要是看一下LINQ的Join用法，以及Enumerable.Join()的用法。\nJoin用于连接数据，首先就是数据之间有联系咯。\n先说Enumerable.Join()。 参数类型如下：\n1 2 3 4 5 6 7 8 public static IEnumerable\u0026lt;TResult\u0026gt; Join\u0026lt;TOuter, TInner, TKey, TResult\u0026gt; ( this IEnumerable\u0026lt;TOuter\u0026gt; outer, IEnumerable\u0026lt;TInner\u0026gt; inner, Func\u0026lt;TOuter, TKey\u0026gt; outerKeySelector, Func\u0026lt;TInner, TKey\u0026gt; innerKeySelector, Func\u0026lt;TOuter, TInner, TResult\u0026gt; resultSelector ) 类型参数 TOuter 第一个序列中的元素的类型。 TInner 第二个序列中的元素的类型。 TKey 键选择器函数返回的键的类型。 TResult 结果元素的类型。 参数 outer 类型：System.Collections.Generic.IEnumerable 要联接的第一个序列。 inner 类型：System.Collections.Generic.IEnumerable 要与第一个序列联接的序列。 outerKeySelector 类型：System.Func\u0026lt;TOuter, TKey\u0026gt; 用于从第一个序列的每个元素提取联接键的函数。 innerKeySelector 类型：System.Func\u0026lt;TInner, TKey\u0026gt; 用于从第二个序列的每个元素提取联接键的函数。 resultSelector 类型：System.Func\u0026lt;TOuter, TInner, TResult\u0026gt; 用于从两个匹配元素创建结果元素的函数。 返回值 类型：System.Collections.Generic.IEnumerable IEnumerable\u0026lt;T\u0026gt; that has elements of type TResult that are obtained by performing an inner join on two sequences.\u0026quot; xml:space=\u0026ldquo;preserve\u0026rdquo;\u0026gt;一个具有 TResult 类型元素的 IEnumerable，这些元素是通过对两个序列执行内部联接得来的。 使用说明 在 Visual Basic 和 C# 中，可以在 IEnumerable 类型的任何对象上将此方法作为实例方法来调用。当使用实例方法语法调用此方法时，请省略第一个参数。有关详细信息，请参阅 扩展方法 (Visual Basic) 或 扩展方法（C# 编程指南）。\n先上一个MSDN的例子。\npublic static void JoinEx1() { Person magnus = new Person { Name = \u0026quot;Hedlund, Magnus\u0026quot; }; Pet barley = new Pet { Name = \u0026quot;Barley\u0026quot;, Owner = terry }; Person terry = new Person { Name = \u0026quot;Adams, Terry\u0026quot; }; Person charlotte = new Person { Name = \u0026quot;Weiss, Charlotte\u0026quot; }; Pet boots = new Pet { Name = \u0026quot;Boots\u0026quot;, Owner = terry }; Pet whiskers = new Pet { Name = \u0026quot;Whiskers\u0026quot;, Owner = charlotte}; Pet daisy = new Pet { Name = \u0026quot;Daisy\u0026quot;, Owner = magnus }; List\u0026lt;Person\u0026gt; people = new List\u0026lt;Person\u0026gt; { magnus, terry, charlotte }; List\u0026lt;Pet\u0026gt; pets = new List\u0026lt;Pet\u0026gt; { barley, boots, whiskers, daisy }; // Create a list of Person-Pet pairs where // each element is an anonymous type that contains a // Pet's name and the name of the Person that owns the Pet. var query = people.Join( pets,//需要Join的另一个数据源 person =\u0026gt; person,//自己用来比较的key， lambda 表达式 pet =\u0026gt; pet.Owner,//另一个数据源用来比较的key， lambda 表达式 (person, pet) =\u0026gt;new { OwnerName = person.Name, Pet = pet.Name } //想要取出来的数据，支持匿名对象， lambda 表达式); foreach (var obj in query) { Console.WriteLine( \u0026quot;{0} - {1}\u0026quot;,obj.OwnerName,obj.Pet); } } LINQ的Join 同样是上面的数据，如果换成LINQ的Join，写法如下： var query = from person in people // 第一个数据源 join pet in pets //第二个数据源 on person equals pet.Owner //Join条件 select new { OwnerName = person.Name, Pet = pet.Name };\n//要到得到的数据。\n上面两种写法得到的结果都是内链接结果，至于左连接、右连接、外连接\u0026hellip;. 等我下次有心情再更新吧，再不走家里的键盘又要坏了。\n一些资料链接： https://msdn.microsoft.com/zh-cn/library/bb311040.aspx https://msdn.microsoft.com/zh-cn/library/bb534675%28v=vs.110%29.aspx?f=255\u0026MSPPError=-2147217396 http://www.cnblogs.com/Ivony/archive/2008/08/18/1270555.html http://www.cnblogs.com/Ivony/archive/2008/08/28/1278643.html http://www.cnblogs.com/Ivony/archive/2008/10/14/1309807.html ;\nLINQ GroupJoin 实现左连接 var queryGroup = from person in people // 第一个数据源 join pet in pets //第二个数据源 on person equals pet.Owner into ps //加了into,华丽变身GroupJoin select new { OwnerName = person.Name, Pet = ps }; //要到得到的数据。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23-join%E7%94%A8%E6%B3%95/","title":"C# join用法"},{"content":"LINQ 优点 总结(转载) 原文链接：http://www.cnblogs.com/c-jquery-linq-sql-net-problem/archive/2011/01/15/LINQ_Merit.html\n这几天在读一本LINQ方面的书《Essential LINQ》,在这里和大家分享下。\n由于对LINQ的深入总结需要大量的篇幅，因此在这里分成几个部分来讲。\n（*我看《Essential LINQ》是英文版的，有些名词不能翻译成正统的中文解释请给予谅解）\nLINQ的优点：\nLINQ基本有以下七个优点，让我来一一举例说明：\nIntegrated：所谓的Integrated（集成化），LINQ是从以下方面体现集成的： (1):把查询语法融入了C#(VB)这些语言中，让他变成了一种语法。这样就能和C#中的其他语法一样支持：\n语句高亮显示，类型检查，允许使用debugger调试\n(2):把以前复杂的查询前的工作都集成封装起来，让开发人员侧重于查询。\n(3):集成后的语法更加的清晰易懂，可读性较高。\n1 2 3 4 5 6 7 8 9 10 11 12 比较： //原来的格式 SqlConnection sqlConn = new SqlConnection(connectionString);\u0026gt; sqlConn.Open(); SqlCommand command = new SqlCommand(); command.Connection = sqlConn; command.CommandText = \u0026#34;Select * From Customer\u0026#34;; SqlDataReader dataReader = command.ExecuteReader(CommandBehavior.CloseConnection); //LINQ的格式 NORTHWNDDataContext dc = new NORTHWNDDataContext(); var query = from c in dc.Customers select c; Unitive：所谓Unitive(统一化)就指不管对任何类型外部和内部数据源(对象集合,xlm,数据库数据)都使用统一的查询语法。 使用统一化查询语言的好处在于以下几点：\n你不用因为要使用不太熟悉的数据源而花很多精力去了解它，你可以快速简单的使用LINQ语法对起查询。 由于使用了统一的语法，可以使代码维护变的更加简单。 以下代码体现了LINQ的统一化：\n1 2 3 4 5 6 7 8 9 10 //数据源:对象集合 var query = from c in GetCustomers() select c; //数据源:SQL var query1 = from c in dc.Customers select c; //数据源:XML var query2 = from c in customers.Descendants(\u0026#34;Customer\u0026#34;) select c; Extensible：所谓Extensible(可扩展)指以下2个方面: (1).可查询数据源的扩展。 LINQ提供了个LINQ provider model，你可以为LINQ创建或提供provider让LINQ支持更多的数据源。\n(2).可扩展查询方法。开发者可以根据自己的需求为LINQ重写和扩展查询方法。\n以下是些第三方的LINQ provider：\nLINQ Extender, LINQ to JavaScript, LINQ to JSON, LINQ to MySQL, LINQ to Flickr, LINQ to Google\nDeclarative：所谓Declarative(声明式)，简单的来说指的是开发人员只要告诉程序做什么，程序自己判断怎么做。 Declarative programming(声明式编程)的优点体现在以下2点：\n(1).提高了开发速度。因为开发者不用书写大量的代码来具体化执行步骤，只许告诉程序做什么。\n(2).提高代码优化空间。因为开发者不用参与干涉对程序执行的具体步骤，这样就提供给编译器更多的空间去优化代码。\n举例SQL来说，LINQ生成的SQL语句往往比一对SQL水平一般的开发者能写出更好的SQL语句。\n比较Declarative programming 与 Imperative programming：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //声明式编程 List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; lists = new List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; { new List\u0026lt;int\u0026gt; { 1, 2, 3 }, new List\u0026lt;int\u0026gt; { 4, 5 } }; var query = from list in lists from num in list where num % 3 == 0 orderby num descending select num; //命令式编程 List\u0026lt;int\u0026gt; list1 = new List\u0026lt;int\u0026gt;(); list1.Add(1); list1.Add(2); list1.Add(3); List\u0026lt;int\u0026gt; list2 = new List\u0026lt;int\u0026gt;(); list2.Add(4); list2.Add(5); List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; lists1 = new List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt;(); lists1.Add(list1); lists1.Add(list2); List\u0026lt;int\u0026gt; newList = new List\u0026lt;int\u0026gt;(); foreach (var item in lists1) foreach (var num in item) if (num % 3 == 0) newList.Add(num); newList.Reverse(); .Hierarchical：所谓Hierarchical(层次化)指使用面向对象的方式抽象数据。 SQL是关系型数据库，它以关系的方式描述数据以数据的联系，但我们的程序设计成面向对象的因此我们在程序里得到的数据库数据往往都是\nrectangular grid（平面的显示数据）。但是LINQ通过所谓的O-R Mapping方式，把关系型转换成对象与对象方式描述数据。\n这样带来的好处是：开发者能直接以对象的方式去操作数据，对习惯面向对象的开发者来说面向对象模型更易理解。\n.Composable：所谓Composable(可组成)指LINQ可以把一个复杂的查询拆分成多个简单查询。 LINQ返回的结果都是基于接口：IEnumerable，因此能对查询结果继续查询，而且LINQ具有延迟执行的特性因此拆分执行不会影响效率。\n优点在于：\n(1).方便调试。把复杂的查询拆分成简单的查询，然后逐个调试。\n(2).便于代码维护。把代码拆分后能使代码变的更易理解。\n以下代码体现了可组成性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //以下代码体现了Composable List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; lists = new List\u0026lt;List\u0026lt;int\u0026gt;\u0026gt; { new List\u0026lt;int\u0026gt; { 1, 2, 3 }, new List\u0026lt;int\u0026gt; { 4, 5 } }; var query1 = from list in lists from num in list select num; var query2 = from num in query1 where num % 3 == 0 select num; var query3 = from num in query2 orderby num descending select num; ######7.Transformative：所谓Transformative(可转换)指的是LINQ能把一种数据源的内容转换到其他数据源。\n方便用户做数据移植。\n以下代码体现了转换的特性：\n1 2 3 4 5 6 //把关系型数据转换成XML型 var query = new XElement(\u0026#34;Orders\u0026#34;, from c in dc.Customers where c.City == \u0026#34;Paris\u0026#34; select new XElement(\u0026#34;Order\u0026#34;, new XAttribute(\u0026#34;Address\u0026#34;, c.Address))); 以上就是LINQ的几大优点，很高兴能在这里和大家分享。有任何不足之处请给予补充和纠正，谢谢光临小舍。\n//2011/1/28 补充(LINQ TO SQL)\n在LINQ TO SQL 方面，如果使用LINQ TO SQL可以有效的防止SQL注入，LINQ TO SQL 会把注入的代码当做无用的参数处理。\nhttp://www.cnblogs.com/c-jquery-linq-sql-net-problem/archive/2011/01/15/LINQ_Merit.html\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23-linq/","title":"C# LINQ"},{"content":"周末闲着无事刷知乎发现一个爬虫教程（高德API+Python解决租房问题 ），正中最近想要换地方住的痛点。然后大早上懒觉都没睡就屁颠屁颠开始研究这个教程了。这样教程在实验楼网站里面有手把手步骤，有兴趣自取（实验楼：高德API+Python解决租房问题）。\n整体项目主要分成两步：\n第一步:python爬取数据，生成数据文件;\n第二部：导入数据文件，在地图上显示房源，设定上班地点后自动计算出行路线和路程时间。\n研究了一下这个教程之后发现这货做得实在有点粗糙，只能当教程用，完全没有通用实际价值。\n而且这里面还有个更大的问题：教程是基于北京的数据来做的，而我在上海\u0026hellip;\n虽然说改改python数据源，改改导航页面JS完事。不过是在难用\u0026hellip;\n于是，开始自己动手了。先看原有的python代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #-*- coding:utf-8 -*- from bs4 import BeautifulSoup from urlparse import urljoin import requests import csv url = \u0026#34;http://bj.58.com/pinpaigongyu/pn/{page}/?minprice=2000_4000\u0026#34; #已完成的页数序号，初时为0 page = 0 csv_file = open(\u0026#34;rent.csv\u0026#34;,\u0026#34;wb\u0026#34;) csv_writer = csv.writer(csv_file, delimiter=\u0026#39;,\u0026#39;) while True: page += 1 print \u0026#34;fetch: \u0026#34;, url.format(page=page) response = requests.get(url.format(page=page)) html = BeautifulSoup(response.text) house_list = html.select(\u0026#34;.list \u0026gt; li\u0026#34;) # 循环在读不到新的房源时结束 if not house_list: break for house in house_list: house_title = house.select(\u0026#34;h2\u0026#34;)[0].string.encode(\u0026#34;utf8\u0026#34;) house_url = urljoin(url, house.select(\u0026#34;a\u0026#34;)[0][\u0026#34;href\u0026#34;]) house_info_list = house_title.split() # 如果第二列是公寓名则取第一列作为地址 if \u0026#34;公寓\u0026#34; in house_info_list[1] or \u0026#34;青年社区\u0026#34; in house_info_list[1]: house_location = house_info_list[0] else: house_location = house_info_list[1] house_money = house.select(\u0026#34;.money\u0026#34;)[0].select(\u0026#34;b\u0026#34;)[0].string.encode(\u0026#34;utf8\u0026#34;) csv_writer.writerow([house_title, house_location, house_money, house_url]) csv_file.close() 整个代码基本思路就是，爬取http://bj.58.com/pinpaigongyu/pn/{page}/?minprice=2000_4000页面数据，然后扔到创建的csv文件里面作为下一步的数据源。 通过研究http://bj.58.com/pinpaigongyu/pn/{page}/?minprice=2000_4000这个页面的数据，我们可以很容易发现，在页面中，每条数据都是一个li标签。\n如下图：\nli结构如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;li logr=\u0026#34;\u0026#34; class=\u0026#34;\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;/pinpaigongyu/26851774057013x.shtml\u0026#34; target=\u0026#34;_blank\u0026#34; onclick=\u0026#34;clickLog(\u0026#39;from=fcpc_list_gy_sh_tupian\u0026#39;)\u0026#34; tongji_label=\u0026#34;listclick\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;img\u0026#34;\u0026gt; \u0026lt;img lazy_src=\u0026#34;\u0026#34; alt=\u0026#34;\u0026#34; src=\u0026#34;\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;des\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;【合租】菊园新区 柳湖景庭 3室次卧\u0026lt;/h2\u0026gt; \u0026lt;p class=\u0026#34;room\u0026#34;\u0026gt; 3室1厅1卫\u0026amp;nbsp; \u0026amp;nbsp; 13m²\u0026amp;nbsp;\u0026amp;nbsp; 3/6层\u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;dist\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;spec\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;spec1\u0026#34;\u0026gt;公共阳台\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;spec2\u0026#34;\u0026gt;公共卫生间\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;spec3\u0026#34;\u0026gt;离地铁近\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;spec4\u0026#34;\u0026gt;厨房\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;money\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;b\u0026gt;1100\u0026lt;/b\u0026gt;元/月 \u0026lt;/span\u0026gt; \u0026lt;p\u0026gt;租房月付\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; 照着python的思路，是把所有的li标签的数据提取出来的。\n我自己研究的时候又看了下，其实数据都在一个属性为tongji_label=\u0026ldquo;listclick\u0026quot;的a标签里面。\n一般来说，字符匹配用正则表达式完事，奈何正则水平实在不佳。我还是选择直接上HtmlAgilityPack算了。 关于HtmlAgilityPack的介绍还是看官网算了。HtmlAgilityPack\nHtmlAgilityPack是.NET一个比较强大的HTML处理类库了，基本可以让你像JS来操作HTML标签。 安装这货很简单，直接在Nuget PM包管理工具里面输入下面命令就完事了。\n1 Install-Package HtmlAgilityPack 有需要使用教程可以看这个：Html Agility Pack基础类介绍及运用\n下面直接贴controller源码算了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 /// \u0026lt;/summary\u0026gt; /// \u0026lt;param name=\u0026#34;costFrom\u0026#34;\u0026gt;价格区间起始值\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;costTo\u0026#34;\u0026gt;价格区间终止值\u0026lt;/param\u0026gt; /// \u0026lt;param name=\u0026#34;cnName\u0026#34;\u0026gt;城市拼音首字母\u0026lt;/param\u0026gt; /// \u0026lt;returns\u0026gt;\u0026lt;/returns\u0026gt; public ActionResult Get58CityRoomData(int costFrom, int costTo, string cnName) { if (costTo\u0026lt;=0 || costTo \u0026lt; costFrom) { return Json(new { IsSuccess = false, Error = \u0026#34;输入数据有误，请重新输入。\u0026#34; }); } if (string.IsNullOrEmpty(cnName)) { return Json(new { IsSuccess = false, Error = \u0026#34;城市定位失败，建议清除浏览器缓存后重新进入。\u0026#34; }); } try { var lstHouse = new List\u0026lt;HouseInfo\u0026gt;(); string tempURL = \u0026#34;http://\u0026#34; + cnName + \u0026#34;.58.com/pinpaigongyu//pn/{0}/?minprice=\u0026#34; + costFrom + \u0026#34;_\u0026#34; + costTo; Uri uri = new Uri(tempURL); var htmlResult = HTTPHelper.GetHTMLByURL(string.Format(tempURL, 1)); HtmlDocument htmlDoc = new HtmlDocument(); htmlDoc.LoadHtml(htmlResult); var countNodes = htmlDoc.DocumentNode. SelectSingleNode(\u0026#34;.//span[contains(@class,\u0026#39;list\u0026#39;)]\u0026#34;); int pageCount = 10; if (countNodes != null \u0026amp;\u0026amp; countNodes.HasChildNodes) { pageCount = Convert.ToInt32(countNodes.ChildNodes[0].InnerText) / 20; if(pageCount==0) { return Json(new { IsSuccess = false, Error =string.Format(\u0026#34;没有找到价格区间为{0} - {1}的房子。\u0026#34;, costFrom,costTo)}); } } for (int pageIndex = 1; pageIndex \u0026lt;= pageCount; pageIndex++) { htmlResult = HTTPHelper.GetHTMLByURL(string.Format(tempURL, pageIndex)); htmlDoc.LoadHtml(htmlResult); var roomList = htmlDoc.DocumentNode .SelectNodes(\u0026#34;.//a[contains(@tongji_label,\u0026#39;listclick\u0026#39;)]\u0026#34;); foreach (var room in roomList) { var houseTitle = room.SelectSingleNode(\u0026#34;.//h2\u0026#34;).InnerHtml; var houseURL = uri.Host + room.Attributes[\u0026#34;href\u0026#34;].Value; var house_info_list = houseTitle.Split(\u0026#39; \u0026#39;); var house_location = string.Empty; if (house_info_list[1].Contains(\u0026#34;公寓\u0026#34;) || house_info_list[1].Contains(\u0026#34;青年社区\u0026#34;)) { house_location = house_info_list[0]; } else { house_location = house_info_list[1]; } var momey = room.SelectSingleNode(\u0026#34;.//b\u0026#34;).InnerHtml; lstHouse.Add(new HouseInfo() { HouseTitle = houseTitle, HouseLocation = house_location, HouseURL = houseURL, Money = momey, }); } } return Json(new { IsSuccess = true, HouseInfos = lstHouse }); } catch (Exception ex) { return Json(new { IsSuccess = false, Error = \u0026#34;获取数据异常。\u0026#34; + ex.ToString() }); } } 下面解释一下核心代码。\n片段一：获取总数。\n在观察58同城页面的时候，无意发现其实第一个加载的页面中有一个数据总条数，隐藏在页面里面的。\n1 \u0026lt;span class=\u0026#34;listsum\u0026#34;\u0026gt;\u0026lt;em\u0026gt;1813\u0026lt;/em\u0026gt;条结果\u0026lt;/span\u0026gt; 这样一来，总页面就很清晰了。页面=总数/每页20条。然后我们根据已知的数据规则去循环请求页面，也就能拿到所有的搜索数据了。\n核心代码，获取总条数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var countNodes = htmlDoc.DocumentNode. SelectSingleNode(\u0026#34;.//span[contains(@class,\u0026#39;list\u0026#39;)]\u0026#34;); int pageCount = 10; if (countNodes != null \u0026amp;\u0026amp; countNodes.HasChildNodes) { pageCount = Convert.ToInt32(countNodes.ChildNodes[0].InnerText) / 20; if(pageCount==0) { return Json(new { IsSuccess = false, Error =string.Format(\u0026#34;没有找到价格区间为{0} - {1}的房子。\u0026#34;, costFrom,costTo)}); } } 在HTMLDoc里面找到一个span的class包含list的节点，获取它子节点（即em）的内容，强制转换成数字，也就是我们要找的总条数了。总条数除以20就得到了页数，下面就是开始循环请求页面了。\n在最上面我们分析过公寓数据分布，数据是li里面套a标签，我们需要的地理位置、房间名称、价格都在a标签里面。\n这样一来，我们这要获得到页面所有带有属性为tongji_label=\u0026ldquo;listclick\u0026quot;的a标签数据，也就得到了我们所有需要的数据。\n看一下a标签的数据组成：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026lt;a href=\u0026#34;/pinpaigongyu/26851774057013x.shtml\u0026#34; target=\u0026#34;_blank\u0026#34; onclick=\u0026#34;clickLog(\u0026#39;from=fcpc_list_gy_sh_tupian\u0026#39;)\u0026#34; tongji_label=\u0026#34;listclick\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;img\u0026#34;\u0026gt; \u0026lt;img lazy_src=\u0026#34;\u0026#34; alt=\u0026#34;\u0026#34; src=\u0026#34;\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;des\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;【合租】菊园新区 柳湖景庭 3室次卧\u0026lt;/h2\u0026gt; \u0026lt;p class=\u0026#34;room\u0026#34;\u0026gt; 3室1厅1卫\u0026amp;nbsp; \u0026amp;nbsp; 13m²\u0026amp;nbsp;\u0026amp;nbsp; 3/6层\u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;dist\u0026#34;\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;spec\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;spec1\u0026#34;\u0026gt;公共阳台\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;spec2\u0026#34;\u0026gt;公共卫生间\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;spec3\u0026#34;\u0026gt;离地铁近\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;spec4\u0026#34;\u0026gt;厨房\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;money\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;b\u0026gt;1100\u0026lt;/b\u0026gt;元/月 \u0026lt;/span\u0026gt; \u0026lt;p\u0026gt;租房月付\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/a\u0026gt; 我们要的房间信息在一个h2的标签里面，公寓租金价钱在class=\u0026ldquo;money\u0026quot;的div标签里面。\n于是有了一下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 for (int pageIndex = 1; pageIndex \u0026lt;= pageCount; pageIndex++) { htmlResult = HTTPHelper.GetHTMLByURL(string.Format(tempURL, pageIndex)); htmlDoc.LoadHtml(htmlResult); //找到所有的带有属性为tongji_label=\u0026#34;listclick\u0026#34;的a标签数据 var roomList = htmlDoc.DocumentNode.SelectNodes(\u0026#34;.//a[contains(@tongji_label,\u0026#39;listclick\u0026#39;)]\u0026#34;); foreach (var room in roomList) { //获取其中为h2的房间数据，然后用空格分割成数组 var houseTitle = room.SelectSingleNode(\u0026#34;.//h2\u0026#34;).InnerHtml; var houseURL = uri.Host + room.Attributes[\u0026#34;href\u0026#34;].Value; var house_info_list = houseTitle.Split(\u0026#39; \u0026#39;); var house_location = string.Empty; //分割出来的数组，第二个包含公寓或青年社区，则取第一个数据为所在地区，否则取第二个数据 //【合租】菊园新区 柳湖景庭 3室次卧 // 所在地区为：菊园新区 if (house_info_list[1].Contains(\u0026#34;公寓\u0026#34;) || house_info_list[1].Contains(\u0026#34;青年社区\u0026#34;)) { house_location = house_info_list[0]; } else { house_location = house_info_list[1]; } //获取标签为b的数据，价格就在里面了 var momey = room.SelectSingleNode(\u0026#34;.//b\u0026#34;).InnerHtml; lstHouse.Add(new HouseInfo() { HouseTitle = houseTitle, HouseLocation = house_location, HouseURL = houseURL, Money = momey, }); } } 后端来说，基本就这些内容了。\n还有一些前端高德地图接口调用下次再讲吧，要陪女票玩游戏去了\u0026hellip;\n^-^\n以上源码地址：https://github.com/liguobao/58HouseSearch\n在线地址：58公寓高德搜房(全国版)：https://woyaozufang.live\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23-58%E5%90%8C%E5%9F%8E%E5%93%81%E7%89%8C%E5%85%AC%E5%AF%93%E7%88%AC%E8%99%AB/","title":"C#-58同城品牌公寓爬虫"},{"content":"dotnet托管堆和垃圾回收 托管堆基础 简述：每个程序都要使用这样或那样的资源，包括文件、内存缓冲区、屏幕空间、网络连接\u0026hellip;..事实上，在面向对象的环境中，每个类型都代表可供程序使用的一种资源。要使用这些资源，必须为代表资源的类型分配内存。 以下是访问一个资源所需步骤：\n调用IL指令newobj，为代表资源的类型分配内存。(C# new操作符) 初始化内存，设置资源的初始状态。（一般指构造函数） 访问类型的成员来使用资源。（使用成员变量、方法、属性等） 摧毁资源的状态以进行清除。（Dispose？？？） 释放内存。（GC） 从托管堆分配资源 CLR要求所有的对象都从托管堆分配。 进程初始化，CLR划出一个地址空间区域作为托管堆。CLR还要维护一个指针，姑且叫NextObjPtr，该指针指向下一个对象在堆中的分配位置。刚开始的时候， NextObjPtr 设为地址空间区域的基地址。 一个区域被非垃圾对象填满后，CLR会分配更多的区域。\n这一个过程一直重复，直至整个进程地址空间被填满。所以，应用程序内存收进程的虚拟地址空间的限制。\n32位进程最多能分配1.5GB，64位进程最多能分配8T。 注：进程内存大小的相关资料\nMemory Support and Windows Operating Systems\n进程地址空间\n32位模式下C/C++程序可用最大内存\nC# 的new操作符导致CLR执行以下操作： 计算类型的字段（以及从基类型继承的字段）所需要的字节数。\n加上对象的开销所需的字节数。每个对象都有两个开销字段：类型对象指针和同步块索引。对于32位应用程序，这两个字段各需要32位，所以每个对象需要增加8字节。对于64位应用程序，这两个字段各需要64位，所以每个对象要增加16字节。\nCLR检查区域中是否有分配对象所需的字节数。如果托管堆有足够的可用空间，就在NetxObjPtr指针指向的地址处放入对象，为对象分配的字节会被清零。接着调用类型的构造器（为this参数传递NextObjPtr），new操作符返回对象引用。就在返回这个对象引用之前，NextObjPtr指针的值会加上这个对象占用的字节数来得到一个新值，即下个对象放入托管堆时的地址。如下图：\n垃圾回收算法 ####CLR使用引用跟踪算法。\n引用跟踪算法只关心引用类型的变量，因为只有这种变量才能引用堆上面的对象； 值类型变量直接包含值类型实例。引用类型变量可在许多场合使用，包括类的静态和实例字段，或者方法的参数和局部变量。这里我们将所有引用类型的变量都称为根。 CLR开始GC时，首先暂停所有的线程。(这样可以防止线程在CLR检查期间访问对象并更改其状态。) 然后CLR进入GC标记阶段。在这个阶段，CLR遍历堆中的所有对象，将同步块索引字段中的一位设为0。这表明所有的对象都应删除。然后，CLR检查所有的活动根，查看他们引用了哪些对象。这正是CLR的GC被称作引用跟踪GC的原因。如果一个根包含null，CLR忽略这个根并继续检查下一个根。 下图展示一个堆，其中包含几个对象。 应用程序的根直接引用对象A 、C、D 、F。所有的对象都已经被标记。标记对象D时，GC发现这个对象含有一个引用对象H的字段，造成对象H也被标记。标记过程会持续，直至应用程序的所有根所有检查完毕。 检查完毕后，堆中的对象要么已标记，要么未标记。已标记的对象不能被垃圾回收，因为至少有一个根在引用它。我们说这种对象是可达的，因为应用程序可以通过引用它的变量抵达它。 未标记的对象是不可达的，因为应用程序中不存在使对象能被再次访问的根。\nCLR知道哪些对象可以幸存，哪些可以被删除后，进入GC的压缩（类似于碎片整理）阶段。在压缩阶段，CLR对堆中已标记的对象进行“乾坤大挪移”，整理所有幸存下来的对象，使他们占用连续的内存。\n这样做的好处在于：\n所有幸存对象在内存中紧挨在一起，恢复了引用的“局部性”，减少了应用程序的工作集，从而提升了将来访问这些对象时的性能；\n经过整理后，可用空间也是连续的，整个地址空间区段得到了解放，允许其他东西进驻。\n在内存中移动了对象之后有一个问题亟待解决。引用幸存对象的根现在引用的还是对象最初在内存中的位置，而非移动后的位置。被暂停的线程恢复执行时，将访问旧的内存位置，会造成内存损坏。 这显然是不能容忍的，所以作为压缩阶段的一部分，CLR还要从每个根减去所引用对象在内存中偏移的字节数。这样就能保证每个根还是引用和之前一样的对象，只是对象在内存中变换了位置。 如图： 代：提升性能 (待续) CLR的GC是基于代的垃圾回收器，它对你的代码做出了以下几点假设：\n对象越新，生存周期越短。\n对象越老，生存周期越长。\n回收堆的一部分 ，速度快于回收整个堆。\n大量研究表明，这些假设对于现今大多数的应用程序都是成立的，它们影响了垃圾回收器的实现方式。这里将解释代的工作原理。\n托管堆在初始化时不包括对象。添加到堆的对象成为第0代对象。简单来说，第0代对象就是那些新构造的对象，垃圾回收器从未检查过它们。如下图，新启动的应用程序，分配了5个对象（从A到E）。过了一会，C和E变得不可达了。\nCLR初始化第0代对象选择一个预算容量。如果分配一个新对象造成第0代超预算，就必须启动一次GC。假设对象A到E刚好用完了第0代的空间，那么分配对象F就必须启动GC。GC之后存活的对象现场成为第1代对象。如下图：\n一次GC之后，第0代就不包含任何对象。和前面一样，新对象会分配到第0代。新分配对象F到对象K都到了第0代。 之后，程序继续运行，B、H、J变得不可达，它们的内存将在某一个时刻回收。\n假设现在新分配对象L会造成第0代超出预算,造成必须启动垃圾回收。\n开始垃圾回收时,垃圾回收器必须决定检查哪些代。前面说过,CLR初始化时会为第0代对象选择预算.事实上,它还必须为第1代选择预算.\n开始一次垃圾回收时,垃圾回收器还会检查第一代占用了多少内存。在本例中,由于第1代占用内存远少于预算,所以垃圾回收器只检查第0代对象。回顾之前基于代的垃圾回收器做出的第一个假设：对象越新，生存期越短。 因此，第0代包含更多的垃圾的可能性更大，能回收更多的内存。由于忽略第1代中的对象，所以加快了垃圾回收速度。\n显然，忽略第1代中的对象能提升垃圾回收器的性能。但对性能有更大提振作用的是现在不必遍历托管堆中的每个对象。如果根或对象引用了老一代的某个对象，垃圾回收器就可以忽略老对象内部的所有引用，能在更短的时间内构造好可达对象图。当然，如果老对象的字段也可能引用新对象。为了确保对老对象的已更新字段进行检查，垃圾回收器利用了JIT编译器内部的一个机制。这个机制在对象的引用字段发生变化时，会设置一个对应的标志位。这样，垃圾回收器就知道自上一次垃圾回收以来，哪些老对象（如果有的话）已被写入。只有字段发生变化的老对象才需要检查是否引用了第0代中的任何新对象。\n基于代的垃圾回收器还假设越老的对象活得越长。也就是说，第1代对象在应用程序中有可能是继续可达的。如果垃圾回收器检查第1代的对象，很有可能找不到多少垃圾，结果是也回收不了多少内存。因此，对第1代进行垃圾回收很可能是浪费时间的。如果第一代真有垃圾，垃圾将留在那里。如下图： 程序继续运行，继续往第0代分配对象，同时程序停止对第1代某对象的使用。\n如下图： 分配对象P导致第0代超预算，开始GC。第1代的所有对象占据内存仍小于预算，垃圾回收器再次决定只回收第0代。忽略第1代中的垃圾对象。如下图： 程序继续运行，假设第一代的增长导致它的全部对象占用了全部预算。这时候应用程序分配对象P到对象S，使第0代对象达到它的预算总和。如下图： 这时候，应用程序准备分配对象T，由于第一代已满，所以必须开始GC。但这一次垃圾回收器发现第一代占用了太多内存，以至于用完了预算。由于前几次对第0代进行GC时，第1代中可能已经有很多对象变得不可达。所以这次垃圾回收器决定检查第1代和第0代中的所有对象。两代都被垃圾回收后，堆的情况如下图： 托管堆只支持三代：第0代、第1代和第2代。\nCLR初始化时，会为每一代选择预算。\n然而，CLR的垃圾回收是自调节的。\n这意味着垃圾回收器会在执行垃圾回收的过程了解程序的行为。\n例如：假设应用程序构造了许多对象，但每个对象的时间都很短。 在这种情况下，对第0代的垃圾回收会回收到大量的内存。事实上，第0代的所有对象都可能被回收。\n如果垃圾回收器发现在回收第0代后存活下来的对象很少，就可能减少第0代的预算。已分配空间的减少意味着垃圾回收将更频繁地发生，但垃圾回收器每次做的事情也减少，这减少了进程的工作集。\n另一方面，如果垃圾回收器回收了第0代，发现还有很多对象存活，没多少内存可以被回收，就会增大第0代的预算。\n同样的启发性算法调整预算适用于了第1代和第2代的预算。\n引自：《CLR VIA C# -21章》\n自动内存管理\n垃圾回收的基础\n代数\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23.net%E6%89%98%E7%AE%A1%E5%A0%86%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","title":"C#.NET托管堆和垃圾回收"},{"content":"托管堆和垃圾回收(续) 大对象 CLR将对象分成大对象和小对象。目前认为85000字节或者更大的对象是大对象。CLR以不同方式对待大小对象。\n大对象不是在小对象的地址空间分配的，而是在进程地址空间的其他地方分配。\n目前版本的GC不“压缩”大对象，因为在内存中移动它们代价过高。但这可能在进程中的大对象之间造成地址空间碎片化，以至于抛出OutMemoryException。CLR将来的版本可能会压缩大对象。\n大对象总是第2代，绝不可能是第0代或者第1代。所以只能为需要长时间存活的资源创建大对象。分配短时间存活的大对象会导致第2代被更频繁地回收，损失性能。大对象一般是大字符串（XML/JSON）或者用于I/O操作的字节数组（从文件/网络将字节读入缓冲区以便处理）。\n垃圾回收模式 CLR启动时会选择一个GC模式，进程中之前该模式都不会改变。\n有两个基本GC模式。\n工作站 该模式针对客户端应用程序优化GC。GC造成的延时很低，应用程序线程挂起时间很短，避免用户感到焦虑。在该模式中,GC假定机器上运行的其他应用程序都不会消耗太多的CPU资源。 服务器 该模式针对服务器端应用程序优化GC。被优化的主要是吞吐量和资源利用。GC假定机器上没有运行其他应用程序（无论客户端还是服务器应用程序），并假定机器的所有CPU都可以用来辅助完成GC。该模式造成托管堆被拆分成几个区域，每个CPU一个。开始垃圾回收时，垃圾回收器在每个CPU上运行一个特殊线程；每个线程都和其他线程并发回收它自己的区域。对于工作者线程行为一致的服务器应用程序，并发回收能很好进行。这个功能要求应用程序在多CPU计算机上运行，是线程能真正同时工作，从而得到性能上的提升。 应用程序默认以“工作站”GC模式运行。寄宿了CLR的服务器应用程序（如ASP.NET ）可请求CLR加载服务器 GC.但如果应用程序在单处理器计算机上运行，CLR总是使用“工作站”GC模式。\n独立应用程序可以创建一个配置文件告诉CLR 使用CLR使用服务器回收器。配置文件要为应用程序添加gcServer元素。下面是一个示例配置文件：\n1 2 3 4 5 \u0026lt;configuration\u0026gt; \u0026lt;runtime\u0026gt; \u0026lt;gcServer enabled=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/runtime\u0026gt; \u0026lt;/configuration\u0026gt; 可以使用GCSettings类的只读Boolean属性IsServerGC得到CLR是否处于“服务器”GC模式。\n除了这两种模式，GC还支持两种子模式：并发(默认)或者非并发。 在并发方式中，垃圾回收器有一个额外的后台线程，它能在应用程序运行时并发标记对象。 程序运行时，垃圾回收器运行一个普通优先级的后台线程来查找不可达对象。找到之后，垃圾回收器再次挂起所以线程，判断是否要“压缩”内存。如决定压缩，内存会被压缩，根引用会被修正，应用程序线程恢复运行。这一次垃圾回收花费的时间比平常少，因为不可达对象集合已构造好了。但垃圾回收器也可能决定不压缩内存；事实上，垃圾回收器更倾向不压缩。可用内存多，垃圾回收器便不会压缩堆；这有利于增强性能，但会增大程序的工作集。使用并发垃圾回收器，应用程序消耗的内存通常比使用非并发垃圾回收器多。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23.net%E6%89%98%E7%AE%A1%E5%A0%86%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%BB%AD/","title":"C#.NET托管堆和垃圾回收(续)"},{"content":"C#避免在函数或者操作中抛出异常 引言 如某个场景下，你的函数或操作需要操作一个序列的对象，且在处理的过程中抛出了异常。这时如果没有一些状态记录之类的数据，我们不了解已经处理了多少的数据，也不知道应该采用怎么样的策略回滚，因此根本无法返回到之前的状态。 我们看一下下面的一个代码：\n1 2 var allEmp = FindAllEmployees(); allEmp.ForEach(e =\u0026gt; e.MonthlySalary *=1.05M); 这样的代码看起来没什么问题。可是某一天，这个程序运行时抛出了异常。抛出异常的位置可能未知，导致部分员工得到了加薪，另外的一些员工却没有。结果是除了人工检查数据，我们已经没有办法重新找回丢失的状态。\n这样的代码修改元素的方式导致发生了上面的问题。这段代码并没有遵循“强异常安全保证”规则。换而言之，在运行时遇到错误，我们无法得知具体发生了什么，没有发生什么。\n原则：如果我们能保证当方法无法完成时，程序的状态不会发生改变，这样的问题就不会发生。 我们有几种方法都可以实现这样的需求，但是每种方法都有各自的优势和风险。\n在函数/操作中抛出异常 显而易见的，不是所有的方法都会遇到这样的问题（异常导致状态丢失）。很多时候我们只是检查了一下序列中的元素，访问之后并不会修改其中的元素。这类的行为我们其实并不需要太过于小心。现在我们回到最开始的地方，对于上面的场景（为每位员工加薪百分之五），如果我们想遵循“强异常安全保证”原则，那应该如何修改这个方法呢？\n第一种异常：获取数据的时候异常 在上面的例子中，即使FindAllEmployees()函数抛出异常，导致我们无法正确让员工加薪。虽然这样的情况并不是导致我们的数据产生问题，但是该加薪的大家没有得到加薪，这是一个多么沮丧的事情呢。\n解决方法：重写前面以lambda表达式给出的操作方法（即FindAllEmployees()方法），让其永远不会抛出异常。 很多时候，我们在开始修改数据之前，先校验数据的合法性以及剔除错误数据（如果允许剔除的话）并不是非常困难。我们是可以采取这样的方法来实现我们的目的。不过在这里的话，我们就必须严格处理操作方法，使得它能满足所有情况下的需求。\n第二种异常：lambda表达式中操作数据异常 同样是上面的例子，如果我们在执行加薪操作的时候，提升了那些已经离职的员工薪资导致了异常，使得程序中断，状态丢失。这样的情况，我们在执行加薪操作前先过滤掉已离职的员工便是一种正确的做法。\n解决方法：操作数据前通过校验过滤后再执行操作 如： allEmp.Where(emp=\u0026gt;emp.Active).ForEach(e =\u0026gt; e.MonthlySalary *=1.05M);\n第三种异常：执行操作的时候抛出异常 有时候，我们根本无法保证处理方法的时候会不会抛出异常。这个时候就必须采取一些代价更加昂贵的处理方法了。\n解决方法：创建副本尝试执行操作，副本无误后执行真正操作 我们在编写这类代码的时候，应该考虑抛出异常之后的处理方案。这就意味着，我们的操作应该先在原数据副本上执行，随后仅在操作成功之后再将其替换原有的数据。 如:\n1 2 3 4 5 6 7 8 9 var updatas = (from e in allEmp select new Emp { EmpID=e.EmpID, ..... MonthlySalary =e.MonthlySalary *=1.05M }).ToList(); allEmp = updatas; 但是这样的修改也引发了其他的问题：代码量增加了，同时生成副本也消耗了大量的资源。这样的做法也有一个好处，我们在操作副本数据时遇到异常之后，有充分的\u0026quot;空间\u0026quot;来处理这些数据。\n实际中，这意味着我们让查询表达式返回了新序列，而不是去修改原先序列中的元素。这样的话，我们在尝试完成所有的操作的同时，即使失败了，也不会影响到我们程序的原有状态。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23%E9%81%BF%E5%85%8D%E5%9C%A8%E5%87%BD%E6%95%B0%E6%88%96%E8%80%85%E6%93%8D%E4%BD%9C%E4%B8%AD%E6%8A%9B%E5%87%BA%E5%BC%82%E5%B8%B8/","title":"C#避免在函数或者操作中抛出异常"},{"content":"C# 类字段与类属性 字段 字段表示只读或可读/可写的数据值。 字段可以是静态的，这种字段被认为是类型状态的一部分。 字段也可以是实例（非静态），这种字段被认为是对象状态的一部分。 强烈建议把字段声明为私有，防止类型或对象的状态被类型外部代码破坏。 属性 属性允许用简单的、字段风格的语法设置或查询类型或对象的逻辑状态，同时保证状态不被破坏。 作用于类型称为静态属性，作用于对象称为实例属性。 属性可以无参，也可以有多个参数（相当少见，但集合类用的多）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 using System; public sealed class SomeType { // 1 // Nested class private class SomeNestedType { } // 2 // Constant, read­only, and static read/write field private const Int32 c_SomeConstant = 1; // 3 private readonly String m_SomeReadOnlyField = \u0026#34;2\u0026#34;; // 4 private static Int32 s_SomeReadWriteField = 3; // 5 // Type constructor static SomeType() { } // 6 // Instance constructors public SomeType(Int32 x) { } // 7 public SomeType() { } // 8 // Instance and static methods private String InstanceMethod() { return null; } // 9 public static void Main() { } // 10 // Instance property public Int32 SomeProp { // 11 get { return 0; } // 12 set { } // 13 } // Instance parameterful property (indexer) public Int32 this[String s] { // 14 get { return 0; } // 15 set { } // 16 } // Instance event public event EventHandler SomeEvent; // 17 } ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23%E7%B1%BB%E5%AD%97%E6%AE%B5%E4%B8%8E%E7%B1%BB%E5%B1%9E%E6%80%A7/","title":"C#类字段与类属性"},{"content":"可能是因为我们都习惯于明确定义，一般而言,日常我们很少使用匿名对象。 然而对于实现那些短时间存在的、并不在应用程序逻辑中起支配地位的类型，使用匿名对象就是一个不错的选择了另一个方面，可能也是因为匿名类型的生命周期无法跨越包含改类型的方法，导致很多人觉得匿名对象并不好用，因为其无法在多个方法之间传递。\n这样说并不准确。我们完全可以为匿名类型编写泛型方法。不过若是如此，我们便不能在泛型类型方法中处理任何特殊的元素或者编写任何的专门逻辑。 下面我们就来写一个简单的示例，示例功能：返回集合中与待查找对象相等的所有元素。\n1 2 3 4 5 6 7 8 static IEnumerable\u0026lt;T\u0026gt; FindValue(IEnumerable\u0026lt;T\u0026gt; enumerable, T value) { foreach (T element in enumerable) { if (element.Equals(value)) yield return element; } } 这个方法是可以配合匿名类型使用的，但是这个方法本质上其实就是一个泛型方法，并不了解匿名类型的信息。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/c%23%E4%B8%BA%E5%8C%BF%E5%90%8D%E7%B1%BB%E5%9E%8B%E5%AE%9A%E4%B9%89%E5%B1%80%E9%83%A8%E5%87%BD%E6%95%B0/","title":"C#为匿名类型定义局部函数"},{"content":"CLR为每个 ApDomain 都提供了一个 GC句柄表（GC Handle table），允许应用程序监视或者手动控制对象的生存期。这个表在 ApDomain 创建之初是空白的。\n表中每个记录项都包含一下两种信息：\n对托管堆中的一个对象的引用，以及之初如何监视或者控制对象的标志（flag）。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/clr-%E6%89%8B%E5%8A%A8%E7%9B%91%E6%8E%A7%E5%92%8C%E6%8E%A7%E5%88%B6%E5%AF%B9%E8%B1%A1%E7%9A%84%E7%94%9F%E5%AD%98%E5%91%A8%E6%9C%9F/","title":"CLR 手动监控和控制对象的生存周期"},{"content":"对于.NET平台上的代码生成器来说，codesmith是一个非常好的选择。\n以前在学院实验室用的都是SQL server数据库，老师给的一套codesmith模板用来生成model/DAL/BLL很是方便。\r不过后来放弃SQL server 投入MySQL之后，刚开始都是手写SQL，还是很痛苦的。\r再后来又去找MySQL codesmith模板,这个对应的资料就不多了。不过最后还是找到了一套不错的，凑合能用。起初也懒，codesmith语法不熟，就没想过去修改一下了。\r最近又要用到这套东西，于是决定还是去修改一番，更便于使用。\r这个文章就主要讲一下修改过程，顺便说一下codesmith的简单语法。\n先说一下操作步骤：\n把模板的文件夹扔到codesmith模板文件的路径下，接着打开Codesmith，找到刚扔过去的文件夹，选择Main.cst,右键-execute-选择对应的MySQL库-选中表。 （注：codesmith连接MySQL有问题的话， 移步这里解决 CodeSmith 连接MySQL数据库报“can\u0026rsquo;t find .net framework data provider”)\n如下图： 然后点击Generate就能顺利生成model/dal/bll了。\n生成代码结构如下： 这样操作没什么问题，顺利生成了我们要的model/dal/bll了，然后....我懒嘛。\r每次都要把表一个个选一次，麻不麻烦啊。然后就想了，能不能改一下模板呢。于是便开始google相关资料了。找到了几个相关文章，参考这就开始改造了。\r先看看原来的Main.cst里面写了撒。\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;%@ CodeTemplate Language=\u0026#34;C#\u0026#34; ResponseEncoding=\u0026#34;UTF-8\u0026#34; TargetLanguage=\u0026#34;Text\u0026#34; Src=\u0026#34;\u0026#34; Inherits=\u0026#34;\u0026#34; Debug=\u0026#34;False\u0026#34; Description=\u0026#34;Template description here.\u0026#34; Output=\u0026#34;None\u0026#34;%\u0026gt; \u0026lt;%@ Register Name=\u0026#34;Models\u0026#34; Template=\u0026#34;DBMad.Models.cst\u0026#34; MergeProperties=\u0026#34;False\u0026#34; ExcludeProperties=\u0026#34;\u0026#34; %\u0026gt;\t\u0026lt;%@ Register Name=\u0026#34;DAL\u0026#34; Template=\u0026#34;DBMad.DAL.cst\u0026#34; MergeProperties=\u0026#34;False\u0026#34; ExcludeProperties=\u0026#34;\u0026#34; %\u0026gt; \u0026lt;%@ Register Name=\u0026#34;BLL\u0026#34; Template=\u0026#34;DBMad.BLL.cst\u0026#34; MergeProperties=\u0026#34;False\u0026#34; ExcludeProperties=\u0026#34;\u0026#34; %\u0026gt; \u0026lt;%@ Property Name=\u0026#34;SourceTable\u0026#34; Type=\u0026#34;SchemaExplorer.TableSchema\u0026#34; Optional=\u0026#34;False\u0026#34;%\u0026gt; \u0026lt;%@ Property Name=\u0026#34;RootNamespace\u0026#34; Default=\u0026#34;Net.Itcast.CN\u0026#34; Type=\u0026#34;System.String\u0026#34; Optional=\u0026#34;False\u0026#34;%\u0026gt; \u0026lt;%@ Assembly Name=\u0026#34;SchemaExplorer\u0026#34; %\u0026gt; \u0026lt;%@ Assembly Name=\u0026#34;System.Data\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;SchemaExplorer\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;System.Data\u0026#34; %\u0026gt; \u0026lt;script runat=\u0026#34;template\u0026#34;\u0026gt; private string _outputDirectory = String.Empty; [Editor(typeof(System.Windows.Forms.Design.FolderNameEditor), typeof(System.Drawing.Design.UITypeEditor))] [Description(\u0026#34;The directory to output the results to.\u0026#34;)] public string OutputDirectory { get {\treturn _outputDirectory; } set { if (value != null \u0026amp;\u0026amp; !value.EndsWith(\u0026#34;\\\\\u0026#34;)) { value += \u0026#34;\\\\\u0026#34;; } _outputDirectory = value; } } \u0026lt;/script\u0026gt; 这一段基本就是在声明选项以及引用命名空间，表现出来的便是我们看到的下图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026lt;% Models model = this.Create\u0026lt;Models\u0026gt;(); model.ModelsNamespace = this.RootNamespace+\u0026#34;.Model\u0026#34;; model.TargetTable = this.SourceTable; model.RenderToFile(this.OutputDirectory+\u0026#34;Model/\u0026#34;+model.GetFileName(),true); DAL dal = this.Create\u0026lt;DAL\u0026gt;(); dal.TargetTable = this.SourceTable; dal.ModelsNamespace = model.ModelsNamespace; dal.DALClassNameSurfix = \u0026#34;DAL\u0026#34;; dal.DALNamespace =this.RootNamespace+\u0026#34;.DAL\u0026#34;; dal.RenderToFile(this.OutputDirectory+\u0026#34;DAL/\u0026#34; +dal.GetFileName(),true); BLL bll = this.Create\u0026lt;BLL\u0026gt;(); bll.ModelsNamespace = model.ModelsNamespace; bll.DALClassNameSurfix = dal.DALClassNameSurfix; bll.DALNamespace = dal.DALNamespace; bll.BLLClassNameSurfix = \u0026#34;BLL\u0026#34;; bll.BLLNamespace = this.RootNamespace+\u0026#34;.BLL\u0026#34;; bll.TargetTable = this.SourceTable; bll.RenderToFile(this.OutputDirectory+\u0026#34;BLL/\u0026#34; +bll.GetFileName(),true); Response.Write(\u0026#34;ok,see \u0026#34;+this.OutputDirectory); %\u0026gt; 这一段就是我们点击Generate之后执行的代码，基本功能就是调用 DBMad.Models.cst,DBMad.DAL.cst,DBMad.BLL.cst。 因为在上面声明数据源的时候，使用了SchemaExplorer.TableSchema，导致我们选择表的时候不能多选。代码如下：\n\u0026lt;%@ Property Name=\u0026ldquo;SourceTable\u0026rdquo; Type=\u0026ldquo;SchemaExplorer.TableSchema\u0026rdquo; Optional=\u0026ldquo;False\u0026rdquo;%\u0026gt;\n这样一想，这个Main.cst就是一个可以处理单表的生成模板了，我们只要自己写一个可以多选表的模板，然后循环调用这个模板去生成，不就完事了？\n找了一下资料，发现只需要把上面的选项Type改一下，便可以多选表了。\n如下：\n\u0026lt;%@ Property Name=\u0026ldquo;SourceTables\u0026rdquo; Type=\u0026ldquo;SchemaExplorer.TableSchemaCollection\u0026rdquo; Default=\u0026quot;\u0026quot; Optional=\u0026ldquo;False\u0026rdquo; Category=\u0026quot;\u0026quot;%\u0026gt;\n整体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u0026lt;%@ CodeTemplate Language=\u0026#34;C#\u0026#34; ResponseEncoding=\u0026#34;UTF-8\u0026#34; TargetLanguage=\u0026#34;Text\u0026#34; Src=\u0026#34;\u0026#34; Inherits=\u0026#34;\u0026#34; Debug=\u0026#34;False\u0026#34; Description=\u0026#34;Template description here.\u0026#34; Output=\u0026#34;None\u0026#34;%\u0026gt; \u0026lt;%@ Property Name=\u0026#34;SourceTables\u0026#34; Type=\u0026#34;SchemaExplorer.TableSchemaCollection\u0026#34; Default=\u0026#34;\u0026#34; Optional=\u0026#34;False\u0026#34; Category=\u0026#34;\u0026#34;%\u0026gt; \u0026lt;%@ Register Name=\u0026#34;SE\u0026#34; Template=\u0026#34;CreatSingleTable.cst\u0026#34; MergeProperties=\u0026#34;False\u0026#34; ExcludeProperties=\u0026#34;\u0026#34; %\u0026gt; \u0026lt;%@ Property Name=\u0026#34;RootNamespace\u0026#34; Default=\u0026#34;Net.Itcast.CN\u0026#34; Type=\u0026#34;System.String\u0026#34; Optional=\u0026#34;False\u0026#34;%\u0026gt; \u0026lt;%@ Assembly Name=\u0026#34;SchemaExplorer\u0026#34; %\u0026gt; \u0026lt;%@ Assembly Name=\u0026#34;System.Data\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;SchemaExplorer\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;System.Data\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;System.Collections\u0026#34; %\u0026gt; \u0026lt;script runat=\u0026#34;template\u0026#34;\u0026gt; private string _outputDirectory = String.Empty; [Editor(typeof(System.Windows.Forms.Design.FolderNameEditor), typeof(System.Drawing.Design.UITypeEditor))] [Description(\u0026#34;The directory to output the results to.\u0026#34;)] public string OutputDirectory { get {\treturn _outputDirectory; } set { if (value != null \u0026amp;\u0026amp; !value.EndsWith(\u0026#34;\\\\\u0026#34;)) { value += \u0026#34;\\\\\u0026#34;; } _outputDirectory = value; } } \u0026lt;/script\u0026gt; \u0026lt;% foreach(TableSchema ts in SourceTables) { SE s = new SE(); s.SourceTable = ts; s.RootNamespace = RootNamespace; s.OutputDirectory = OutputDirectory; s.Render(this.Response); } %\u0026gt; \u0026lt;script runat=\u0026#34;template\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 前面一部分还是一样的声明，\n\u0026lt;%@ Property Name=\u0026ldquo;SourceTables\u0026rdquo; Type=\u0026ldquo;SchemaExplorer.TableSchemaCollection\u0026rdquo; Default=\u0026quot;\u0026quot; Optional=\u0026ldquo;False\u0026rdquo; Category=\u0026quot;\u0026quot;%\u0026gt;\n这一句把选项类型修改成可多选的（既 集合）。 效果如下图： 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;% foreach(TableSchema ts in SourceTables) { SE s = new SE(); s.SourceTable = ts; s.RootNamespace = RootNamespace; s.OutputDirectory = OutputDirectory; s.Render(this.Response); } %\u0026gt; \u0026lt;script runat=\u0026#34;template\u0026#34;\u0026gt; \u0026lt;/script\u0026gt; 这一段代码便是获取刚得到的表集合，遍历集合然后依次调用之前的单表生成模板。\n到这里差不多已经完成了我要的效果，选择多表，实现一次生成所有的表对应的model/dal/bll。\n这个效果基本就是我要的了，但是后来又发现，model里面的字段居然没有注释，我在建表的时候写了字段注释的呀。\n打开model的cst文件之后发现，模板并没有做注释这个工作。 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 \u0026lt;%@ CodeTemplate Language=\u0026#34;C#\u0026#34; TargetLanguage=\u0026#34;C#\u0026#34; Src=\u0026#34;ToolsCodeTemplate.cs\u0026#34; Inherits=\u0026#34;ToolsCodeTemplate\u0026#34;%\u0026gt; \u0026lt;%@ Property Name=\u0026#34;TargetTable\u0026#34; Type=\u0026#34;SchemaExplorer.TableSchema\u0026#34; Category=\u0026#34;Context\u0026#34; Description=\u0026#34;TargetTable that the object is based on.\u0026#34; %\u0026gt; \u0026lt;%@ Property Name=\u0026#34;ModelsNamespace\u0026#34; Default=\u0026#34;Model\u0026#34; Type=\u0026#34;System.String\u0026#34; Category=\u0026#34;Context\u0026#34; Description=\u0026#34;TargetTable that the object is based on.\u0026#34; %\u0026gt; \u0026lt;%@ Assembly Name=\u0026#34;SchemaExplorer\u0026#34; %\u0026gt; \u0026lt;%@ Assembly Name=\u0026#34;System.Data\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;SchemaExplorer\u0026#34; %\u0026gt; \u0026lt;%@ Import Namespace=\u0026#34;System.Data\u0026#34; %\u0026gt; \u0026lt;% PrintHeader(); %\u0026gt; using System; using System.Collections.Generic; using System.Text; namespace \u0026lt;%= ModelsNamespace %\u0026gt; {\t[Serializable()] public class \u0026lt;%= GetModelClassName() %\u0026gt; { \u0026lt;% foreach (ColumnSchema column in TargetTable.Columns) { %\u0026gt; private \u0026lt;%= GetPropertyType(column) %\u0026gt; _\u0026lt;%= GetPropertyName(column) %\u0026gt;;\t\u0026lt;% } %\u0026gt; \u0026lt;% foreach (ColumnSchema column in TargetTable.Columns) { %\u0026gt; public \u0026lt;%= GetPropertyType(column) %\u0026gt; \u0026lt;%= GetPropertyName(column) %\u0026gt; { get { return _\u0026lt;%= GetPropertyName(column) %\u0026gt;; } set { _\u0026lt;%= GetPropertyName(column) %\u0026gt; = value; } } \u0026lt;% } %\u0026gt;\t} } \u0026lt;script runat=\u0026#34;template\u0026#34;\u0026gt; public string GetModelClassName() { return GetModelClassName(TargetTable); } public override string GetFileName() { return this.GetModelClassName(this.TargetTable) + \u0026#34;.cs\u0026#34;; } \u0026lt;/script\u0026gt; 获取表中字段名使用的是GetPropertyName(column)，咦，在哪实现了这个东西呢？回去翻一下文件，哦，还有一个ToolsCodeTemplate.cs文一直没管呢。\n果然，GetPropertyName(column)在这里。\n1 2 3 4 5 6 7 8 9 public string GetPropertyName(ColumnSchema column) { return GetNameFromDBFieldName(column); } public string GetNameFromDBFieldName(ColumnSchema column) { return column.Name; } 读取列名就是这么简单，那么我们对应写一个函数读取一下列注释，然后再model里面调用一下不好了。\n又查了一下资料，\n1 2 3 4 public string GetColumnComment(ColumnSchema column) { return column.Description; } 嗯，理论上这样是可以的\u0026hellip; 然而，我想多了。倒腾了好久，这个属性值都是空的\u0026hellip; google了一圈之后发现，原来是SchemaExplorer.MySQLSchemaProvider.dll 里面压根没实现读取列注释的实现\u0026hellip;.\n不过也有对应的解决方法：\n完美解决CodeSmith无法获取MySQL表及列Description说明注释的方案\n把DLL替换一下就好了。\n最后附上模板连接:CodeSmith-for-MySQL-Template\n注：\n模板会把MySQL的表名前三个字符截取掉，建议把表明设置为tbl开头，或者自行修改模板文件。 想让字段注释生效记得替换SchemaExplorer.MySQLSchemaProvider.dll(替换前记得备份！) ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/codesmith-for-mysql-template/","title":"CodeSmith for MySQL template"},{"content":"1、下载 mysql-connector-net 安装\nmysql-connector-net\n2、mysql-connector-net 安装完毕之后，到对应的安装目录下，把对应的MySQL .NET dll拷贝到 CodeSmith的bin目录和SchemaProviders目录。\n一般DLL所在目录是：\nC:\\Program Files (x86)\\MySQL\\MySQL Connector Net 6.9.8\\Assemblies\\v4.0\n3、重启CodeSmith生效\n其余解决方案： codesmith无法连接Mysql的解决方法\ncodesmith6.5连接Mysql提示“找不到请求的 .Net Framework Data Provider。可能没有安装。”解决方法\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/codesmith-%E8%BF%9E%E6%8E%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%A5cant-find-.net-framework-data-provider/","title":"CodeSmith 连接MySQL数据库报“can't find .net framework data provider”"},{"content":"先看一段代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #region test1 闭包 public static void test1() { int index = 0; Func\u0026lt;IEnumerable\u0026lt;int\u0026gt;\u0026gt; sequence =()=\u0026gt;GetEnumrableInt(index); index = 20; foreach(int n in sequence()) Console.WriteLine(n); Console.WriteLine(\u0026#34;Done\u0026#34;); index = 100; foreach (int n in sequence()) Console.WriteLine(n); } public static IEnumerable\u0026lt;int\u0026gt; GetEnumrableInt(int index) { List\u0026lt;int\u0026gt; l = new List\u0026lt;int\u0026gt;(); for(int i=index;i\u0026lt;index+30;i++) { l.Add(i); } return l; } #endregion 上面一坨代码演示了在闭包中使用了外部变量，随即又在外部修改了这些变量的情况，得到的结果是输出了20-50的数，然后又输出了100-130之间的数。这种行为有点诡异，但是确实有存在的意义\u0026hellip;(书本这样说的，我到觉得很少会用到。)\n为了将查询表达式转换成可执行代码，C#编译器做了很多工作。一般而言，C#编译器将查询和lambda表达式转换成 \u0026ldquo;静态委托\u0026rdquo;、\u0026ldquo;实例委托\u0026rdquo; 或 \u0026ldquo;闭包\u0026rdquo;。编译器将根据lambda表达式中的代码选择一种实现方式。选择哪种方式依赖于lambda表达式的主体（body）。这看上去似乎是一些语言上的实现细节，但它却会显著地影响到我们的代码。编译器选择何种实现将可能导致diamante行为发生微妙的变化。\n并不是任何的lambda表达式都会生成同样结构的代码。\n对于编译器来说，最简单的一种行为是为以下形式的代码生成委托。\n1 2 3 4 5 6 7 8 9 10 11 12 //我们的lambda表达式 public static void test2() { int[] someNum = {0,1,2,3,4,5,6,7,8,9,10 }; IEnumerable\u0026lt;int\u0026gt; ans = from n in someNum select n * n; foreach (int i in ans) Console.WriteLine(i); } 编译器将使用静态委托来实现n*n的lambda表达式，其为上面代码生成的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //编译器为我们的lambda生成的代码 #region 等价于 test2() private static int HiddenFunc(int n) { return n * n; } //静态委托 private static Func\u0026lt;int, int\u0026gt; HiddenDelegate; public void test2_1() { int[] someNum = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 }; if(HiddenDelegate==null) { HiddenDelegate = new Func\u0026lt;int, int\u0026gt;(HiddenFunc); } IEnumerable\u0026lt;int\u0026gt; ans = someNum.Select\u0026lt;int, int\u0026gt;(HiddenDelegate); foreach(int i in ans) Console.WriteLine(i); } #endregion 这个lambda表达式主体部分并没有访问任何的实例变量或者局部变量。lambda表达式仅仅访问了它的参数。对于这种情况，C#编译器将创建一个静态方法，作为委托的目标。这也是编译器执行的最简单的一种处理方式。若表达式可以通过私有的静态方法实现，那么编译器将生成该私有的静态方法以及相对应的委托定义。对于上面的代码例子中的情况以及仅访问了静态变量的表达式，编译器都会采用这样的方案。\n接下来介绍另一种较为简单的情况： lambda表达式需要访问类型的实例变量，但无需访问外层方法中的局部变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 public class ModFilter { private readonly int modules; public ModFilter(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { return from n in sequence where n % modules == 0 //新添加的表达式 select n * n; //和前面的例子是一样的 } } /* 在这种情况下，编译器将为表达式创建一个实例方法来包装该委托。 其基本概念和前一种情况一致，只是这里使用了实例方法，以便读取并修改当前对象的状态。 与静态委托的例子一样，这里编译器将把lambda表达式转换成我们熟悉的代码。其中包含委托的定义以及方法调用。 如下： */ public class ModFilter_Other { private readonly int modules; //实例方法 private bool WhereClause(int n) { return ((n%this.modules) ==0); } private static int SelectClause(int n) { return n * n; } private static Func\u0026lt;int, int\u0026gt; SelectDelegate; public ModFilter_Other(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { if(SelectDelegate==null) { SelectDelegate = new Func\u0026lt;int, int\u0026gt;(SelectClause); } return sequence.Where\u0026lt;int\u0026gt;( new Func\u0026lt;int, bool\u0026gt;(this.WhereClause)). Select\u0026lt;int, int\u0026gt;(SelectClause); } } 概括来说便是：lambda表达式中的代码访问了对象实例中的成员变量，那么编译器将生成实例方法来表示lambda表达式中的代码。其实这并没有什么奇特之处——编译器省去了我们的一些代码输入工作，代码也变得整洁很多，本质来说这还是普通的方法调用。\n不过若是lambda表达式中访问到了外部方法中的局部变量或者方法参数，那么编译器将帮你完成很多工作。\n这里会用到闭包。编译器将生成一个私有的嵌套类型，以便为局部变量实现闭包。\n局部变量必须传入到实现了lambda表达式主体部分的委托里。\n此外，所有由该lambda表达式执行的对这些局部变量所作的修改都必须能够在外部访问到。\n当然，代码中内层和外层中共享的可能不止有一个变量，也可能不止一个的查询表达式。\n我们来修改一下该实例方法，让其访问一个局部变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 public class ModFilter { private readonly int modules; public ModFilter(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { int numValues = 0; return from n in sequence where n % modules == 0 //新添加的表达式 select n * n / ++ numValues; //访问局部变量 } } 注意，select字句需要访问numValues这个局部变量。编译器为了创建这个闭包，需要使用嵌套类型来实现你所需要的行为。下面展示的是编译器为你生成的代码。 public class ModFilter { private sealed class Closure { public ModFilter outer; public int numValues; public int SelectClause(int n) { return ((n * n) / ++this.numValues); } } private readonly int modules; //实例方法 private bool WhereClause(int n) { return ((n % this.modules) == 0); } public ModFilter(int mod) { modules = mod; } public IEnumerable\u0026lt;int\u0026gt; FindValues(IEnumerable\u0026lt;int\u0026gt; sequence) { Closure c = new Closure(); c.outer = this; c.numValues = 0; return sequence.Where\u0026lt;int\u0026gt;( new Func\u0026lt;int, bool\u0026gt;(this.WhereClause)). Select\u0026lt;int, int\u0026gt;(c.SelectClause); } } 在上面这段代码中，编译器专门创建了一个嵌套类，用来容纳所有将在lambda表达式中访问或修改的变量。实际上，这些局部变量将完全被嵌套类的字段所代替。lambda表达式内部的代码以及表达式外部(但仍在当前方法内)的代码访问的均是同一个字段，lambda表达式中的逻辑也被编译成了内部类的一个方法。\n对于lambda表达式中将要用到的外部方法的参数，编译器也会以对待局部变量的方式实现：编译器将这些参数复制到表示该闭包的嵌套类中。\n回到最开始的那个示例，这是我们应该可以理解这种看似怪异的行为了。变量index在传入闭包后，但在查询开始执行前曾被外部代码修改。也就是说，你修改了闭包的内部状态，然后还期待其能够回到从前的状态开始执行，显然这是不可能实现的。\n考虑到延迟执行中的交互以及编译器实现闭包的方式，修改查询与外部代码之间绑定的变量将可能会引发错误的行为。 因此，我们应该尽量避免在方法中修改哪些将要传入到闭包中，并将在闭包中使用的变量。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/dotnet-lmabda%E9%81%BF%E5%85%8D%E4%BF%AE%E6%94%B9%E7%BB%91%E5%AE%9A%E5%8F%98%E9%87%8F/","title":"dotnet lmabda避免修改绑定变量"},{"content":"众所周知，在HTTPS页面请求HTTP资料的时候，现代浏览器会拦截，提示用户是否继续，或者直接拦截，提示都不出来。\n最近给自己做了个快速书签工具，点击书签就直接把书签发送到服务器地址，然后保存到我的网站中。\n一开始一切都挺正常的，不过遇到了https的网站的时候，就跪掉了。\n开始的时候看到HTTPS证书是收费的，想想还是算了，反正凑合能用就是。前几天偶尔看到有一个免费申请HTTPS的开源软件，喵了一下看起来还不错，这几天有空了立马开干。下面有一个教程，我申请证书差不多就是按照这个来处理的。\n用Let’s Encrypt获取免费证书\n关于这个Let\u0026rsquo;s Encrypt，维基百科是这样介绍的：\nLet\u0026rsquo;s Encrypt 是一个将于2015年末推出的数字证书认证机构，将通过旨在消除当前手动创建和安装证书的复杂过程的自动化流程，为安全网站提供免费的SSL/TLS证书。 Let\u0026rsquo;s Encrypt 是由互联网安全研究小组（ISRG，一个公益组织）提供的服务。主要赞助商包括电子前哨基金会，Mozilla基金会，Akamai以及思科。2015年4月9日，ISRG与Linux基金会宣布合作。用以实现这一新的数字证书认证机构的协议被称为自动证书管理环境（ACME）。 GitHub上有这一规范的草案，且提案的一个版本已作为一个Internet草案发布。Let\u0026rsquo;s Encrypt 宣称这一过程将十分简单、自动化并且免费。 2015年8月7日，该服务更新其推出计划，预计将在2015年9月7日当周某时发布首个证书，随后向列入白名单的域名发行少量证书并逐渐扩大发行。若一切按计划进行，该服务预计将在2015年11月16日当周某时全面开始提供.\n整个项目在Github有代码，主要是通过客户端来为我们的网站生成https证书。 首先我们先下载客户端，如下：\n1 git clone https://github.com/letsencrypt/letsencrypt.git 接着进入这个仓库内，执行下面代码：\n1 2 3 ./letsencrypt-auto certonly -a webroot\\ --webroot-path 网站所在路径(如：/var/www/web/) \\ -d 你的域名(如：test.online) -d www.你的域名(如ww.test.online) 这里需要注意的事，我这里为了排版，给上面的命令加了换行，运行这个命令的时候记得把换行符去掉。 换行符在webroot、-d 前面各有一个。\n一切顺利的话，我们在/etc/letsencrypt/live/域名/这个目录下能看到四个文件，分别是：\n域名证书文件 签发域名证书的证书链文件 域名证书+证书链文件 私钥文件 如下图： 接着就是为网站设置证书了。\nJexus设置HTTPS要更改jws.conf文档以及网站的配置文档。\n操作步骤如下：\n修改jws.conf 进入Jexus文件夹中，打开 “jws.conf”，添加下面两句： 1 2 CertificateFile = /etc/letsencrypt/live/域名/fullchain.pem CertificateKeyFile = /etc/letsencrypt/live/域名/privkey.pem 修改之后效果图如下： 开启网站的HTTPS功能 进入siteconf/文件夹，找到对应的网站conf文件，\n把网站服务端口改为443： port=443\n启用https： UseHttps=true\n修改之后的效果图如下： 然后重启jexus即可。\n完了之后，通过HTTPS即可访问。\n最后上一个HTTPS证书的图证明一下这个是可行的。 撒花，下次再见。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/jexus%E6%94%AF%E6%8C%81https%E5%8D%8F%E8%AE%AE/","title":"Jexus支持HTTPS协议"},{"content":"最近安装Microsoft .NET Core 1.0.0 VS 2015 Tooling Preview 2实在有点曲折，忍不住写个文章来讲这货的坑爹之旅了。\n一般我们在.NET Downloads 下载回来的Microsoft .NET Core 1.0.0 VS 2015 Tooling Preview 2是一个简易安装包。\n它在安装过程中会不断去网络请求需要的msi文件，美名曰：在线安装。\n然而在我国的国情以及我国网络运营商的衬托下，在线安装这种东西实在不可恭维。\n本来网络稳定，在线安装 这种鬼也还算能用，不过最近微软爸爸不知道为嘛了，.net core相关安装包的下载地址全线失效。 如DotNetCore.1.0.1-SDK.1.0.0.Preview2-003133-x64.exe，直接出502 Bad Gateway。\n这个还能用迅雷或者命令行下载回来，但是DotNetCore.1.0.1-SDK.1.0.0.Preview2这货安装过程中需要的一下msi安装包，就死活下不回来了。\n安装过程报错：0x80070003 系统找不到需要的文件。 此处已确认是微软爸爸的bug了。issue在这里\n分析log 我们去看安装失败的log，能看到类似下面的log：\nError 0x80072efd: Failed attempt to download URL: \u0026lsquo;https://download.microsoft.com/download/A/3/8/A38489F3-9777-41DD-83F8-2CBDFAB2520C/packages/ancm_iis_express_x64_en_rc2_39.msi' to: \u0026lsquo;C:\\Users\\cneuss\\AppData\\Local\\Temp{C307771D-8D9A-45B5-B514-B6CA69C0C6E2}\\ANCM_IISExpress_x64\u0026rsquo;\n很明显这个操作从\nhttps://download.microsoft.com/download/A/3/8/A38489F3-9777-41DD-83F8-2CBDFAB2520C/packages/ancm_iis_express_x64_en_rc2_39.msi\n上面下载ancm_iis_express_x64_en_rc2_39.msi文件。\n然而我们点击进去，看到这个同样的问题：502 Bad Gateway。\n安装到这里，已经GG了。\n不过既然知道是因为下载文件的问题了，那么解决办法也应运而生了。\n我们完全手动下载文件（用迅雷或者别的下载工具），发布在本地，改hosts地址让下载请求直接从本地下载文件。\n这个方案听起来是没有任何的问题的，我也成功使用迅雷把无法下载的文件下载到本地了。然而在改host地址这里卡住了。\n不知道为嘛，无论我把download.microsoft.com指向怎么改，也无法把请求重定向到本地。\n后来认真看了下安装log，发现所以的下载操作都是把文件下载到 C:\\Users\\cneuss\\AppData\\Local\\Temp 目录（具体目录看log文件内容）下的临时路径，报错是系统找不到需要的文件。\n那么，我们手动把需要的文件放到对应的位置，问题也就解决了。\n所以，为了清晰找到临时路径，安装之前先把“C:\\Users\\cneuss\\AppData\\Local\\Temp”的文件清空，然后点击安装包。\n很快可以在temp路径下看到冒出来的{xxxxxxxxxxxxx}文件夹，然后迅速把我们通过迅雷下载回来的文件仍到这个目录底下。\n迅速操作的原因是，在线安装包正在下载所需要的文件，如：ancm_iis_express_x64_en_rc2_39.msi，我们要在下载超时之前把文件应该在的位置，这样的话即使下载没拿到文件，安装程序还是可以拿我们的文件去执行安装。\n别的就是不断尝试，看缺少那个msi手动下哪个msi的事情了。\n最终方案 最后，根据log文件，还发现了一个更简单的方法：\n在DotNetCore.1.0.1-SDK.1.0.0.Preview2-003133-x64.exe的同级目录下新建packages文件夹，把上面无法在线下载到的msi仍进去，然后就一路绿灯了。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/microsoft-.net-core-1.0.0-vs-2015-tooling-preview-2-0x80070003/","title":"Microsoft .NET Core 1.0.0 VS 2015 Tooling Preview 2 0x80070003"},{"content":"前几天在做一个使用URL通过WebRequest请求HTML页面的功能的时候遇到了点坑，程序在开发环境没有任何的问题，部署到linux mono上之后就跪了。代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 public static string GetHTML(string url) { string htmlCode; try { HttpWebRequest webRequest = (System.Net.HttpWebRequest)System.Net.WebRequest.Create(url); webRequest.Timeout = 30000; webRequest.Method = \u0026#34;GET\u0026#34;; webRequest.UserAgent = \u0026#34;Mozilla/4.0\u0026#34;; webRequest.Headers.Add(\u0026#34;Accept-Encoding\u0026#34;, \u0026#34;gzip, deflate\u0026#34;); HttpWebResponse webResponse = (System.Net.HttpWebResponse)webRequest.GetResponse(); //获取目标网站的编码格式 string contentype = webResponse.Headers[\u0026#34;Content-Type\u0026#34;]; Regex regex = new Regex(\u0026#34;charset\\\\s*=\\\\s*[\\\\W]?\\\\s*([\\\\w-]+)\u0026#34;, RegexOptions.IgnoreCase); if (webResponse.ContentEncoding.ToLower() == \u0026#34;gzip\u0026#34;)//如果使用了GZip则先解压 { using (System.IO.Stream streamReceive = webResponse.GetResponseStream()) { using (var zipStream = new System.IO.Compression.GZipStream(streamReceive, System.IO.Compression.CompressionMode.Decompress)) { //匹配编码格式 if (regex.IsMatch(contentype)) { Encoding ending = Encoding.GetEncoding(regex.Match(contentype).Groups[1].Value.Trim()); using (StreamReader sr = new System.IO.StreamReader(zipStream, ending)) { htmlCode = sr.ReadToEnd(); } } else { using (StreamReader sr = new System.IO.StreamReader(zipStream, Encoding.UTF8)) { htmlCode = sr.ReadToEnd(); } } } } } else { using (System.IO.Stream streamReceive = webResponse.GetResponseStream()) { using (System.IO.StreamReader sr = new System.IO.StreamReader(streamReceive, Encoding.Default)) { htmlCode = sr.ReadToEnd(); } } } return htmlCode; }catch(Exception ex) { LogHelper.WriteException(\u0026#34;GetHTML\u0026#34;, ex, new { Url = url }); return \u0026#34;\u0026#34;; } } 开发环境在Windows10 + VS2013,整个代码跑起来没什么问题。\n无论是HTTP还是HTTPS协议，网页HTML一样能获取得到。\n网站部署到linux Jexus之后HTTP协议的网站同样可以获取到HTML，遇到HTTPS协议的网站的时候就跪了。\n抓到的异常信息如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 System.Net.WebException: Error: TrustFailure (The authentication or decryption has failed.) ---\u0026gt; System.IO.IOException: The authentication or decryption has failed. ---\u0026gt; System.IO.IOException: The authentication or decryption has failed. ---\u0026gt; Mono.Security.Protocol.Tls.TlsException: Invalid certificate received from server. Error code: 0xffffffff800b0109 at Mono.Security.Protocol.Tls.RecordProtocol.EndReceiveRecord (IAsyncResult asyncResult) \u0026lt;0x41b58d80 + 0x0013e\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at Mono.Security.Protocol.Tls.SslClientStream.SafeEndReceiveRecord (IAsyncResult ar, Boolean ignoreEmpty) \u0026lt;0x41b58cb0 + 0x00031\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at Mono.Security.Protocol.Tls.SslClientStream.NegotiateAsyncWorker (IAsyncResult result) \u0026lt;0x41b72a40 + 0x0023f\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 --- End of inner exception stack trace --- at Mono.Security.Protocol.Tls.SslClientStream.EndNegotiateHandshake (IAsyncResult result) \u0026lt;0x41ba07e0 + 0x000f3\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at Mono.Security.Protocol.Tls.SslStreamBase.AsyncHandshakeCallback (IAsyncResult asyncResult) \u0026lt;0x41ba0540 + 0x00086\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 --- End of inner exception stack trace --- at Mono.Security.Protocol.Tls.SslStreamBase.EndRead (IAsyncResult asyncResult) \u0026lt;0x41b73fd0 + 0x00199\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at Mono.Net.Security.Private.LegacySslStream.EndAuthenticateAsClient (IAsyncResult asyncResult) \u0026lt;0x41b73f30 + 0x00042\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at Mono.Net.Security.Private.LegacySslStream.AuthenticateAsClient (System.String targetHost, System.Security.Cryptography.X509Certificates.X509CertificateCollection clientCertificates, SslProtocols enabledSslProtocols, Boolean checkCertificateRevocation) \u0026lt;0x41b6a660 + 0x00055\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at Mono.Net.Security.MonoTlsStream.CreateStream (System.Byte[] buffer) \u0026lt;0x41b69c30 + 0x00159\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 --- End of inner exception stack trace --- at System.Net.HttpWebRequest.EndGetResponse (IAsyncResult asyncResult) \u0026lt;0x41b67660 + 0x001f9\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at System.Net.HttpWebRequest.GetResponse () \u0026lt;0x41b60920 + 0x0005a\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 at WebBookmarkUI.Commom.HTTPHelper.GetHTML (System.String url) \u0026lt;0x41b59b70 + 0x00235\u0026gt; in \u0026lt;filename unknown\u0026gt;:0 有空的信息基本就是：\nInvalid certificate received from server The authentication or decryption has failed 一开始百思不得其解，为嘛好好的程序在开发环境跑得都好的，到了mono上就挂了，多疑的我还以为是mono的bug。 今天静下心来去找了一下资料，发现Mono的文档有这个问题的描述，认真读了一遍，又去请教了一番宇内流云大大，终于弄懂了是什么回事。 先贴一下相关资料：\nstackoverflow mono-webrequest-fails-with-https\nmono doc security\n这个问题是出现的原因是Windows自带了HTPPS的根证书，linux默认则是没有带有根证书的。我们的mono在调用WebRequest去请求HTTPS协议的网站的时候，抛出上上面的异常了。\n解决方案也很简单，为linux导入一下HTTPS根证书就好。\n在linux服务器上面执行下面这条命令。\n1 mozroots --import --ask-remove --machine 然后在网站的Application_Start()里面添加下面代码：\n1 2 3 4 5 6 7 System.Net.ServicePointManager.ServerCertificateValidationCallback += delegate(object sender, System.Security.Cryptography.X509Certificates.X509Certificate certificate, System.Security.Cryptography.X509Certificates.X509Chain chain, System.Net.Security.SslPolicyErrors sslPolicyErrors) { return true; // **** Always accept }; 完事。\n这个故事告诉我们，linux干活都是要亲力亲为呀。\n","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/mono-webreques-https-exception/","title":"mono webreques https exception"},{"content":"备忘网站 Markdown 语法说明 (简体中文版) Markdown: Basics （快速入门） 使用GitHub和Hexo搭建免费静态Blog(本博客案例) ###安装Hexo\n1 2 3 4 5 npm install hexo-cli -g npm install hexo --save #如果命令无法运行，可以尝试更换taobao的npm源 npm install -g cnpm --registry=https://registry.npm.taobao.org 安装Hexo插件 1 2 3 4 5 6 7 8 9 10 11 12 13 npm install hexo-generator-index --save npm install hexo-generator-archive --save npm install hexo-generator-category --save npm install hexo-generator-tag --save npm install hexo-server --save npm install hexo-deployer-git --save npm install hexo-deployer-heroku --save npm install hexo-deployer-rsync --save npm install hexo-deployer-openshift --save npm install hexo-renderer-marked@0.2 --save npm install hexo-renderer-stylus@0.2 --save npm install hexo-generator-feed@1 --save npm install hexo-generator-sitemap@1 --save win下面的git客户端提示FIlename too long解决方法 1 git config --global core.longpaths true git-ssh 配置和使用 ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%A4%87%E5%BF%98%E7%BD%91%E7%AB%99/","title":"备忘网站"},{"content":"##写在前面\n做爬虫的小伙伴一般都绕不过代理IP这个问题.\nPS:如果还没遇到被封IP的场景，要不就是你量太小人家懒得理你，要不就是人家压根不在乎\u0026hellip;\n爬虫用户自己是没有能力维护一系列的代理服务器和代理IP的，这个成本实在有点高了。 所以公用代理服务器应运而生,现在几大云服务商家都提供代理IP服务，一般论个买\u0026hellip;\n同时网上也有很多代理IP共享网站，会把一些免费的代理IP放出来给大家用。 大家都是做爬虫的，那么，是不是可以先把代理IP网站的数据爬一遍？ 所以可以看到不少的爬代理IP的爬虫，如突破反爬虫的利器——开源IP代理池之类的项目。 这些项目都能达到抓取代理IP数据的目的，很多时候也够用了。\n然而在使用过程中我们发现了一些问题：\n网站公布的代理IP不一定是可用的。可能代理服务器挂了，可能IP无效了\u0026hellip;等等之类的。 代理IP是部分可用的。某代理IP可用代理访问百度，但是代理访问谷歌的时候就GG了。 代理连通性是好的，但是已经被访问站识别为代理IP返回验证码或者辣鸡数据。 proxyipcenter的解决方案 出于以上种种的原因，按耐不住的dalao(@virjar)开始自己动手撸了。\n于是，proxyipcenter出来了。\n这个项目做了什么东西呢？ dalao是这样写的：\nDungProxy是一个代理IP服务,他包括一个代理IP资源server端和一系列适配中心IP资源得客户端。\nserver负责代理IP资源的收集维护。\nclient则是一系列方便用户使用得API,他屏蔽了代理IP下载、代理IP选取、IP绑定、IP切换等比较复杂逻辑。用户只需要引入client即可方便使用代理IP服务\n简单来说：\nserver是一个代理IP爬虫，同时负责简单的数据清洗。\nclient本质是一个代理IP池，获取数据源之后，基于需要代理访问的网站在本地维护一个代理IP池供爬虫使用。\n以下内容转载自http://git.oschina.net/virjar/proxyipcenter, 并已获得相关授权。(PS:dalao写的太好了，我都懒得重新写一遍了\u0026hellip;问过dalao之后直接转载过来算了。)\nproxyipcenter server DrungProxy的代理IP都是从互联网收集,他是架设在一个高度不可用的资源上面的服务。server会负责对这些资源进行清洗、校验、打分,最终输出可以被客户端使用的IP资源。IP资源从入库到最终判定可用生命流程如下\nIP抓取 server监听了很多代理IP网站,这些网站包括国内外十几家,有意思的是drungProxy的IP爬虫是一系列网站模版。五六行配置即可实现一个简单的网站模版,然后我们有一个上层调度模块将会负责调起模版进行数据抓取。 IP消重 需要消重的原因是程序运行到一定时间之后,大量IP都是数据库里面已经存在的了,这个时候如果在数据库进行消重逻辑将会导致大量数据库读写,实际上我们的服务器是一个1块钱的腾讯云(曾经是),看起来是撑不住这么大的请求的(平均每天可以有10K量级)。最后在入库前设置了一个bloomFilter消重模块,能够高效的检测资源是否被入库过。 位置信息完善 这个逻辑不大,通过taobaoIp接口获取地址信息,完善IP资源元数据。taobaoIP IP验证 IP验证分为好几个步骤。我们的IP总资源有80W,检验一个IP是否可用一般来说需要20秒左右的时间,因为代理IP本身响应比较慢,我们会把超时时间设置得比较长。所以可以计算一下80W数据走一轮将要消耗得时间,即使在多线程并行环境下时间也是很多的。为了在一定资源下完成校验,我们设计了如下步骤 端口开启校验,在进行可用性校验前,首先需要检查IP端口是否开启。调研发现大量资源其实端口都不通,所以专门设计一个任务验证端口是否开启,端口开启验证超时时间为5秒。由于大多数资源端口都没有开启,所以大部分资源的校验时间下降到5秒了。 可用性校验,进行可用性校验的需要先进行端口开启校验,系统中端口开启的资源大概3W,所以校验可用性的总资源有3W左右。可用性校验存在如下问题,很多代理IP其实不是代理网站,想他发送请求最终不是我们预期的数据,比如他返回给我们一个代理IP认证网页。所以我们不能根据是否能够请求到数据来判定IP是否可用。我们的做法是在公网放置一个API接口,然后控制代理IP访问我们自己的接口,如果能够拿到符合我们接口的预期数据,那么认为IP可用。 domain可用该校验,可用性校验通过之后IP还不是真正可用,悲伤的发现代理IP是和域名相关的。所以同一个IP在不同域名下表现可能不一样。所以我们维护了一个域名IP池,这里面存储各个域名下可用IP IP分发 IP分发是根据客户请求分配可用IP。分发逻辑现在还没有完全完善,但是已经实现了最迫切和有校的分发方案。分发逻辑设计是:先尝试查询domainIP池,再根据其他请求参数做条件匹配,再查询系统可用IP,再随机选择可用填充。四个步骤如果有一个步骤得到的IP超过请求参数期待数目,则不进行接下来的动作。 IP验证模型 再IP验证的时候,我们设计了一个模型用来确定哪些IP应该优先验证。模型描述如下:长期可用IP检测频率低,长期不可用IP检测评率低。不稳定IP和刚加入的IP检测频率高。我们使用优先队列来实现这个逻辑,所有IP根据分值放在不同优先队列中,每次校验的时候再不同优先队列中拿出一定资源进行校验(不同优先级拿出的资源数目不一样,高优先级的对象拿出更多资源),对于同一个优先队列,我们根据最后验证时间排序。使上次更新时间最久的资源被优先选择。\n分发去重 分发资源的时候,设计去重问题,也就是根据相同条件,每次分发得到的IP很大可能会重复。为了规避这个问题,每次分发都会相应的下发一个资源签名,他会记录分发过的IP。在下次请求的时候,客户端需要带上这个签名,服务器会根据签名过滤,同时会重新对新分发的IP资源做再次签名.\nserver部署 server端使用java编写,使用maven管理项目,使用mysql作为数据库。相关技术包括springMVC,spring,tomcat,mybatis,guava,fastjson,httpclient等。 运行server的方式很简单\n在项目根目录执行maven命令(需要提前安装maven,maven安装方式略)mvn install -Dmaven.test.skip=true 在server目录执行maven命令 mvn tomcat7:run server配置 直接运行项目使用的是我们的默认数据库,同时使用的是默认配置。实际上server存在一些配置用来设置运行参数。合理的运行参数能够合理使用机器资源以及达到更好的运行效果。 项目主要有两个配置文件需要配置:\nmysql.properties 用来配置数据库信息 config.properties 配置其他启动参数,主要需要关注里面几个url地址,还有 system.thread.的参数项。system.thread用于指定某一种类型的任务执行的线程数,如果数据小于1,则这个模块不会启动。但是如果这个模块接收到了任务请求,那么他会转发到其他服务器上面(也就是上面的两个forward相关的url,没办法服务器都是腊鸡服务器 ) 其他的应该没有了把,哦对了,项目存在多个profile,也就是resources.local,resources.beta,resources.prod等。他们叫做profile,是maven里面的概念,默认是resources.local生效的。如果想使用其他profile下面的配置,则增加 -Pprofile参数,如运行server mvn -Pskyee clean tomcat7:run\nserver接口事例 http://115.159.40.202:8080/proxyipcenter/av?usedSign=\u0026amp;checkUrl=http%3A%2F%2Ffree-proxy-list.net%2F\u0026amp;domain=free-proxy-list.net\u0026amp;num=10\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 { \u0026#34;data\u0026#34;: { \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 257, \u0026#34;ip\u0026#34;: \u0026#34;203.192.12.148\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;203.192.12.149\u0026#34;, \u0026#34;port\u0026#34;: 80, \u0026#34;ipValue\u0026#34;: 3418360980, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华北\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;100000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;110000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;110100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 104, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 1310, \u0026#34;availbelScore\u0026#34;: 8, \u0026#34;connectionScoreDate\u0026#34;: 1475641264000, \u0026#34;availbelScoreDate\u0026#34;: 1475646860000, \u0026#34;createtime\u0026#34;: 1473840886000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 654, \u0026#34;ip\u0026#34;: \u0026#34;120.55.245.47\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;112.124.119.21\u0026#34;, \u0026#34;port\u0026#34;: 80, \u0026#34;ipValue\u0026#34;: 2016933167, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华东\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;浙江省\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;杭州市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;阿里云\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;300000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;330000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;330100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;1000323\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 83, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 1429, \u0026#34;availbelScore\u0026#34;: 2, \u0026#34;connectionScoreDate\u0026#34;: 1475659905000, \u0026#34;availbelScoreDate\u0026#34;: 1475630273000, \u0026#34;createtime\u0026#34;: 1473840884000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 2489, \u0026#34;ip\u0026#34;: \u0026#34;124.193.33.233\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;124.193.33.233\u0026#34;, \u0026#34;port\u0026#34;: 3128, \u0026#34;ipValue\u0026#34;: 2093031913, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华北\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;鹏博士\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;100000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;110000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;110100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;1000143\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 3390, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 310, \u0026#34;availbelScore\u0026#34;: 2, \u0026#34;connectionScoreDate\u0026#34;: 1475657685000, \u0026#34;availbelScoreDate\u0026#34;: 1475661878000, \u0026#34;createtime\u0026#34;: 1473839334000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 5004, \u0026#34;ip\u0026#34;: \u0026#34;203.192.12.146\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;203.192.12.149\u0026#34;, \u0026#34;port\u0026#34;: 80, \u0026#34;ipValue\u0026#34;: 3418360978, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华北\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;100000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;110000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;110100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 161, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 1291, \u0026#34;availbelScore\u0026#34;: 10, \u0026#34;connectionScoreDate\u0026#34;: 1475638336000, \u0026#34;availbelScoreDate\u0026#34;: 1475636727000, \u0026#34;createtime\u0026#34;: 1473840882000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 5421, \u0026#34;ip\u0026#34;: \u0026#34;221.237.155.64\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;221.237.155.64\u0026#34;, \u0026#34;port\u0026#34;: 9797, \u0026#34;ipValue\u0026#34;: 3723336512, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;西南\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;四川省\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;成都市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;电信\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;500000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;510000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;510100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;100017\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 3238, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 119, \u0026#34;availbelScore\u0026#34;: -1, \u0026#34;connectionScoreDate\u0026#34;: 1475611973000, \u0026#34;availbelScoreDate\u0026#34;: 1475629954000, \u0026#34;createtime\u0026#34;: 1473840773000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 8722, \u0026#34;ip\u0026#34;: \u0026#34;58.243.0.162\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;58.243.0.162\u0026#34;, \u0026#34;port\u0026#34;: 9999, \u0026#34;ipValue\u0026#34;: 989003938, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华东\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;安徽省\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;安庆市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;联通\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;300000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;340000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;340800\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;100026\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 5143, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 154, \u0026#34;availbelScore\u0026#34;: -3, \u0026#34;connectionScoreDate\u0026#34;: 1475665673000, \u0026#34;availbelScoreDate\u0026#34;: 1475614147000, \u0026#34;createtime\u0026#34;: 1473839836000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 11698, \u0026#34;ip\u0026#34;: \u0026#34;218.7.170.190\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;218.7.170.190\u0026#34;, \u0026#34;port\u0026#34;: 3128, \u0026#34;ipValue\u0026#34;: 3657935550, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;东北\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;黑龙江省\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;绥化市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;联通\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;200000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;230000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;231200\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;100026\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 3145, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 317, \u0026#34;availbelScore\u0026#34;: -1, \u0026#34;connectionScoreDate\u0026#34;: 1475642001000, \u0026#34;availbelScoreDate\u0026#34;: 1475524810000, \u0026#34;createtime\u0026#34;: 1473839128000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 13318, \u0026#34;ip\u0026#34;: \u0026#34;220.249.185.178\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;220.249.185.178\u0026#34;, \u0026#34;port\u0026#34;: 9999, \u0026#34;ipValue\u0026#34;: 3707353522, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华东\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;福建省\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;福州市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;联通\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;300000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;350000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;350100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;100026\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 5094, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 129, \u0026#34;availbelScore\u0026#34;: -1, \u0026#34;connectionScoreDate\u0026#34;: 1475615670000, \u0026#34;availbelScoreDate\u0026#34;: 1475585178000, \u0026#34;createtime\u0026#34;: 1473840539000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 57033, \u0026#34;ip\u0026#34;: \u0026#34;210.245.25.228\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;210.245.25.228\u0026#34;, \u0026#34;port\u0026#34;: 3128, \u0026#34;ipValue\u0026#34;: 3539278308, \u0026#34;country\u0026#34;: \u0026#34;越南\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 1024, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 488, \u0026#34;availbelScore\u0026#34;: 36, \u0026#34;connectionScoreDate\u0026#34;: 1475635386000, \u0026#34;availbelScoreDate\u0026#34;: 1475630473000, \u0026#34;createtime\u0026#34;: 1473836572000, \u0026#34;lostheader\u0026#34;: false }, { \u0026#34;id\u0026#34;: 124334, \u0026#34;ip\u0026#34;: \u0026#34;60.194.72.253\u0026#34;, \u0026#34;proxyIp\u0026#34;: \u0026#34;60.194.72.253\u0026#34;, \u0026#34;port\u0026#34;: 3128, \u0026#34;ipValue\u0026#34;: 1019365629, \u0026#34;country\u0026#34;: \u0026#34;中国\u0026#34;, \u0026#34;area\u0026#34;: \u0026#34;华北\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;北京市\u0026#34;, \u0026#34;isp\u0026#34;: \u0026#34;鹏博士\u0026#34;, \u0026#34;countryId\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;areaId\u0026#34;: \u0026#34;100000\u0026#34;, \u0026#34;regionId\u0026#34;: \u0026#34;110000\u0026#34;, \u0026#34;cityId\u0026#34;: \u0026#34;110100\u0026#34;, \u0026#34;ispId\u0026#34;: \u0026#34;1000143\u0026#34;, \u0026#34;transperent\u0026#34;: 2, \u0026#34;speed\u0026#34;: 2366, \u0026#34;type\u0026#34;: 1, \u0026#34;connectionScore\u0026#34;: 610, \u0026#34;availbelScore\u0026#34;: 16, \u0026#34;connectionScoreDate\u0026#34;: 1475643516000, \u0026#34;availbelScoreDate\u0026#34;: 1475631080000, \u0026#34;createtime\u0026#34;: 1473839561000, \u0026#34;lostheader\u0026#34;: false } ], \u0026#34;num\u0026#34;: 10, \u0026#34;sign\u0026#34;: \u0026#34;9999#C99+999#9B99B99999##Y9999+9999999999999999999999t9999s99999999s9999999999999999999999999999#99999999999999GB999999999G9999s9s99999#9999999999Y9+999##99999999+99999999999999+999999999999B999+Y9999G9+99999999999YB99999999999999999999999+99Y999999999B9999G999s99G999999999#99999#9Y999s999999999#B99999999999999999999+999999Y9999999Y9999999999999Y9999Y999999999999999\u0026#34; }, \u0026#34;status\u0026#34;: true } proxyipcenter client client 设计文档 client 使用文档 client运行原理 这里讲述IP池的设计相关,如果您仅仅是为了使用dunproxy-client,则不必关心本文内容\nclient就是一个代理IP池的实现,IP池的设计基于两个点:\n代理IP都是不稳定的,不可靠的,需要一个机制来切换IP,尽可能使用高质量IP。\nIP和环境关系很大,同一个IP在不同的机器下访问不同的目标网站,其可用性表现都是不一样的\n使用IpPoolAPI获取IP资源 获取IP 获取一个IP的方式是这样的 IpPool.getInstance().bind(domain, accessUrl);\n第一个参数是域名,可以传递null,传递null提取accessUrl schema里面的host 第二个参数是你当前需要访问的url, 可以为null,为null时domain不能为空 曾经有一个绑定用户的功能,使得同一个账户每次获取的IP相同,后来觉得是过度设计,因为对于抓取场景,切换IP是很普通的需求,而且貌似没有多少server会检查常用IP。就算有也是小众需求,本框架不必支持\n记录IP使用 每当使用IP的时候,需要记录一次IP使用,也就是将IP实例的使用次数加一,用于打分机制计算IP的使用分值,评估IP可用性 方式如下:com.virjar.dungproxy.client.model.AvProxy.recordUsage\n记录IP使用失败 每当IP使用失败的时候,需要记录IP使用失败,也就是将IP实例的失败次数加一,用于打分机制计算IP的使用分值,评估IP可用性 方式如下:com.virjar.dungproxy.client.model.AvProxy.recordFailed()\nIP下线 IP下线很简单,拿到IP实例,这样调用com.virjar.dungproxy.client.model.AvProxy.offline()。 一般情况不建议这么做,因为IP池会自动检查IP是否应该下线,IP池可以定制各种策略。当时,有些时候IP池的检查机制比较缓慢,而上层业务可以明确知道本IP不可用,这个时候可以使用本API强制下线\n销毁IP池实例 IP池是单例的,同时里面维护了两个任务线程,在业务完成的时候,需要销毁IP池才能终止内部线程。同时也会执行一些收尾工作,如将可用IP dump。 销毁方式是:com.virjar.dungproxy.client.ippool.IpPool.destroy\n其他 IP池有其他很多扩展点,但是目前接口没有开发完成,待后续完善\nTODO 几个主流语言的客户端 .NET/.NET core client (辣鸡楼主还没动手\u0026hellip;) Python client(另外一个大佬好像忘了这事了\u0026hellip;) Golang client(可能还是辣鸡楼主动手\u0026hellip;) ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%8F%AF%E8%83%BD%E6%98%AF%E4%B8%80%E4%BB%BD%E6%B2%A1%E4%BB%80%E4%B9%88%E7%94%A8%E7%9A%84%E7%88%AC%E8%99%AB%E4%BB%A3%E7%90%86ip%E6%8C%87%E5%8D%97/","title":"可能是一份没什么用的爬虫代理IP指南"},{"content":"一些有用的脚本 获取电池使用情况报告(battery-report)-电池历史记录 来源：获取电池使用情况报告(battery-report)-电池历史记录\n点击任务栏搜索框，搜索：POWERSHELL 鼠标右键点击搜索结果中的“Windows Powershell”，点击“以管理员身份运行” 1 $HTML=[System.Environment]::GetFolderPath(\u0026#39;Desktop\u0026#39;)+\u0026#34;\\\u0026#34;+(Get-Date -Format \u0026#39;yyyy-MM-dd\u0026#39;)+\u0026#34;-电池记录.html\u0026#34;;POWERCFG /BATTERYREPORT /OUTPUT \u0026#34;$HTML\u0026#34;;$TF=Get-Content \u0026#34;$HTML\u0026#34;;$TF| %{$_.Replace(\u0026#34;Battery report\u0026#34;,\u0026#34;电池报告\u0026#34;)}| %{$_.Replace(\u0026#34;COMPUTER NAME\u0026#34;,\u0026#34;计算机名\u0026#34;)}| %{$_.Replace(\u0026#34;SYSTEM PRODUCT NAME\u0026#34;,\u0026#34;计算机型号\u0026#34;)}| %{$_.Replace(\u0026#34;OS BUILD\u0026#34;,\u0026#34;操作系统内部版本\u0026#34;)}| %{$_.Replace(\u0026#34;PLATFORM ROLE\u0026#34;,\u0026#34;平台角色\u0026#34;)}| %{$_.Replace(\u0026#34;CONNECTED STANDBY\u0026#34;,\u0026#34;InstantGo（连接待机）\u0026#34;)}| %{$_.Replace(\u0026#34;REPORT TIME\u0026#34;,\u0026#34;报告时间\u0026#34;)}| %{$_.Replace(\u0026#34;Installed batteries\u0026#34;,\u0026#34;已安装的电池\u0026#34;)}| %{$_.Replace(\u0026#34;Information about each currently installed battery\u0026#34;,\u0026#34;查看当前已安装电池的信息\u0026#34;)}| %{$_.Replace(\u0026#34;NAME\u0026#34;,\u0026#34;名称\u0026#34;)}| %{$_.Replace(\u0026#34;MANUFACTURER\u0026#34;,\u0026#34;制造商\u0026#34;)}| %{$_.Replace(\u0026#34;SERIAL NUMBER\u0026#34;,\u0026#34;序列号\u0026#34;)}| %{$_.Replace(\u0026#34;CHEMISTRY\u0026#34;,\u0026#34;化学成分\u0026#34;)}| %{$_.Replace(\u0026#34;AT DESIGN CAPACITY\u0026#34;,\u0026#34;设计容量时\u0026#34;)}| %{$_.Replace(\u0026#34;DESIGN CAPACITY\u0026#34;,\u0026#34;设计容量\u0026#34;)}| %{$_.Replace(\u0026#34;FULL CHARGE CAPACITY\u0026#34;,\u0026#34;完全充电容量\u0026#34;)}| %{$_.Replace(\u0026#34;CYCLE COUNT\u0026#34;,\u0026#34;循环计数\u0026#34;)}| %{$_.Replace(\u0026#34;Recent usage\u0026#34;,\u0026#34;最近使用情况\u0026#34;)}| %{$_.Replace(\u0026#34;Power states over the last 3 days\u0026#34;,\u0026#34;过去72小时内的电源状态\u0026#34;)}| %{$_.Replace(\u0026#34;START TIME\u0026#34;,\u0026#34;开始时间\u0026#34;)}| %{$_.Replace(\u0026#34;STATE\u0026#34;,\u0026#34;状态\u0026#34;)}| %{$_.Replace(\u0026#34;SOURCE\u0026#34;,\u0026#34;电源\u0026#34;)}| %{$_.Replace(\u0026#34;CAPACITY REMAINING\u0026#34;,\u0026#34;剩余容量\u0026#34;)}| %{$_.Replace(\u0026#34;Battery usage\u0026#34;,\u0026#34;电池使用情况\u0026#34;)}| %{$_.Replace(\u0026#34;Battery drains over the last 3 days\u0026#34;,\u0026#34;过去72小时内的电池消耗\u0026#34;)}| %{$_.Replace(\u0026#34;DURATION\u0026#34;,\u0026#34;使用时间\u0026#34;)}| %{$_.Replace(\u0026#34;ENERGY DRAINED\u0026#34;,\u0026#34;消耗的能量\u0026#34;)}| %{$_.Replace(\u0026#34;Usage history\u0026#34;,\u0026#34;使用历史记录\u0026#34;)}| %{$_.Replace(\u0026#34;History of system usage on AC and battery\u0026#34;,\u0026#34;有关交流电源和电池的使用记录\u0026#34;)}| %{$_.Replace(\u0026#34;BATTERY DURATION\u0026#34;,\u0026#34;电池使用时间\u0026#34;)}| %{$_.Replace(\u0026#34;AC DURATION \u0026#34;,\u0026#34;交流电源使用时间\u0026#34;)}| %{$_.Replace(\u0026#34;PERIOD\u0026#34;,\u0026#34;周期\u0026#34;)}| %{$_.Replace(\u0026#34;ACTIVE\u0026#34;,\u0026#34;活动\u0026#34;)}| %{$_.Replace(\u0026#34;Battery capacity history\u0026#34;,\u0026#34;电池设计容量历史记录\u0026#34;)}| %{$_.Replace(\u0026#34;Charge capacity history of the system\u0026#39;s batteries\u0026#34;,\u0026#34;电池充电能力历史记录\u0026#34;)}| %{$_.Replace(\u0026#34;Battery life estimates based on observed drains\u0026#34;,\u0026#34;以观察到的消耗情况预计电池寿命\u0026#34;)}| %{$_.Replace(\u0026#34;Battery life estimates\u0026#34;,\u0026#34;预计电池寿命\u0026#34;)}| %{$_.Replace(\u0026#34;AT FULL CHARGE\u0026#34;,\u0026#34;完全充电时\u0026#34;)}| %{$_.Replace(\u0026#34;Current estimate of battery life based on all observed drains since OS install\u0026#34;,\u0026#34;以操作系统安装后所有观察到的消耗记录为基础预计的当前电池寿命\u0026#34;)}| %{$_.Replace(\u0026#34;Since OS install\u0026#34;,\u0026#34;从操作系统安装后\u0026#34;)}| %{$_.Replace(\u0026#34;Supported\u0026#34;,\u0026#34;支持\u0026#34;)}| %{$_.Replace(\u0026#34;Not supported\u0026#34;,\u0026#34;不支持\u0026#34;)}| %{$_.Replace(\u0026#34;BATTERY\u0026#34;,\u0026#34;电池\u0026#34;)}| %{$_.Replace(\u0026#34;Suspended\u0026#34;,\u0026#34;已暂停\u0026#34;)}| %{$_.Replace(\u0026#34;Active\u0026#34;,\u0026#34;活动\u0026#34;)}| %{$_.Replace(\u0026#34;Unspecified\u0026#34;,\u0026#34;未知\u0026#34;)}| %{$_.Replace(\u0026#34;Mobile\u0026#34;,\u0026#34;移动\u0026#34;)}| %{$_.Replace(\u0026#34;Desktop\u0026#34;,\u0026#34;桌面\u0026#34;)}| %{$_.Replace(\u0026#34;Workstation\u0026#34;,\u0026#34;工作站\u0026#34;)}| %{$_.Replace(\u0026#34;Report generated\u0026#34;,\u0026#34;生成当前报告\u0026#34;)}| %{$_.Replace(\u0026#34;Battery\u0026#34;,\u0026#34;电池\u0026#34;)}| %{$_.Replace(\u0026#34;AC\u0026#34;,\u0026#34;交流电源\u0026#34;)}|Out-File \u0026#34;$HTML\u0026#34;;pause ","date":"2016-10-04T00:00:00Z","permalink":"https://liguobao.github.io/p/%E4%B8%80%E4%BA%9B%E6%9C%89%E7%94%A8%E7%9A%84%E8%84%9A%E6%9C%AC/","title":"一些有用的脚本"},{"content":"外公外婆聊天记录 第一部分, 关于地主 我: 应该不是, XX 地方(离我家不远的一个村落)那边的地主, 我有个同学是 XX 村落的地主曾孙, 他爷爷是地主家的儿子, 姓邓的.\n外公: 那是邓明光的儿子吧.\n我: 邓明光的儿子? 应该不是, 我同学的爷爷是我上高中的时候去世的, 以前是在 XX 小说当老师的, 同学的奶奶是另一个地方的地主家的女儿. 邓明光? 是 XX 那个地方小洋楼的那个人吗? 三层的洋楼, 水泥做的, 白色刷灰, 很多年的啦(有点历史的意思, 那个楼应该是民国期间的建筑).\n外婆: 现在中午了, 人都不知道那里去了. (不太记得为什么外婆插了这句话.)\n外公: 咳嗽.\n捉鱼的渔网 我: 那外公你以前捉鱼的网是怎么做的?\n外公: 乜嘢?\n我: 以前捉鱼用的网是怎么做的呀?\n","date":"2015-08-31T00:00:00Z","permalink":"https://liguobao.github.io/p/%E5%A4%96%E5%85%AC%E5%A4%96%E5%A9%86%E8%81%8A%E5%A4%A9%E8%AE%B0%E5%BD%95/","title":"外公外婆聊天记录"}]